import streamlit as st
import pandas as pd
import os
import yfinance as yf
from datetime import datetime, timedelta
from fredapi import Fred
import requests
import io
import google.generativeai as genai
import time

# Set page config
st.set_page_config(
    page_title="é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç† (ç”± Gemini é©…å‹•)",
    layout="wide"
)

# --- Function to load custom CSS ---
def load_custom_css():
    try:
        with open("style.css", "r", encoding="utf-8") as f:
            css_content = f.read()
        st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning("è­¦å‘Šï¼šstyle.css æª”æ¡ˆæœªæ‰¾åˆ°ã€‚å°‡ä½¿ç”¨é è¨­æ¨£å¼ã€‚")
    except Exception as e:
        st.error(f"è¼‰å…¥è‡ªè¨‚ CSS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- Load CSS and Apply Theme Wrapper ---
load_custom_css()

# Apply a global div with the theme class.
st.markdown(f"<div class='theme-{st.session_state.get('active_theme', 'dark')}'>", unsafe_allow_html=True)

# --- Inject Dynamic Font Size CSS ---
font_size_css_map = {
    "å°": "0.875rem", # Approx 14px if base is 16px
    "ä¸­": "1rem",    # Approx 16px (base)
    "å¤§": "1.125rem"  # Approx 18px
}
selected_font_size_value = font_size_css_map.get(st.session_state.get("font_size_name", "ä¸­"), "1rem")

font_override_style = f"""
<style>
html {{
    font-size: {selected_font_size_value} !important;
}}
/* Add any element-specific overrides here if needed, e.g.: */
/*
.stButton button {{ font-size: 0.9em !important; }}
.stTextInput input {{ font-size: 1em !important; }}
*/
</style>
"""
st.markdown(font_override_style, unsafe_allow_html=True)

# API Key Definitions
api_keys_info = {
    "gemini_api_key_1": "Gemini API Key 1",
    "gemini_api_key_2": "Gemini API Key 2",
    "gemini_api_key_3": "Gemini API Key 3",
    "fred_api_key": "FRED API Key",
    "alpha_vantage_api_key": "Alpha Vantage API Key",
    "api_key_fmpnb": "Financial Modeling Prep API Key",
    "api_key_finnhub": "Finnhub API Key",
    "api_key_figi": "OpenFigi API Key",
    "api_key_iex": "IEX Cloud API Key",
    "api_key_polygon": "Polygon API Key",
    "deepseek_api_key": "DeepSeek API Key",
}

# Initialize session state for API keys if not already done
if 'initialized_keys' not in st.session_state:
    for key_name_snake_case in api_keys_info.keys():
        # Convert snake_case to UPPER_SNAKE_CASE for st.secrets
        secret_key_name = key_name_snake_case.upper()
        st.session_state[key_name_snake_case] = st.secrets.get(secret_key_name, "")
    st.session_state.initialized_keys = True

# Gemini Model Definitions
available_models = ["gemini-1.5-flash-latest", "gemini-1.5-pro-latest", "gemini-1.0-pro"]

# Initialize session state for Model Settings if not already done
if 'initialized_model_settings' not in st.session_state:
    st.session_state.selected_model_name = available_models[0]
    st.session_state.global_rpm_limit = 5
    st.session_state.global_tpm_limit = 200000
    st.session_state.initialized_model_settings = True

# Default Main Gemini Prompt
DEFAULT_MAIN_GEMINI_PROMPT = """è«‹ä½ åˆ†ææˆ‘æä¾›çš„æ‰€æœ‰æ–‡å­—æª”ã€‚
ä½ çš„ä»»å‹™æ˜¯æ•´ç†é€™äº›æª”æ¡ˆä¸­åŒ…å«çš„ç¤¾ç¾¤åª’é«”è²¼æ–‡ã€‚
è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºå‘ˆç¾çµæœï¼š
1.  **ä¾†æºè­˜åˆ¥**ï¼šç¢ºèªæ¯å€‹è²¼æ–‡çš„åŸå§‹æª”æ¡ˆåç¨±ã€‚
2.  **å…§å®¹æ‘˜è¦**ï¼šå°æ¯å€‹è²¼æ–‡é€²è¡Œç°¡æ½”æ‘˜è¦ã€‚
3.  **æƒ…ç·’åˆ†æ**ï¼šåˆ¤æ–·æ¯å€‹è²¼æ–‡è¡¨é”çš„æƒ…ç·’ï¼ˆä¾‹å¦‚ï¼Œæ­£é¢ã€è² é¢ã€ä¸­æ€§ï¼‰ã€‚
4.  **é—œéµä¸»é¡Œ**ï¼šæå–æ¯å€‹è²¼æ–‡è¨è«–çš„æ ¸å¿ƒä¸»é¡Œã€‚
5.  **å»ºè­°è¡Œå‹•**ï¼šå¦‚æœè²¼æ–‡æš—ç¤ºäº†æŸç¨®è¡Œå‹•æˆ–å»ºè­°ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
è«‹ç¢ºä¿æœ€çµ‚è¼¸å‡ºçµæœåš´æ ¼éµå¾ªä¸Šè¿°æ‰€æœ‰æŒ‡ç¤ºã€‚"""

# Initialize session state for Prompt Settings if not already done
if 'initialized_prompt_settings' not in st.session_state:
    st.session_state.main_gemini_prompt = DEFAULT_MAIN_GEMINI_PROMPT
    st.session_state.initialized_prompt_settings = True

# Initialize session state for File Upload Settings if not already done
if 'initialized_file_upload_settings' not in st.session_state:
    st.session_state.uploaded_files_list = []
    st.session_state.uploaded_file_contents = {}
    st.session_state.initialized_file_upload_settings = True

# Initialize session state for Data Source Settings if not already done
if 'initialized_data_source_settings' not in st.session_state:
    st.session_state.select_yfinance = False
    st.session_state.select_fred = False
    st.session_state.select_ny_fed = False
    st.session_state.select_all_sources = False
    st.session_state.data_start_date = "20230101"
    st.session_state.data_end_date = datetime.now().strftime("%Y%m%d")
    st.session_state.yfinance_tickers = "AAPL,^MOVE"
    st.session_state.yfinance_interval_label = "æ¯æ—¥"
    st.session_state.fred_series_ids = "DGS10,VIXCLS"
    st.session_state.fetched_data_preview = {}
    st.session_state.fetch_errors = []
    st.session_state.fetch_data_button_clicked = False # To track if button was clicked
    st.session_state.initialized_data_source_settings = True

# Initialize session state for Gemini Interaction Settings if not already done
if 'initialized_gemini_interaction_settings' not in st.session_state:
    st.session_state.chat_history = []
    st.session_state.active_gemini_key_index = 0
    st.session_state.gemini_api_key_usage = {} # {key_value: {'requests': [timestamp], 'tokens': [(timestamp, count)]}}
    st.session_state.gemini_caches_list = []
    st.session_state.selected_cache_for_generation = None
    st.session_state.initialized_gemini_interaction_settings = True

# Initialize Theme Settings
if 'initialized_theme_settings' not in st.session_state:
    st.session_state.active_theme = "dark"  # Default to dark theme
    st.session_state.initialized_theme_settings = True

# Initialize Font Size Settings
if 'initialized_font_settings' not in st.session_state:
    st.session_state.font_size_name = "ä¸­"  # Default to medium
    st.session_state.initialized_font_settings = True

# Function to fetch yfinance data
@st.cache_data(ttl=3600)
def fetch_yfinance_data(tickers_str: str, start_date_str: str, end_date_str: str, interval: str):
    data_frames = {}
    errors = []

    if not tickers_str.strip():
        errors.append("Ticker å­—ä¸²ä¸å¯ç‚ºç©ºã€‚")
        return data_frames, errors

    list_of_tickers = [ticker.strip().upper() for ticker in tickers_str.split(',') if ticker.strip()]
    if not list_of_tickers:
        errors.append("æœªæä¾›æœ‰æ•ˆçš„ Tickerã€‚")
        return data_frames, errors

    try:
        start_dt = datetime.strptime(start_date_str, "%Y%m%d")
    except ValueError:
        errors.append(f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚")
        return data_frames, errors

    try:
        end_dt = datetime.strptime(end_date_str, "%Y%m%d")
        # yfinance 'end' is exclusive, so if we want to include the end_date_str, we might need to add a day.
        # For simplicity as per instructions, we'll use it as is for now, or adjust if necessary.
        # If end_dt is meant to be inclusive for user input, uncomment below:
        # end_dt = end_dt + timedelta(days=1)
    except ValueError:
        errors.append(f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚")
        return data_frames, errors

    if start_dt > end_dt:
        errors.append(f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚")
        return data_frames, errors

    for ticker in list_of_tickers:
        try:
            df = yf.download(ticker, start=start_dt, end=end_dt, interval=interval, progress=False)
            if df.empty:
                errors.append(f"Ticker {ticker}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚")
            else:
                df.reset_index(inplace=True)
                # Convert all column names to string to avoid potential issues with non-string column names
                df.columns = df.columns.astype(str)
                data_frames[ticker] = df
        except Exception as e:
            errors.append(f"ä¸‹è¼‰ Ticker {ticker} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # Consider adding a small delay here if implementing retries in future
            # import time
            # time.sleep(1)

    return data_frames, errors

# Function to fetch FRED data
@st.cache_data(ttl=86400)
def fetch_fred_data(series_ids_str: str, start_date_str: str, end_date_str: str, api_key: str):
    data_series_dict = {}
    errors = []

    if not api_key:
        errors.append("éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªæä¾›ã€‚")
        return data_series_dict, errors

    try:
        fred = Fred(api_key=api_key)
    except Exception as e:
        errors.append(f"FRED API é‡‘é‘°åˆå§‹åŒ–å¤±æ•—: {str(e)}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°ã€‚")
        return data_series_dict, errors

    if not series_ids_str.strip():
        errors.append("Series ID å­—ä¸²ä¸å¯ç‚ºç©ºã€‚")
        return data_series_dict, errors

    list_of_series_ids = [sid.strip().upper() for sid in series_ids_str.split(',') if sid.strip()]
    if not list_of_series_ids:
        errors.append("æœªæä¾›æœ‰æ•ˆçš„ Series IDã€‚")
        return data_series_dict, errors

    try:
        start_dt = datetime.strptime(start_date_str, "%Y%m%d")
    except ValueError:
        errors.append(f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚")
        return data_series_dict, errors

    try:
        end_dt = datetime.strptime(end_date_str, "%Y%m%d")
    except ValueError:
        errors.append(f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚")
        return data_series_dict, errors

    if start_dt > end_dt:
        errors.append(f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚")
        return data_series_dict, errors

    for series_id in list_of_series_ids:
        try:
            series_data = fred.get_series(series_id, observation_start=start_dt, observation_end=end_dt)
            if series_data.empty:
                errors.append(f"Series ID {series_id}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚")
            else:
                df = series_data.to_frame(name=series_id)
                df.reset_index(inplace=True)
                df.rename(columns={'index': 'Date', series_id: 'Value'}, inplace=True)
                # Ensure 'Date' column is datetime type, and 'Value' is numeric
                df['Date'] = pd.to_datetime(df['Date'])
                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
                df.dropna(subset=['Value'], inplace=True) # Remove rows where value couldn't be converted
                data_series_dict[series_id] = df
        except ValueError as ve: # More specific exception for invalid series ID
             errors.append(f"Series ID {series_id} ç„¡æ•ˆæˆ–æ‰¾ä¸åˆ°: {str(ve)}")
        except Exception as e:
            errors.append(f"ä¸‹è¼‰ Series ID {series_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    return data_series_dict, errors

# Constants for NY Fed Data Fetching
NY_FED_POSITIONS_URLS_CORRECTED = [
    "https://markets.newyorkfed.org/api/pd/get/SBN2024/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
    "https://markets.newyorkfed.org/api/pd/get/SBN2022/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
    "https://markets.newyorkfed.org/api/pd/get/SBN2015/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
    "https://markets.newyorkfed.org/api/pd/get/SBN2013/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
    "https://markets.newyorkfed.org/api/pd/get/SBP2013/timeseries/PDPUSGCS3LNOP_PDPUSGCS36NOP_PDPUSGCS611NOP_PDPUSGCSM11NOP.xlsx",
    "https://markets.newyorkfed.org/api/pd/get/SBP2001/timeseries/PDPUSGCS5LNOP_PDPUSGCS5MNOP.xlsx",
]

SBP_COLS_TO_SUM = {
    "SBP2013": ["PDPUSGCS3LNOP", "PDPUSGCS36NOP", "PDPUSGCS611NOP", "PDPUSGCSM11NOP"],
    "SBP2001": ["PDPUSGCS5LNOP", "PDPUSGCS5MNOP"],
}

# Function to fetch NY Fed Primary Dealer Positions
@st.cache_data(ttl=86400)
def fetch_ny_fed_data():
    all_positions_data = []
    errors = []
    # Assuming header at row index 4, date in first column (index 0) for all files as a simplification.
    HEADER_ROW_ASSUMPTION = 4
    DATE_COLUMN_INDEX_ASSUMPTION = 0

    for url in NY_FED_POSITIONS_URLS_CORRECTED:
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status() # Will raise an HTTPError if the HTTP request returned an unsuccessful status code

            excel_content = io.BytesIO(response.content)
            xls = pd.ExcelFile(excel_content)

            # Simplified parsing based on assumption
            df = pd.read_excel(xls, sheet_name=0, header=HEADER_ROW_ASSUMPTION, index_col=DATE_COLUMN_INDEX_ASSUMPTION)

            df.index = pd.to_datetime(df.index, errors='coerce')
            df = df[df.index.notna()] # Remove rows where date could not be parsed

            if df.empty:
                errors.append(f"æª”æ¡ˆ {url} åœ¨è½‰æ›æ—¥æœŸå¾Œæ²’æœ‰æœ‰æ•ˆæ•¸æ“šã€‚")
                continue

            source_type = None
            target_cols = []

            if "SBN" in url:
                source_type = "SBN"
                # Filter columns that exist in the DataFrame
                target_cols = [col for col in df.columns if str(col).startswith("PDPOSGSC-")]
            elif "SBP2013" in url:
                source_type = "SBP2013"
                target_cols = [col for col in SBP_COLS_TO_SUM["SBP2013"] if col in df.columns]
            elif "SBP2001" in url:
                source_type = "SBP2001"
                target_cols = [col for col in SBP_COLS_TO_SUM["SBP2001"] if col in df.columns]

            if not target_cols:
                errors.append(f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) ä¸­æœªæ‰¾åˆ°ç›®æ¨™æ¬„ä½æˆ–ç›®æ¨™æ¬„ä½åˆ—è¡¨ç‚ºç©ºã€‚")
                continue

            # Ensure target columns are numeric before summing
            df_target = df[target_cols].apply(pd.to_numeric, errors='coerce')

            # Check if all target columns became NaN (e.g. if they were not numeric)
            if df_target.isnull().all().all():
                errors.append(f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) çš„ç›®æ¨™æ¬„ä½ {target_cols} è½‰æ›ç‚ºæ•¸å­—å¾Œå‡ç‚ºç©ºå€¼ã€‚")
                continue

            daily_sum = df_target.sum(axis=1)
            all_positions_data.append(daily_sum)

        except requests.exceptions.HTTPError as http_err:
            errors.append(f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”Ÿ HTTP éŒ¯èª¤: {http_err}")
        except requests.exceptions.RequestException as req_err:
            errors.append(f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {req_err}")
        except Exception as e:
            errors.append(f"è™•ç†æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    if not all_positions_data:
        return None, errors

    try:
        final_series = pd.concat(all_positions_data)
        # Group by index (date) and take the last non-null value for that date.
        # This handles overlaps where one file might have a more up-to-date value for a given Wednesday.
        final_series = final_series.groupby(final_series.index).last()
        final_series = final_series.sort_index()
        final_series = final_series.ffill() # Forward fill any remaining NaNs

        result_df = final_series.to_frame(name="Total_Dealer_Positions")
        result_df.reset_index(inplace=True)
        result_df.rename(columns={'index': 'Date'}, inplace=True)
        # Ensure Date column is just date, not datetime, if desired (usually it's weekly data)
        # result_df['Date'] = result_df['Date'].dt.date
    except Exception as e:
        errors.append(f"åˆä½µå’Œæœ€çµ‚è™•ç† NY Fed æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None, errors

    return result_df, errors

# Gemini API Call Function
def call_gemini_api(prompt_parts: list, api_keys_list: list, selected_model: str,
                    global_rpm: int, global_tpm: int, # TPM not strictly enforced yet
                    generation_config_dict: dict = None, cached_content_name: str = None):

    if not api_keys_list:
        return "éŒ¯èª¤ï¼šæœªæä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚"

    active_key_index = st.session_state.get('active_gemini_key_index', 0)
    current_api_key = api_keys_list[active_key_index]

    # Simplified RPM Check (non-blocking, returns error if limit would be hit)
    now = time.time()
    if current_api_key not in st.session_state.gemini_api_key_usage:
        st.session_state.gemini_api_key_usage[current_api_key] = {'requests': [], 'tokens': []}

    # Remove timestamps older than 60 seconds
    st.session_state.gemini_api_key_usage[current_api_key]['requests'] = \
        [ts for ts in st.session_state.gemini_api_key_usage[current_api_key]['requests'] if now - ts < 60]

    if len(st.session_state.gemini_api_key_usage[current_api_key]['requests']) >= global_rpm:
        # Rotate key immediately if current one is rate-limited for this attempt
        st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list)
        return f"éŒ¯èª¤ï¼šAPI é‡‘é‘° {current_api_key[:10]}... RPM é”åˆ°ä¸Šé™ ({global_rpm})ã€‚è«‹ç¨å¾Œé‡è©¦æˆ–åˆ‡æ›é‡‘é‘°ã€‚"

    try:
        genai.configure(api_key=current_api_key)
        model = genai.GenerativeModel(model_name=selected_model) # Ensure model_name is passed

        gen_config_obj = None
        if generation_config_dict:
            gen_config_obj = genai.types.GenerationConfig(**generation_config_dict)

        # Construct the full prompt string from parts for API call
        # The API expects a list of parts, but for a simple text prompt, it's often a single string.
        # If prompt_parts is already structured for the API (e.g. list of TextPart or similar), use as is.
        # For this initial implementation, assuming prompt_parts is a list of strings to be joined.
        final_prompt_content = "\n".join(map(str, prompt_parts))

        response = model.generate_content(
            final_prompt_content, # Pass the combined string
            generation_config=gen_config_obj,
            safety_settings=None,
            tools=None,
            tool_config=None,
            cached_content=cached_content_name
        )

        # Record usage
        st.session_state.gemini_api_key_usage[current_api_key]['requests'].append(now)
        token_count = 0
        if response.usage_metadata and response.usage_metadata.total_token_count:
            token_count = response.usage_metadata.total_token_count
            st.session_state.gemini_api_key_usage[current_api_key]['tokens'].append((now, token_count))

        st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list)

        # Handle cases where response.text might be missing
        if response.parts:
            return "".join(part.text for part in response.parts if hasattr(part, 'text'))
        elif response.text: # Fallback for older versions or different response structures
             return response.text
        else: # If no text or parts, likely an issue or non-text response
            return "æ¨¡å‹æœªè¿”å›æ–‡å­—å…§å®¹ã€‚"


    except genai.types.BlockedPromptException as bpe:
        return f"éŒ¯èª¤ï¼šæç¤ºè©è¢« Gemini API å°é–ã€‚åŸå› : {bpe}"
    except genai.types.generation_types.StopCandidateException as sce:
        return f"éŒ¯èª¤ï¼šå…§å®¹ç”Ÿæˆå› å®‰å…¨åŸå› æˆ–å…¶ä»–é™åˆ¶è€Œåœæ­¢ã€‚åŸå› : {sce}"
    except Exception as e:
        # Attempt to get more detailed error message if available
        error_message = str(e)
        if hasattr(e, 'message'): # Some specific API errors might have a 'message' attribute
            error_message = e.message
        elif hasattr(e, 'args') and e.args: # General exceptions often store info in args
            error_message = str(e.args[0])

        # Log the full error for debugging if needed, but return a user-friendly one
        # print(f"Gemini API Error: {e}") # For server-side logging
        return f"å‘¼å« Gemini API æ™‚ç™¼ç”ŸéŒ¯èª¤: {error_message}"


# Sidebar
st.sidebar.title("âš™ï¸ å…¨åŸŸè¨­å®šèˆ‡å·¥å…·")

# Theme Toggle UI & Font Size
st.sidebar.header("ğŸ¨ å¤–è§€ä¸»é¡Œèˆ‡å­—é«”")
active_theme = st.session_state.get("active_theme", "dark")
current_theme_label = "æš—è‰²æ¨¡å¼ (Gemini)" if active_theme == "dark" else "äº®è‰²æ¨¡å¼ (é è¨­)"
toggle_label = f"åˆ‡æ›åˆ° {'äº®è‰²æ¨¡å¼ (é è¨­)' if active_theme == 'dark' else 'æš—è‰²æ¨¡å¼ (Gemini)'}"
new_toggle_state_is_dark = st.sidebar.toggle(
    toggle_label,
    value=(active_theme == "dark"),
    key="theme_toggle_widget",
    help="é»æ“Šåˆ‡æ›äº®æš—ä¸»é¡Œ"
)
if new_toggle_state_is_dark and active_theme == "light":
    st.session_state.active_theme = "dark"
    st.experimental_rerun()
elif not new_toggle_state_is_dark and active_theme == "dark":
    st.session_state.active_theme = "light"
    st.experimental_rerun()
st.sidebar.caption(f"ç›®å‰ä¸»é¡Œ: {current_theme_label}")

st.sidebar.markdown("##### é¸æ“‡å­—é«”å¤§å°:")
font_cols = st.sidebar.columns(3)
if font_cols[0].button("A- (å°)", key="font_small_button", use_container_width=True):
    st.session_state.font_size_name = "å°"
    st.experimental_rerun()
if font_cols[1].button("A (ä¸­)", key="font_medium_button", use_container_width=True):
    st.session_state.font_size_name = "ä¸­"
    st.experimental_rerun()
if font_cols[2].button("A+ (å¤§)", key="font_large_button", use_container_width=True):
    st.session_state.font_size_name = "å¤§"
    st.experimental_rerun()
st.sidebar.caption(f"ç›®å‰å­—é«”: {st.session_state.get('font_size_name', 'ä¸­')}")
st.sidebar.markdown("---")

# API Key Management
st.sidebar.header("ğŸ”‘ API é‡‘é‘°ç®¡ç†")
st.sidebar.caption("è«‹åœ¨æ­¤è™•ç®¡ç†æ‚¨çš„ API é‡‘é‘°ã€‚")
# ... (rest of the sidebar code for API keys, model settings, etc. remains unchanged from this point)

# Check for essential API keys and display a warning if missing
gemini_keys_present = any(st.session_state.get(f"gemini_api_key_{i+1}", "") for i in range(3))
if not gemini_keys_present:
    st.sidebar.warning("è­¦å‘Šï¼šè‡³å°‘éœ€è¦ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°æ‰èƒ½ä½¿ç”¨ Gemini åˆ†æåŠŸèƒ½ã€‚")

# Create text input fields for each API key
for key_name_snake_case, key_label in api_keys_info.items():
    st.session_state[key_name_snake_case] = st.sidebar.text_input(
        key_label,
        type="password",
        value=st.session_state[key_name_snake_case],
        key=f"{key_name_snake_case}_input" # Unique key for each widget
    )

st.sidebar.success("API é‡‘é‘°å·²æ›´æ–°ä¸¦å„²å­˜åœ¨æœƒè©±ä¸­ã€‚") # Optional confirmation

st.sidebar.header("ğŸ¤– Gemini æ¨¡å‹è¨­å®š")
st.sidebar.caption("é¸æ“‡ä¸¦é…ç½®è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ã€‚")

# Gemini Model Selection
st.session_state.selected_model_name = st.sidebar.selectbox(
    "é¸æ“‡ Gemini æ¨¡å‹:",
    options=available_models,
    index=available_models.index(st.session_state.selected_model_name), # Ensure current session value is selected
    key="selected_model_name_selector"
)

# Global RPM Setting
st.session_state.global_rpm_limit = st.sidebar.number_input(
    "å…¨åŸŸ RPM (æ¯åˆ†é˜è«‹æ±‚æ•¸):",
    min_value=1,
    value=st.session_state.global_rpm_limit,
    step=1,
    key="global_rpm_limit_input"
)

# Global TPM Setting
st.session_state.global_tpm_limit = st.sidebar.number_input(
    "å…¨åŸŸ TPM (æ¯åˆ†é˜è©å…ƒæ•¸):",
    min_value=1000,
    value=st.session_state.global_tpm_limit,
    step=10000,
    key="global_tpm_limit_input"
)
st.sidebar.caption("æ³¨æ„ï¼šè«‹åƒè€ƒ Gemini å®˜æ–¹æ–‡ä»¶äº†è§£ä¸åŒæ¨¡å‹çš„å…·é«” RPM/TPM é™åˆ¶ã€‚")

st.sidebar.header("ğŸ“ ä¸»è¦æç¤ºè©")
st.sidebar.caption("è¨­å®šç”¨æ–¼æŒ‡å° Gemini åˆ†æçš„ä¸»è¦æç¤ºè©ã€‚")

# Main Gemini Prompt Text Area
st.session_state.main_gemini_prompt = st.sidebar.text_area(
    "ä¸»è¦åˆ†ææç¤ºè© (System Prompt):",
    value=st.session_state.main_gemini_prompt,
    height=300,
    key="main_gemini_prompt_input"
)

# Prompt File Uploader
uploaded_prompt_file = st.sidebar.file_uploader(
    "æˆ–å¾ .txt æª”æ¡ˆè¼‰å…¥æç¤ºè©:",
    type=["txt"],
    key="prompt_file_uploader"
)

if uploaded_prompt_file is not None:
    prompt_content = uploaded_prompt_file.read().decode("utf-8")
    st.session_state.main_gemini_prompt = prompt_content
    # The text_area will update automatically on the next Streamlit rerun
    # because its value is bound to st.session_state.main_gemini_prompt.
    # For immediate visual feedback if desired, one could add:
    # st.sidebar.success("æç¤ºè©å·²å¾æª”æ¡ˆè¼‰å…¥ï¼")
    # However, this might be slightly redundant if the text_area updates promptly.

st.sidebar.header("ğŸ§¹ å¿«å–ç®¡ç†")
st.sidebar.caption("ç®¡ç†æ‡‰ç”¨ç¨‹å¼çš„æ•¸æ“šå¿«å–ã€‚")

if st.sidebar.button("æ¸…é™¤æ‰€æœ‰æ•¸æ“šå¿«å–", key="clear_all_cache_button"):
    st.cache_data.clear()
    st.sidebar.success("æ‰€æœ‰æ•¸æ“šå¿«å–å·²æˆåŠŸæ¸…é™¤ï¼ä¸‹æ¬¡ç²å–æ•¸æ“šæ™‚å°‡å¾æºé ­é‡æ–°è¼‰å…¥ã€‚")
st.sidebar.caption("é»æ“Šæ­¤æŒ‰éˆ•å°‡æ¸…é™¤æ‰€æœ‰å·²å¿«å–çš„ yfinance, FRED åŠ NY Fed æ•¸æ“šã€‚")

st.sidebar.header("ğŸ§  Gemini å…§å®¹å¿«å–")
st.session_state.cache_display_name_input = st.sidebar.text_input(
    "è¦å¿«å–çš„å…§å®¹åç¨± (ä¾‹å¦‚ system_prompt_cache):",
    value=st.session_state.get("cache_display_name_input", "system_prompt_main"), # Provide default
    key="cache_display_name_input_widget"
)
st.session_state.cache_content_input = st.sidebar.text_area(
    "è¦å¿«å–çš„å…§å®¹ (é€šå¸¸æ˜¯ System Prompt):",
    value=st.session_state.get("cache_content_input", st.session_state.get("main_gemini_prompt","")), # Default to main prompt
    height=150,
    key="cache_content_input_widget"
)
st.session_state.cache_ttl_seconds_input = st.sidebar.number_input(
    "å¿«å– TTL (ç§’, e.g., 3600 for 1 hour):",
    min_value=60,
    value=st.session_state.get("cache_ttl_seconds_input",3600),
    key="cache_ttl_input_widget"
)

if st.sidebar.button("å‰µå»º/æ›´æ–°å…§å®¹å¿«å–", key="create_cache_button"):
    gemini_keys_for_cache = [
        st.session_state.get("gemini_api_key_1",""),
        st.session_state.get("gemini_api_key_2",""),
        st.session_state.get("gemini_api_key_3","")
    ]
    valid_gemini_key_for_cache = next((key for key in gemini_keys_for_cache if key), None)
    selected_model_for_cache = st.session_state.get("selected_model_name", "gemini-1.0-pro") # Default if not set

    if valid_gemini_key_for_cache and st.session_state.cache_display_name_input and st.session_state.cache_content_input:
        try:
            genai.configure(api_key=valid_gemini_key_for_cache) # Configure for CachingClient or direct calls
            ttl_str = f"{st.session_state.cache_ttl_seconds_input}s"
            # Ensure model name is in "models/model-name" format for caching
            model_for_caching_api = f"models/{selected_model_for_cache}" if not selected_model_for_cache.startswith("models/") else selected_model_for_cache

            cached_content = genai.create_cached_content(
                model=model_for_caching_api,
                display_name=st.session_state.cache_display_name_input,
                system_instruction=st.session_state.cache_content_input, # Using system_instruction for content
                ttl=ttl_str
            )
            st.sidebar.success(f"å¿«å– '{cached_content.display_name}' å·²å‰µå»º/æ›´æ–°ã€‚\nåç¨±: {cached_content.name}")
            # Refresh cache list after creation
            st.session_state.gemini_caches_list = list(genai.list_cached_contents(api_key=valid_gemini_key_for_cache))
        except Exception as e:
            st.sidebar.error(f"å‰µå»ºå¿«å–å¤±æ•—: {str(e)}")
    else:
        st.sidebar.warning("è«‹æä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€å¿«å–åç¨±å’Œå¿«å–å…§å®¹ã€‚")

if st.sidebar.button("åˆ—å‡ºå¯ç”¨å¿«å–", key="list_caches_button"):
    gemini_keys_for_cache_list = [
        st.session_state.get("gemini_api_key_1",""),
        st.session_state.get("gemini_api_key_2",""),
        st.session_state.get("gemini_api_key_3","")
    ]
    valid_gemini_key_for_cache_list = next((key for key in gemini_keys_for_cache_list if key), None)
    if valid_gemini_key_for_cache_list:
        try:
            genai.configure(api_key=valid_gemini_key_for_cache_list)
            st.session_state.gemini_caches_list = list(genai.list_cached_contents())
            if not st.session_state.gemini_caches_list:
                st.sidebar.info("ç›®å‰æ²’æœ‰å¯ç”¨çš„å…§å®¹å¿«å–ã€‚")
        except Exception as e:
            st.sidebar.error(f"åˆ—å‡ºå¿«å–å¤±æ•—: {str(e)}")
            st.session_state.gemini_caches_list = [] # Clear on error
    else:
        st.sidebar.warning("è«‹å…ˆè¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆ—å‡ºå¿«å–ã€‚")


if st.session_state.gemini_caches_list:
    cache_options = {"(ä¸ä½¿ç”¨å¿«å–)": None}
    cache_options.update({f"{c.display_name} ({c.name.split('/')[-1][:8]}...)": c.name for c in st.session_state.gemini_caches_list})

    # Find current index for selectbox
    current_selected_cache_name = st.session_state.get("selected_cache_for_generation", None)
    options_list = list(cache_options.values())
    try:
        current_index = options_list.index(current_selected_cache_name)
    except ValueError:
        current_index = 0 # Default to "(ä¸ä½¿ç”¨å¿«å–)"

    selected_display_key = st.sidebar.selectbox(
        "é¸æ“‡ä¸€å€‹å¿«å–ç”¨æ–¼ä¸‹æ¬¡ç”Ÿæˆ:",
        options=list(cache_options.keys()),
        index=current_index, # Use the found index
        key="select_cache_dropdown"
    )
    st.session_state.selected_cache_for_generation = cache_options.get(selected_display_key)

st.session_state.cache_name_to_delete_input = st.sidebar.text_input(
    "è¦åˆªé™¤çš„å¿«å–åç¨± (projects/.../cachedContents/...):",
    value=st.session_state.get("cache_name_to_delete_input",""),
    key="cache_name_to_delete_input_widget"
)
if st.sidebar.button("åˆªé™¤æŒ‡å®šå¿«å–", key="delete_cache_button"):
    cache_to_delete = st.session_state.cache_name_to_delete_input
    if cache_to_delete:
        gemini_keys_for_delete = [
            st.session_state.get("gemini_api_key_1",""),
            st.session_state.get("gemini_api_key_2",""),
            st.session_state.get("gemini_api_key_3","")
        ]
        valid_gemini_key_for_delete = next((key for key in gemini_keys_for_delete if key), None)
        if valid_gemini_key_for_delete:
            try:
                genai.configure(api_key=valid_gemini_key_for_delete)
                genai.delete_cached_content(name=cache_to_delete)
                st.sidebar.success(f"å¿«å– {cache_to_delete} å·²æˆåŠŸåˆªé™¤ã€‚")
                # Refresh cache list
                st.session_state.gemini_caches_list = list(genai.list_cached_contents())
                if st.session_state.selected_cache_for_generation == cache_to_delete:
                    st.session_state.selected_cache_for_generation = None # Reset if deleted cache was selected
            except Exception as e:
                st.sidebar.error(f"åˆªé™¤å¿«å– {cache_to_delete} å¤±æ•—: {str(e)}")
        else:
            st.sidebar.warning("è«‹è¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆªé™¤å¿«å–ã€‚")
    else:
        st.sidebar.warning("è«‹è¼¸å…¥è¦åˆªé™¤çš„å¿«å–åç¨±ã€‚")

# Main page
st.title("é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç†")

st.header("ğŸ“„ æ­¥é©Ÿä¸€ï¼šä¸Šå‚³èˆ‡æª¢è¦–æ–‡ä»¶")
st.caption("è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆã€‚")

# File Uploader
uploaded_files_from_widget = st.file_uploader(
    "è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆ (å¯å¤šé¸ .txt):",
    type=["txt"],
    accept_multiple_files=True,
    key="file_uploader_widget"
)

# Process and store uploaded files
if uploaded_files_from_widget:
    st.session_state.uploaded_files_list = uploaded_files_from_widget
    st.session_state.uploaded_file_contents = {} # Clear old contents
    for file in st.session_state.uploaded_files_list:
        try:
            content = file.read().decode("utf-8")
            st.session_state.uploaded_file_contents[file.name] = content
        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆ {file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    if st.session_state.uploaded_file_contents: # Check if any file was successfully read
        st.success(f"æˆåŠŸä¸Šå‚³ä¸¦è®€å– {len(st.session_state.uploaded_file_contents)} å€‹æª”æ¡ˆã€‚")

# Display uploaded file information and previews
if st.session_state.uploaded_files_list:
    st.subheader("å·²ä¸Šå‚³æ–‡ä»¶é è¦½:")
    if not st.session_state.uploaded_file_contents and uploaded_files_from_widget:
        # This case can happen if all files failed to read in the block above
        st.warning("æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆéƒ½ç„¡æ³•æˆåŠŸè®€å–å…§å®¹ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å…§å®¹ã€‚")
    elif not st.session_state.uploaded_file_contents and not uploaded_files_from_widget:
        # This case implies files were in session_state.uploaded_files_list from a previous run,
        # but their contents were cleared, or uploader is now empty. This should ideally not be hit
        # if logic is correct, but acts as a fallback.
        st.info("ä¹‹å‰ä¸Šå‚³çš„æª”æ¡ˆå…§å®¹å·²æ¸…é™¤æˆ–ç›®å‰æ²’æœ‰é¸æ“‡æª”æ¡ˆã€‚è«‹é‡æ–°ä¸Šå‚³ã€‚")

    for file_name, content in st.session_state.uploaded_file_contents.items():
        with st.expander(f"æª”å: {file_name} (é»æ“Šå±•é–‹/æ”¶èµ·é è¦½)", expanded=False):
            st.text(content[:500] + "..." if len(content) > 500 else content)
elif not uploaded_files_from_widget: # Only show this if the uploader is also empty in the current run
    st.info("è«‹ä¸Šå‚³æ–‡å­—æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")


st.header("ğŸ“Š æ­¥é©ŸäºŒï¼šå¼•å…¥å¤–éƒ¨æ•¸æ“š (å¯é¸)")
# st.caption("é¸æ“‡ä¸¦è¼‰å…¥ yfinance, FRED, NY Fed ç­‰å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šã€‚") # Caption is part of expander now

with st.expander("ğŸ“Š æ­¥é©ŸäºŒï¼šé¸æ“‡ä¸¦è¼‰å…¥å¤–éƒ¨æ•¸æ“š (é»æ“Šå±•é–‹/æ”¶èµ·)", expanded=False):
    st.caption("é¸æ“‡ yfinance, FRED, NY Fed ç­‰å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæºï¼Œè¨­å®šåƒæ•¸ä¸¦è¼‰å…¥æ•¸æ“šã€‚")

    # --- Row 1: Select All & Data Source Checkboxes ---
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        select_all_sources_widget = st.checkbox(
            "ğŸŒ å…¨é¸/å–æ¶ˆæ‰€æœ‰æ•¸æ“šæº",
            value=st.session_state.select_all_sources,
            key="select_all_sources_cb"
        )
        if select_all_sources_widget != st.session_state.select_all_sources:
            st.session_state.select_all_sources = select_all_sources_widget
            st.session_state.select_yfinance = select_all_sources_widget
            st.session_state.select_fred = select_all_sources_widget
            st.session_state.select_ny_fed = select_all_sources_widget
            st.experimental_rerun()
    with col2:
        st.session_state.select_yfinance = st.checkbox(
            "ğŸ“ˆ yfinance è‚¡å¸‚æ•¸æ“š",
            value=st.session_state.select_yfinance,
            key="select_yfinance_cb" # Give a key to ensure it's treated as a separate widget
        )
    with col3:
        st.session_state.select_fred = st.checkbox(
            "ğŸ¦ FRED ç¸½ç¶“æ•¸æ“š",
            value=st.session_state.select_fred,
            key="select_fred_cb"
        )
    with col4:
        st.session_state.select_ny_fed = st.checkbox(
            "ğŸ‡ºğŸ‡¸ NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š",
            value=st.session_state.select_ny_fed,
            key="select_ny_fed_cb"
        )

    # --- Row 2: Date Inputs ---
    date_col1, date_col2 = st.columns(2)
    with date_col1:
        st.session_state.data_start_date = st.text_input(
            "è¼¸å…¥é–‹å§‹æ—¥æœŸ (YYYYMMDD):",
            value=st.session_state.data_start_date,
            key="data_start_date_input"
        )
    with date_col2:
        st.session_state.data_end_date = st.text_input(
            "è¼¸å…¥çµæŸæ—¥æœŸ (YYYYMMDD):",
            value=st.session_state.data_end_date,
            key="data_end_date_input"
        )

    # --- Row 3: Conditional Inputs for yfinance and FRED ---
    param_col1, param_col2 = st.columns(2)
    with param_col1:
        if st.session_state.select_yfinance:
            st.session_state.yfinance_tickers = st.text_input(
                "yfinance è‚¡ç¥¨ä»£ç¢¼ (é€—è™Ÿåˆ†éš”):",
                value=st.session_state.yfinance_tickers,
                key="yfinance_tickers_input"
            )
            interval_options = {"æ¯æ—¥": "1d", "æ¯é€±": "1wk", "æ¯å°æ™‚": "1h", "æ¯5åˆ†é˜": "5m"}
            # Ensure the current session state value is a valid option for index()
            current_interval_label = st.session_state.yfinance_interval_label
            if current_interval_label not in interval_options: # Fallback if label is somehow invalid
                current_interval_label = list(interval_options.keys())[0]
                st.session_state.yfinance_interval_label = current_interval_label

            st.session_state.yfinance_interval_label = st.selectbox(
                "yfinance æ•¸æ“šé€±æœŸ:",
                options=list(interval_options.keys()),
                index=list(interval_options.keys()).index(current_interval_label),
                key="yfinance_interval_label_select"
            )
    with param_col2:
        if st.session_state.select_fred:
            st.session_state.fred_series_ids = st.text_input(
                "FRED Series ID (é€—è™Ÿåˆ†éš”):",
                value=st.session_state.fred_series_ids,
                key="fred_series_ids_input"
            )

    st.markdown("---") # Visual separator

    # --- Row 4: Fetch Data Button ---
    # Using st.session_state.fetch_data_button_clicked to control display of "no data" message
    if st.button("ğŸ” ç²å–ä¸¦é è¦½é¸å®šæ•¸æ“š", key="fetch_data_button"):
        st.session_state.fetch_data_button_clicked = True
        st.session_state.fetched_data_preview = {}
        st.session_state.fetch_errors = []

        something_selected = (st.session_state.select_yfinance or
                              st.session_state.select_fred or
                              st.session_state.select_ny_fed)

        if not something_selected:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ•¸æ“šæºã€‚")
            st.session_state.fetch_data_button_clicked = False
        else:
            with st.spinner("æ­£åœ¨ç²å–æ•¸æ“šï¼Œè«‹ç¨å€™..."):
                if st.session_state.select_yfinance:
                    actual_interval = interval_options[st.session_state.yfinance_interval_label]
                    yfinance_data, yfinance_errs = fetch_yfinance_data(
                        st.session_state.yfinance_tickers,
                        st.session_state.data_start_date,
                        st.session_state.data_end_date,
                        actual_interval
                    )
                    if yfinance_data:
                        st.session_state.fetched_data_preview["yfinance"] = yfinance_data
                    if yfinance_errs:
                        st.session_state.fetch_errors.extend([f"[yfinance] {e}" for e in yfinance_errs])

                if st.session_state.select_fred:
                    fred_api_key = st.session_state.get("fred_api_key", "")
                    if not fred_api_key:
                         st.session_state.fetch_errors.append("[FRED] éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªåœ¨å´é‚Šæ¬„è¨­å®šã€‚è«‹å…ˆè¨­å®šã€‚")
                    else:
                        fred_data, fred_errs = fetch_fred_data(
                            st.session_state.fred_series_ids,
                            st.session_state.data_start_date,
                            st.session_state.data_end_date,
                            fred_api_key
                        )
                        if fred_data:
                            st.session_state.fetched_data_preview["fred"] = fred_data
                        if fred_errs:
                            st.session_state.fetch_errors.extend([f"[FRED] {e}" for e in fred_errs])

                if st.session_state.select_ny_fed:
                    ny_fed_data, ny_fed_errs = fetch_ny_fed_data()
                    if ny_fed_data is not None:
                        st.session_state.fetched_data_preview["ny_fed"] = ny_fed_data
                    if ny_fed_errs:
                        st.session_state.fetch_errors.extend([f"[NY Fed] {e}" for e in ny_fed_errs])

    # --- Data Preview Area (Conditional Display) ---
    if st.session_state.fetch_errors: # Ensure errors are always displayed if they exist
        st.subheader("æ•¸æ“šç²å–éŒ¯èª¤ï¼š")
        for err_msg in st.session_state.fetch_errors: # Iterate through messages
            st.error(err_msg) # Display each error message

    if st.session_state.fetched_data_preview:
        st.subheader("å·²ç²å–æ•¸æ“šé è¦½:")
        if "yfinance" in st.session_state.fetched_data_preview:
            st.markdown("#### yfinance æ•¸æ“š:")
            for ticker, df_yf in st.session_state.fetched_data_preview["yfinance"].items():
                with st.expander(f"Ticker: {ticker} (å…± {len(df_yf)} è¡Œ)", expanded=False):
                    st.dataframe(df_yf.head())

        if "fred" in st.session_state.fetched_data_preview:
            st.markdown("#### FRED æ•¸æ“š:")
            for series_id, df_fred in st.session_state.fetched_data_preview["fred"].items():
                with st.expander(f"Series ID: {series_id} (å…± {len(df_fred)} è¡Œ)", expanded=False):
                    st.dataframe(df_fred.head())

        if "ny_fed" in st.session_state.fetched_data_preview:
            df_ny = st.session_state.fetched_data_preview["ny_fed"]
            if not df_ny.empty:
                st.markdown("#### NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š:")
                with st.expander(f"NY Fed ç¸½æŒæœ‰é‡ (å…± {len(df_ny)} è¡Œ)", expanded=False):
                    st.dataframe(df_ny.head())

        has_data_in_preview = any(
            (isinstance(data_source, dict) and data_source) or
            (isinstance(data_source, pd.DataFrame) and not data_source.empty)
            for data_source in st.session_state.fetched_data_preview.values()
        )

        if has_data_in_preview and not st.session_state.fetch_errors:
             st.success("æ•¸æ“šå·²æˆåŠŸè¼‰å…¥ä¸¦æº–å‚™å¥½ç”¨æ–¼åˆ†æã€‚")
        elif not has_data_in_preview and not st.session_state.fetch_errors and st.session_state.fetch_data_button_clicked :
             st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")

    elif st.session_state.fetch_data_button_clicked and not st.session_state.fetch_errors:
        st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")


st.header("ğŸ’¬ æ­¥é©Ÿä¸‰ï¼šèˆ‡ Gemini é€²è¡Œåˆ†æèˆ‡è¨è«–")

# Chat history display
chat_container = st.container(height=400)
with chat_container:
    for message in st.session_state.chat_history:
        avatar_icon = "ğŸ‘¤" if message["role"] == "user" else "âœ¨" # User: ğŸ‘¤, Model: âœ¨ (or ğŸ¤–)
        with st.chat_message(message["role"], avatar=avatar_icon):
            if message["role"] == "model" and message.get("is_error", False): # Check for error flag
                st.error(message["parts"][0])
            else:
                st.markdown(message["parts"][0])

# User input
user_input = st.chat_input("å‘ Gemini æå•æˆ–çµ¦å‡ºæŒ‡ä»¤ï¼š", key="gemini_user_input")

if user_input:
    st.session_state.chat_history.append({"role": "user", "parts": [user_input]})

    with st.spinner("Gemini æ­£åœ¨æ€è€ƒä¸­ï¼Œè«‹ç¨å€™..."):
        model_response_text = ""
        is_error_response = False
        try:
            # Prepare prompt parts for Gemini
            full_prompt_parts = []
            if st.session_state.get("main_gemini_prompt"):
                full_prompt_parts.append(f"**ä¸»è¦æŒ‡ç¤º (System Prompt):**\n{st.session_state.main_gemini_prompt}\n\n---\n")

            uploaded_texts_str = ""
            if st.session_state.get("uploaded_file_contents"):
                uploaded_texts_str += "**å·²ä¸Šå‚³æ–‡ä»¶å…§å®¹æ‘˜è¦:**\n"
                for file_name, content in st.session_state.uploaded_file_contents.items():
                    uploaded_texts_str += f"æª”å: {file_name}\nå…§å®¹ç‰‡æ®µ:\n{content[:1000]}...\n\n"
                full_prompt_parts.append(uploaded_texts_str + "---\n")

            external_data_str = ""
            if st.session_state.get("fetched_data_preview"):
                external_data_str += "**å·²å¼•å…¥çš„å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæ‘˜è¦:**\n"
                for source, data_items in st.session_state.fetched_data_preview.items():
                    external_data_str += f"\nä¾†æº: {source.upper()}\n"
                    if source == "yfinance" or source == "fred":
                        if isinstance(data_items, dict):
                            for item_name, df_item in data_items.items():
                                if isinstance(df_item, pd.DataFrame):
                                    external_data_str += f"  {item_name} (æœ€è¿‘å¹¾ç­†):\n{df_item.tail(3).to_string()}\n"
                    elif source == "ny_fed" and isinstance(data_items, pd.DataFrame) and not data_items.empty:
                         external_data_str += f"  NY Fed ç¸½æŒæœ‰é‡ (æœ€è¿‘å¹¾ç­†):\n{data_items.tail(3).to_string()}\n"
                full_prompt_parts.append(external_data_str + "---\n")

            full_prompt_parts.append(f"**ä½¿ç”¨è€…ç•¶å‰å•é¡Œ/æŒ‡ä»¤:**\n{user_input}")

            gemini_api_keys_raw = [
                st.session_state.get("gemini_api_key_1", ""),
                st.session_state.get("gemini_api_key_2", ""),
                st.session_state.get("gemini_api_key_3", "")
            ]
            valid_gemini_api_keys = [key for key in gemini_api_keys_raw if key and key.strip()]

            selected_model_name = st.session_state.get("selected_model_name", "gemini-1.0-pro")
            global_rpm_limit = st.session_state.get("global_rpm_limit", 5)
            global_tpm_limit = st.session_state.get("global_tpm_limit", 200000)

            generation_config = {
                "temperature": 0.7, "top_p": 1.0, "top_k": 32, "max_output_tokens": 8192,
            }
            selected_cache_name_for_api = st.session_state.get("selected_cache_for_generation", None)

            if not valid_gemini_api_keys:
                model_response_text = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„è¨­å®šè‡³å°‘ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚"
                is_error_response = True
            elif not selected_model_name:
                model_response_text = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹ Gemini æ¨¡å‹ã€‚"
                is_error_response = True
            else:
                model_response_text = call_gemini_api(
                    prompt_parts=full_prompt_parts,
                    api_keys_list=valid_gemini_api_keys,
                    selected_model=selected_model_name,
                    global_rpm=global_rpm_limit,
                    global_tpm=global_tpm_limit,
                    generation_config_dict=generation_config,
                    cached_content_name=selected_cache_name_for_api
                )
                if model_response_text.startswith("éŒ¯èª¤ï¼š"):
                    is_error_response = True

        except Exception as e: # Catch any unexpected error during prompt assembly or pre-API call logic
            model_response_text = f"è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š {str(e)}"
            is_error_response = True

        st.session_state.chat_history.append({"role": "model", "parts": [model_response_text], "is_error": is_error_response})
        st.experimental_rerun()

# --- This div closure MUST be the VERY LAST THING in your app.py script ---
st.markdown("</div>", unsafe_allow_html=True)
