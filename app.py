import streamlit as st
import pandas as pd
import os
import yfinance as yf
from datetime import datetime, timedelta
from fredapi import Fred
import requests
import io
import google.generativeai as genai
import google.api_core.exceptions
import time
import traceback
import logging
import sys

# --- Basic Logging Configuration ---
logging.basicConfig(
    level=logging.DEBUG, # Changed from INFO to DEBUG
    format='%(asctime)s - %(levelname)s - [%(name)s:%(funcName)s:%(lineno)d] - %(message)s',
    stream=sys.stderr
)

# --- Custom Streamlit Log Handler ---
class StreamlitLogHandler(logging.Handler):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.logs = []

    def emit(self, record):
        self.logs.append(self.format(record))

    def get_logs(self):
        return self.logs

    def clear_logs(self):
        self.logs = []

# --- Instantiate and Add StreamlitLogHandler to Root Logger ---
if 'log_handler' not in st.session_state:
    log_handler = StreamlitLogHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(name)s:%(funcName)s:%(lineno)d] - %(message)s')
    log_handler.setFormatter(formatter)

    root_logger = logging.getLogger()
    root_logger.addHandler(log_handler)
    st.session_state.log_handler = log_handler
    logging.info("StreamlitLogHandler added to root logger and stored in session state.")

# Set page config - MUST be the first Streamlit command
st.set_page_config(
    page_title="é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç† (ç”± Gemini é©…å‹•)",
    layout="wide"
)

def main_app_logic():
    logger = logging.getLogger(__name__)
    logger.debug("Entering main_app_logic")

    # API Key Definitions (needed for initialization and validation)
    api_keys_info = {
        "gemini_api_key_1": "Gemini API Key 1",
        "gemini_api_key_2": "Gemini API Key 2",
        "gemini_api_key_3": "Gemini API Key 3",
        "fred_api_key": "FRED API Key",
        "alpha_vantage_api_key": "Alpha Vantage API Key",
        "api_key_fmpnb": "Financial Modeling Prep API Key",
        "api_key_finnhub": "Finnhub API Key",
        "api_key_figi": "OpenFigi API Key",
        "api_key_iex": "IEX Cloud API Key",
        "api_key_polygon": "Polygon API Key",
        "deepseek_api_key": "DeepSeek API Key",
    }

    # Initialize session state for API keys if not already done
    if 'initialized_keys' not in st.session_state:
        logger.info("Initializing API keys in session state from secrets.")
        for key_name_snake_case in api_keys_info.keys():
            secret_key_name = key_name_snake_case.upper()
            value = st.secrets.get(secret_key_name, "")
            st.session_state[key_name_snake_case] = value
            logger.debug(f"Initializing session_state.{key_name_snake_case} from secrets (length: {len(value)>0})")
        st.session_state.initialized_keys = True
        logger.debug("Initializing session_state.initialized_keys = True")

    # --- Helper function to check for valid Gemini API keys ---
    def are_gemini_keys_valid():
        logger.debug("Entering are_gemini_keys_valid")
        for i in range(1, 4):  # Check gemini_api_key_1, _2, _3
            key_name = f"gemini_api_key_{i}"
            logger.debug(f"Checking Gemini API key: {key_name}")
            key_value = st.session_state.get(key_name, "")
            if key_value and key_value.strip():
                logger.debug(f"Gemini key {key_name} is valid.")
                logger.info(f"Found valid Gemini API key: {key_name}")
                logger.debug("Exiting are_gemini_keys_valid (found valid key)")
                return True
            else:
                logger.debug(f"Gemini key {key_name} is empty or whitespace.")
        logger.warning("No valid Gemini API keys found in session state.")
        logger.debug("Exiting are_gemini_keys_valid (no valid key found)")
        return False

    # --- Perform API Key Check and Display Guidance ---
    if not are_gemini_keys_valid():
        # This message will appear on the main page if keys are missing
        st.warning(
            "âš ï¸ **æ ¸å¿ƒåŠŸèƒ½éœ€è¦ Gemini API é‡‘é‘°**\n\n"
            "æ­¤æ‡‰ç”¨ç¨‹å¼çš„æ ¸å¿ƒåˆ†æåŠŸèƒ½ç”± Google Gemini æä¾›æŠ€è¡“æ”¯æ´ã€‚è«‹åœ¨å·¦å´é‚Šæ¬„è¨­å®šæ‚¨çš„ Gemini API é‡‘é‘°ä»¥å•Ÿç”¨å®Œæ•´åŠŸèƒ½ã€‚\n\n"
            "å¦‚æœæ‚¨é‚„æ²’æœ‰é‡‘é‘°ï¼Œå¯ä»¥é»æ“Šä»¥ä¸‹é€£çµç²å–ï¼š "
            "[é»æ­¤ç²å– Gemini API é‡‘é‘°](https://aistudio.google.com/app/apikey)",
            icon="ğŸ”‘"
        )
        with st.expander("ğŸ”§ å¦‚ä½•è¨­å®š API é‡‘é‘°ï¼Ÿ(ä¸­æ–‡æ•™å­¸)", expanded=True):
            st.markdown("""
                ### å¦‚ä½•è¨­å®šåŠä½¿ç”¨ API é‡‘é‘°ï¼š

                1.  **ç²å–é‡‘é‘°**ï¼š
                    *   å‰å¾€ [Google AI Studio](https://aistudio.google.com/app/apikey) ç¶²ç«™ã€‚
                    *   ç™»å…¥æ‚¨çš„ Google å¸³æˆ¶ã€‚
                    *   é»æ“Š "Create API key in new project" æˆ–é¡ä¼¼æŒ‰éˆ•ä¾†å‰µå»ºä¸€å€‹æ–°çš„ API é‡‘é‘°ã€‚
                    *   è¤‡è£½æ‚¨ç²å¾—çš„ API é‡‘é‘°å­—ä¸²ã€‚

                2.  **åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­è¨­å®š**ï¼š
                    *   åœ¨æœ¬æ‡‰ç”¨ç¨‹å¼çš„å·¦å´é‚Šæ¬„æ‰¾åˆ°ã€ŒğŸ”‘ API é‡‘é‘°ç®¡ç†ã€éƒ¨åˆ†ã€‚
                    *   å°‡æ‚¨è¤‡è£½çš„ API é‡‘é‘°è²¼åˆ° "Gemini API Key 1", "Gemini API Key 2", æˆ– "Gemini API Key 3" ä»»ä¸€è¼¸å…¥æ¡†ä¸­ã€‚
                    *   è‡³å°‘éœ€è¦è¨­å®šä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚
                    *   ï¼ˆå¯é¸ï¼‰æ‚¨ä¹Ÿå¯ä»¥åœ¨æ­¤è™•è¨­å®š FRED API é‡‘é‘°ç­‰å…¶ä»–é‡‘é‘°ã€‚

                3.  **é–‹å§‹ä½¿ç”¨**ï¼š
                    *   é‡‘é‘°è¨­å®šå®Œæˆå¾Œï¼Œæ‡‰ç”¨ç¨‹å¼çš„ Gemini åˆ†æåŠŸèƒ½å³å¯ä½¿ç”¨ã€‚

                **é‡è¦æç¤º**ï¼šè«‹å¦¥å–„ä¿ç®¡æ‚¨çš„ API é‡‘é‘°ï¼Œä¸è¦åˆ†äº«çµ¦ä»–äººæˆ–åœ¨å…¬é–‹çš„ç¨‹å¼ç¢¼ä¸­æ´©æ¼ã€‚
            """)
        logger.info("API key guidance displayed on the main page.")

    # --- Function to load custom CSS ---
    def load_custom_css():
        logger.debug("Entering load_custom_css")
        try:
            with open("style.css", "r", encoding="utf-8") as f:
                css_content = f.read()
            st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
            logger.debug("Successfully loaded and applied style.css")
        except FileNotFoundError:
            logger.warning("style.css æª”æ¡ˆæœªæ‰¾åˆ°ã€‚å°‡ä½¿ç”¨é è¨­æ¨£å¼ã€‚")
            st.warning("è­¦å‘Šï¼šstyle.css æª”æ¡ˆæœªæ‰¾åˆ°ã€‚å°‡ä½¿ç”¨é è¨­æ¨£å¼ã€‚")
        except Exception as e:
            logger.error(f"è¼‰å…¥è‡ªè¨‚ CSS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            st.error(f"è¼‰å…¥è‡ªè¨‚ CSS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.debug("Exiting load_custom_css")

    # --- Load CSS and Apply Theme Wrapper ---
    load_custom_css()

    # Apply a global div with the theme class.
    # Ensure active_theme is initialized before this line if it's used.
    # It's initialized later, so using .get with a default is safe.
    st.markdown(f"<div class='theme-{st.session_state.get('active_theme', 'dark')}'>", unsafe_allow_html=True)

    # --- Inject Dynamic Font Size CSS ---
    font_size_css_map = {
        "å°": "0.875rem",
        "ä¸­": "1rem",
        "å¤§": "1.125rem"
    }
    selected_font_size_value = font_size_css_map.get(st.session_state.get("font_size_name", "ä¸­"), "1rem")
    font_override_style = f"""
<style>
html {{ font-size: {selected_font_size_value} !important; }}
</style>
"""
    st.markdown(font_override_style, unsafe_allow_html=True)

    # Gemini Model Definitions
    available_models = ["gemini-1.5-flash-latest", "gemini-1.5-pro-latest", "gemini-1.0-pro"]
    if 'initialized_model_settings' not in st.session_state:
        logger.debug("Initializing model settings in session state.")
        st.session_state.selected_model_name = available_models[0]
        logger.debug(f"Initializing session_state.selected_model_name = {available_models[0]}")
        st.session_state.global_rpm_limit = 5
        logger.debug(f"Initializing session_state.global_rpm_limit = 5")
        st.session_state.global_tpm_limit = 200000
        logger.debug(f"Initializing session_state.global_tpm_limit = 200000")
        st.session_state.initialized_model_settings = True
        logger.debug("Initializing session_state.initialized_model_settings = True")

    DEFAULT_MAIN_GEMINI_PROMPT = """è«‹ä½ åˆ†ææˆ‘æä¾›çš„æ‰€æœ‰æ–‡å­—æª”ã€‚
ä½ çš„ä»»å‹™æ˜¯æ•´ç†é€™äº›æª”æ¡ˆä¸­åŒ…å«çš„ç¤¾ç¾¤åª’é«”è²¼æ–‡ã€‚
è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºå‘ˆç¾çµæœï¼š
1.  **ä¾†æºè­˜åˆ¥**ï¼šç¢ºèªæ¯å€‹è²¼æ–‡çš„åŸå§‹æª”æ¡ˆåç¨±ã€‚
2.  **å…§å®¹æ‘˜è¦**ï¼šå°æ¯å€‹è²¼æ–‡é€²è¡Œç°¡æ½”æ‘˜è¦ã€‚
3.  **æƒ…ç·’åˆ†æ**ï¼šåˆ¤æ–·æ¯å€‹è²¼æ–‡è¡¨é”çš„æƒ…ç·’ï¼ˆä¾‹å¦‚ï¼Œæ­£é¢ã€è² é¢ã€ä¸­æ€§ï¼‰ã€‚
4.  **é—œéµä¸»é¡Œ**ï¼šæå–æ¯å€‹è²¼æ–‡è¨è«–çš„æ ¸å¿ƒä¸»é¡Œã€‚
5.  **å»ºè­°è¡Œå‹•**ï¼šå¦‚æœè²¼æ–‡æš—ç¤ºäº†æŸç¨®è¡Œå‹•æˆ–å»ºè­°ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
è«‹ç¢ºä¿æœ€çµ‚è¼¸å‡ºçµæœåš´æ ¼éµå¾ªä¸Šè¿°æ‰€æœ‰æŒ‡ç¤ºã€‚"""
    if 'initialized_prompt_settings' not in st.session_state:
        logger.debug("Initializing prompt settings in session state.")
        st.session_state.main_gemini_prompt = DEFAULT_MAIN_GEMINI_PROMPT
        logger.debug(f"Initializing session_state.main_gemini_prompt with default prompt (length: {len(DEFAULT_MAIN_GEMINI_PROMPT)}).")
        st.session_state.initialized_prompt_settings = True
        logger.debug("Initializing session_state.initialized_prompt_settings = True")

    if 'initialized_file_upload_settings' not in st.session_state:
        logger.debug("Initializing file upload settings in session state.")
        st.session_state.uploaded_files_list = []
        logger.debug("Initializing session_state.uploaded_files_list = []")
        st.session_state.uploaded_file_contents = {}
        logger.debug("Initializing session_state.uploaded_file_contents = {}")
        st.session_state.initialized_file_upload_settings = True
        logger.debug("Initializing session_state.initialized_file_upload_settings = True")

    if 'initialized_data_source_settings' not in st.session_state:
        logger.debug("Initializing data source settings in session state.")
        st.session_state.select_yfinance = False
        logger.debug("Initializing session_state.select_yfinance = False")
        st.session_state.select_fred = False
        logger.debug("Initializing session_state.select_fred = False")
        st.session_state.select_ny_fed = False
        logger.debug("Initializing session_state.select_ny_fed = False")
        st.session_state.select_all_sources = False
        logger.debug("Initializing session_state.select_all_sources = False")
        st.session_state.data_start_date = "20230101"
        logger.debug("Initializing session_state.data_start_date = \"20230101\"")
        st.session_state.data_end_date = datetime.now().strftime("%Y%m%d")
        logger.debug(f"Initializing session_state.data_end_date = {st.session_state.data_end_date}")
        st.session_state.yfinance_tickers = "AAPL,^MOVE"
        logger.debug("Initializing session_state.yfinance_tickers = \"AAPL,^MOVE\"")
        st.session_state.yfinance_interval_label = "æ¯æ—¥"
        logger.debug("Initializing session_state.yfinance_interval_label = \"æ¯æ—¥\"")
        st.session_state.fred_series_ids = "DGS10,VIXCLS"
        logger.debug("Initializing session_state.fred_series_ids = \"DGS10,VIXCLS\"")
        st.session_state.fetched_data_preview = {}
        logger.debug("Initializing session_state.fetched_data_preview = {}")
        st.session_state.fetch_errors = []
        logger.debug("Initializing session_state.fetch_errors = []")
        st.session_state.fetch_data_button_clicked = False
        logger.debug("Initializing session_state.fetch_data_button_clicked = False")
        st.session_state.initialized_data_source_settings = True
        logger.debug("Initializing session_state.initialized_data_source_settings = True")

    if 'initialized_gemini_interaction_settings' not in st.session_state:
        logger.debug("Initializing Gemini interaction settings in session state.")
        st.session_state.chat_history = []
        logger.debug("Initializing session_state.chat_history = []")
        st.session_state.active_gemini_key_index = 0
        logger.debug("Initializing session_state.active_gemini_key_index = 0")
        st.session_state.gemini_api_key_usage = {}
        logger.debug("Initializing session_state.gemini_api_key_usage = {}")
        st.session_state.gemini_caches_list = []
        logger.debug("Initializing session_state.gemini_caches_list = []")
        st.session_state.selected_cache_for_generation = None
        logger.debug("Initializing session_state.selected_cache_for_generation = None")
        st.session_state.initialized_gemini_interaction_settings = True
        logger.debug("Initializing session_state.initialized_gemini_interaction_settings = True")

    if 'initialized_theme_settings' not in st.session_state:
        logger.debug("Initializing theme settings in session state.")
        st.session_state.active_theme = "dark"
        logger.debug("Initializing session_state.active_theme = \"dark\"")
        st.session_state.initialized_theme_settings = True
        logger.debug("Initializing session_state.initialized_theme_settings = True")

    if 'initialized_font_settings' not in st.session_state:
        logger.debug("Initializing font settings in session state.")
        st.session_state.font_size_name = "ä¸­"
        logger.debug("Initializing session_state.font_size_name = \"ä¸­\"")
        st.session_state.initialized_font_settings = True
        logger.debug("Initializing session_state.initialized_font_settings = True")

    @st.cache_data(ttl=3600)
    def fetch_yfinance_data(tickers_str: str, start_date_str: str, end_date_str: str, interval: str):
        logger.debug(f"Entering fetch_yfinance_data with tickers: {tickers_str}, start: {start_date_str}, end: {end_date_str}, interval: {interval}")
        logger.info(f"Fetching yfinance data for tickers: {tickers_str}, interval: {interval}")
        data_frames = {}
        errors = []
        if not tickers_str.strip():
            msg = "Ticker å­—ä¸²ä¸å¯ç‚ºç©ºã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_yfinance_data (empty ticker string)")
            return data_frames, errors
        list_of_tickers = [ticker.strip().upper() for ticker in tickers_str.split(',') if ticker.strip()]
        if not list_of_tickers:
            msg = "æœªæä¾›æœ‰æ•ˆçš„ Tickerã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_yfinance_data (no valid tickers)")
            return data_frames, errors
        try:
            start_dt = datetime.strptime(start_date_str, "%Y%m%d")
        except ValueError:
            msg = f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug(f"Exiting fetch_yfinance_data (invalid start_date_str: {start_date_str})")
            return data_frames, errors
        try:
            end_dt = datetime.strptime(end_date_str, "%Y%m%d")
        except ValueError:
            msg = f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug(f"Exiting fetch_yfinance_data (invalid end_date_str: {end_date_str})")
            return data_frames, errors
        if start_dt > end_dt:
            msg = f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug(f"Exiting fetch_yfinance_data (start_dt > end_dt)")
            return data_frames, errors
        for ticker in list_of_tickers:
            logger.debug(f"Processing yfinance ticker: {ticker}")
            try:
                logger.info(f"Downloading yfinance data for {ticker}")
                df = yf.download(ticker, start=start_dt, end=end_dt, interval=interval, progress=False)
                if df.empty:
                    msg = f"Ticker {ticker}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    logger.debug(f"yfinance data for {ticker} is empty.")
                else:
                    df.reset_index(inplace=True)
                    df.columns = df.columns.astype(str)
                    data_frames[ticker] = df
                    logger.info(f"Successfully downloaded yfinance data for {ticker}")
                    logger.debug(f"yfinance data for {ticker} fetched successfully. Shape: {df.shape}")
            except Exception as e:
                msg = f"ä¸‹è¼‰ Ticker {ticker} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
                logger.debug(f"Error fetching yfinance data for {ticker}: {str(e)}")
        logger.debug(f"Exiting fetch_yfinance_data. Found {len(data_frames)} dataframes, {len(errors)} errors.")
        return data_frames, errors

    @st.cache_data(ttl=86400)
    def fetch_fred_data(series_ids_str: str, start_date_str: str, end_date_str: str, api_key: str):
        logger.debug(f"Entering fetch_fred_data with series_ids: {series_ids_str}, start: {start_date_str}, end: {end_date_str}, api_key_present: {bool(api_key)}")
        logger.info(f"Fetching FRED data for series: {series_ids_str}")
        data_series_dict = {}
        errors = []
        if not api_key:
            msg = "éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªæä¾›ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_fred_data (no API key)")
            return data_series_dict, errors
        try:
            logger.debug("Initializing Fred client.")
            fred = Fred(api_key=api_key)
            logger.debug("Fred client initialized successfully.")
        except Exception as e:
            msg = f"FRED API é‡‘é‘°åˆå§‹åŒ–å¤±æ•—: {str(e)}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°ã€‚"
            errors.append(msg)
            logger.error(msg, exc_info=True)
            logger.debug(f"Exiting fetch_fred_data (Fred client initialization failed: {str(e)})")
            return data_series_dict, errors
        if not series_ids_str.strip():
            msg = "Series ID å­—ä¸²ä¸å¯ç‚ºç©ºã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_fred_data (empty series_ids_str)")
            return data_series_dict, errors
        list_of_series_ids = [sid.strip().upper() for sid in series_ids_str.split(',') if sid.strip()]
        if not list_of_series_ids:
            msg = "æœªæä¾›æœ‰æ•ˆçš„ Series IDã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_fred_data (no valid series IDs)")
            return data_series_dict, errors
        try:
            start_dt = datetime.strptime(start_date_str, "%Y%m%d")
        except ValueError:
            msg = f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug(f"Exiting fetch_fred_data (invalid start_date_str: {start_date_str})")
            return data_series_dict, errors
        try:
            end_dt = datetime.strptime(end_date_str, "%Y%m%d")
        except ValueError:
            msg = f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug(f"Exiting fetch_fred_data (invalid end_date_str: {end_date_str})")
            return data_series_dict, errors
        if start_dt > end_dt:
            msg = f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚"
            errors.append(msg)
            logger.error(msg)
            logger.debug("Exiting fetch_fred_data (start_dt > end_dt)")
            return data_series_dict, errors
        for series_id in list_of_series_ids:
            logger.debug(f"Processing FRED series_id: {series_id}")
            try:
                logger.info(f"Downloading FRED data for {series_id}")
                series_data = fred.get_series(series_id, observation_start=start_dt, observation_end=end_dt)
                if series_data.empty:
                    msg = f"Series ID {series_id}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    logger.debug(f"FRED data for {series_id} is empty.")
                else:
                    df = series_data.to_frame(name=series_id)
                    df.reset_index(inplace=True)
                    df.rename(columns={'index': 'Date', series_id: 'Value'}, inplace=True)
                    df['Date'] = pd.to_datetime(df['Date'])
                    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
                    df.dropna(subset=['Value'], inplace=True)
                    data_series_dict[series_id] = df
                    logger.info(f"Successfully downloaded FRED data for {series_id}")
                    logger.debug(f"FRED data for {series_id} fetched successfully. Shape: {df.shape}")
            except ValueError as ve:
                 msg = f"Series ID {series_id} ç„¡æ•ˆæˆ–æ‰¾ä¸åˆ°: {str(ve)}"
                 errors.append(msg)
                 logger.error(msg, exc_info=True)
                 logger.debug(f"Error fetching FRED data for {series_id} (ValueError): {str(ve)}")
            except Exception as e:
                msg = f"ä¸‹è¼‰ Series ID {series_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
                logger.debug(f"Error fetching FRED data for {series_id}: {str(e)}")
        logger.debug(f"Exiting fetch_fred_data. Found {len(data_series_dict)} series, {len(errors)} errors.")
        return data_series_dict, errors

    NY_FED_POSITIONS_URLS_CORRECTED = [
        "https://markets.newyorkfed.org/api/pd/get/SBN2024/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2022/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2015/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2013/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBP2013/timeseries/PDPUSGCS3LNOP_PDPUSGCS36NOP_PDPUSGCS611NOP_PDPUSGCSM11NOP.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBP2001/timeseries/PDPUSGCS5LNOP_PDPUSGCS5MNOP.xlsx",
    ]
    SBP_COLS_TO_SUM = {
        "SBP2013": ["PDPUSGCS3LNOP", "PDPUSGCS36NOP", "PDPUSGCS611NOP", "PDPUSGCSM11NOP"],
        "SBP2001": ["PDPUSGCS5LNOP", "PDPUSGCS5MNOP"],
    }

    @st.cache_data(ttl=86400)
    def fetch_ny_fed_data():
        logger.debug("Entering fetch_ny_fed_data")
        logger.info("Fetching NY Fed Primary Dealer Positions data.")
        all_positions_data = []
        errors = []
        HEADER_ROW_ASSUMPTION = 4
        DATE_COLUMN_INDEX_ASSUMPTION = 0
        for url in NY_FED_POSITIONS_URLS_CORRECTED:
            logger.debug(f"Fetching NY Fed data from URL: {url}")
            try:
                logger.info(f"Downloading NY Fed data from {url}")
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                excel_content = io.BytesIO(response.content)
                xls = pd.ExcelFile(excel_content)
                df = pd.read_excel(xls, sheet_name=0, header=HEADER_ROW_ASSUMPTION, index_col=DATE_COLUMN_INDEX_ASSUMPTION)
                df.index = pd.to_datetime(df.index, errors='coerce')
                df = df[df.index.notna()]
                if df.empty:
                    msg = f"æª”æ¡ˆ {url} åœ¨è½‰æ›æ—¥æœŸå¾Œæ²’æœ‰æœ‰æ•ˆæ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    logger.debug(f"NY Fed data from {url} is empty after date conversion.")
                    continue
                source_type, target_cols = None, []
                if "SBN" in url:
                    source_type = "SBN"
                    target_cols = [col for col in df.columns if str(col).startswith("PDPOSGSC-")]
                elif "SBP2013" in url:
                    source_type = "SBP2013"
                    target_cols = [col for col in SBP_COLS_TO_SUM["SBP2013"] if col in df.columns]
                elif "SBP2001" in url:
                    source_type = "SBP2001"
                    target_cols = [col for col in SBP_COLS_TO_SUM["SBP2001"] if col in df.columns]
                logger.debug(f"URL: {url}, Source Type: {source_type}, Target Columns Identified: {target_cols}")
                if not target_cols:
                    msg = f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) ä¸­æœªæ‰¾åˆ°ç›®æ¨™æ¬„ä½æˆ–ç›®æ¨™æ¬„ä½åˆ—è¡¨ç‚ºç©ºã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    logger.debug(f"No target columns found for {url}.")
                    continue
                df_target = df[target_cols].apply(pd.to_numeric, errors='coerce')
                if df_target.isnull().all().all():
                    msg = f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) çš„ç›®æ¨™æ¬„ä½ {target_cols} è½‰æ›ç‚ºæ•¸å­—å¾Œå‡ç‚ºç©ºå€¼ã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    logger.debug(f"Target columns in {url} are all null after numeric conversion.")
                    continue
                daily_sum = df_target.sum(axis=1)
                all_positions_data.append(daily_sum)
                logger.info(f"Successfully processed NY Fed data from {url}")
                logger.debug(f"Successfully processed NY Fed data from {url}. Daily sum shape: {daily_sum.shape}")
            except requests.exceptions.HTTPError as http_err:
                msg = f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”Ÿ HTTP éŒ¯èª¤: {http_err}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
                logger.debug(f"HTTPError for {url}: {http_err}")
            except requests.exceptions.RequestException as req_err:
                msg = f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {req_err}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
                logger.debug(f"RequestException for {url}: {req_err}")
            except Exception as e:
                msg = f"è™•ç†æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
                logger.debug(f"Generic error processing {url}: {str(e)}")
        if not all_positions_data:
            logger.warning("No data collected from any NY Fed URL.")
            logger.debug("Exiting fetch_ny_fed_data (no data collected)")
            return None, errors
        try:
            final_series = pd.concat(all_positions_data)
            logger.debug(f"NY Fed data concatenated. Series length before processing: {len(final_series)}")
            final_series = final_series.groupby(final_series.index).last()
            final_series = final_series.sort_index()
            final_series = final_series.ffill()
            logger.debug(f"NY Fed data concatenated. Final series length after processing: {len(final_series)}")
            result_df = final_series.to_frame(name="Total_Dealer_Positions")
            result_df.reset_index(inplace=True)
            result_df.rename(columns={'index': 'Date'}, inplace=True)
            logger.info("Successfully combined and processed all NY Fed data.")
        except Exception as e:
            msg = f"åˆä½µå’Œæœ€çµ‚è™•ç† NY Fed æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            errors.append(msg)
            logger.error(msg, exc_info=True)
            logger.debug(f"Error during final NY Fed data combination: {str(e)}")
            logger.debug("Exiting fetch_ny_fed_data (error during final combination)")
            return None, errors
        logger.debug(f"Exiting fetch_ny_fed_data. Result df shape: {result_df.shape if result_df is not None else 'None'}, {len(errors)} errors.")
        return result_df, errors

    def call_gemini_api(prompt_parts: list, api_keys_list: list, selected_model: str,
                        global_rpm: int, global_tpm: int,
                        generation_config_dict: dict = None, cached_content_name: str = None):
        logger.debug(f"Entering call_gemini_api with model: {selected_model}, num_prompt_parts: {len(prompt_parts)}, cache: {cached_content_name}, global_rpm: {global_rpm}, global_tpm: {global_tpm}")
        logger.info(f"Calling Gemini API with model: {selected_model}, cache: {cached_content_name}")

        if not api_keys_list:
            logger.error("Gemini API call failed: No valid API keys provided.")
            logger.debug("Exiting call_gemini_api (no valid API keys)")
            return "éŒ¯èª¤ï¼šæœªæä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚"

        active_key_index = st.session_state.get('active_gemini_key_index', 0)
        current_api_key = api_keys_list[active_key_index]
        logger.debug(f"Using Gemini API key index: {active_key_index}, key: {current_api_key[:10]}...")

        now = time.time()
        if current_api_key not in st.session_state.gemini_api_key_usage:
            st.session_state.gemini_api_key_usage[current_api_key] = {'requests': [], 'tokens': []}
            logger.debug(f"Initialized usage tracking for API key {current_api_key[:10]}...")

        # Filter requests older than 60 seconds
        st.session_state.gemini_api_key_usage[current_api_key]['requests'] = \
            [ts for ts in st.session_state.gemini_api_key_usage[current_api_key]['requests'] if now - ts < 60]
        current_requests_count = len(st.session_state.gemini_api_key_usage[current_api_key]['requests'])
        logger.debug(f"Current requests for key {current_api_key[:10]}... in last 60s: {current_requests_count}, RPM limit: {global_rpm}")

        if current_requests_count >= global_rpm:
            st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list)
            logger.warning(f"RPM limit reached for API key {current_api_key[:10]}... Switching to index {st.session_state.active_gemini_key_index}")
            logger.debug(f"Exiting call_gemini_api (RPM limit reached for {current_api_key[:10]}...)")
            return f"éŒ¯èª¤ï¼šAPI é‡‘é‘° {current_api_key[:10]}... RPM é”åˆ°ä¸Šé™ ({global_rpm})ã€‚è«‹ç¨å¾Œé‡è©¦æˆ–åˆ‡æ›é‡‘é‘°ã€‚"

        try:
            logger.debug(f"Configuring genai with API key: {current_api_key[:10]}...")
            genai.configure(api_key=current_api_key)
            model = genai.GenerativeModel(model_name=selected_model)
            gen_config_obj = genai.types.GenerationConfig(**generation_config_dict) if generation_config_dict else None
            final_prompt_content = "\n".join(map(str, prompt_parts))
            logger.debug(f"Full prompt for Gemini (first 300 chars): {final_prompt_content[:300]}...")
            logger.debug(f"Full prompt for Gemini (last 200 chars): ...{final_prompt_content[-200:]}")

            logger.debug(f"Calling genai.GenerativeModel.generate_content with model {selected_model}, cache: {cached_content_name}")
            response = model.generate_content(
                final_prompt_content, generation_config=gen_config_obj, safety_settings=None,
                tools=None, tool_config=None, cached_content=cached_content_name
            )
            logger.debug(f"Gemini API response received. Usage metadata: {response.usage_metadata if hasattr(response, 'usage_metadata') else 'N/A'}")

            st.session_state.gemini_api_key_usage[current_api_key]['requests'].append(now)
            if response.usage_metadata and response.usage_metadata.total_token_count:
                st.session_state.gemini_api_key_usage[current_api_key]['tokens'].append((now, response.usage_metadata.total_token_count))

            st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list) # Cycle to next key
            logger.debug(f"Cycled active_gemini_key_index to {st.session_state.active_gemini_key_index} for next call.")
            logger.info("Gemini API call successful.")

            response_text = ""
            if response.parts: response_text = "".join(part.text for part in response.parts if hasattr(part, 'text'))
            elif hasattr(response, 'text') and response.text: response_text = response.text

            logger.debug(f"Gemini API response text length: {len(response_text)}")
            if not response_text:
                logger.warning("Gemini API response has no text/parts.")
                logger.debug("Exiting call_gemini_api (response has no text/parts)")
                return "æ¨¡å‹æœªè¿”å›æ–‡å­—å…§å®¹ã€‚"
            logger.debug("Exiting call_gemini_api (success)")
            return response_text

        except genai.types.BlockedPromptException as bpe:
            logger.error(f"Gemini API Error (BlockedPromptException): {bpe}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (BlockedPromptException)")
            return f"éŒ¯èª¤ï¼šæç¤ºè©è¢« Gemini API å°é–ã€‚åŸå› : {bpe}"
        except genai.types.generation_types.StopCandidateException as sce:
            logger.error(f"Gemini API Error (StopCandidateException): {sce}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (StopCandidateException)")
            return f"éŒ¯èª¤ï¼šå…§å®¹ç”Ÿæˆå› å®‰å…¨åŸå› æˆ–å…¶ä»–é™åˆ¶è€Œåœæ­¢ã€‚åŸå› : {sce}"
        except google.api_core.exceptions.PermissionDenied as e:
            logger.error(f"Gemini API Error (PermissionDenied): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (PermissionDenied)")
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ¬Šé™ä¸è¶³æˆ–APIé‡‘é‘°ç„¡æ•ˆã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.InvalidArgument as e:
            logger.error(f"Gemini API Error (InvalidArgument): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (InvalidArgument)")
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ™‚åƒæ•¸ç„¡æ•ˆ (ä¾‹å¦‚æ¨¡å‹åç¨±ä¸æ­£ç¢ºæˆ–å…§å®¹ä¸å½“)ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.FailedPrecondition as e:
            logger.error(f"Gemini API Error (FailedPrecondition): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (FailedPrecondition)")
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API é è¨­æ¢ä»¶å¤±æ•— (ä¾‹å¦‚ï¼Œæ‰€é¸æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå¿«å–)ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.DeadlineExceeded as e:
            logger.error(f"Gemini API Error (DeadlineExceeded): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (DeadlineExceeded)")
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API è¶…æ™‚ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.ServiceUnavailable as e:
            logger.error(f"Gemini API Error (ServiceUnavailable): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (ServiceUnavailable)")
            return f"éŒ¯èª¤ï¼šGeminiæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.InternalServerError as e:
            logger.error(f"Gemini API Error (InternalServerError): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (InternalServerError)")
            return f"éŒ¯èª¤ï¼šGeminiå…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.Unknown as e:
            logger.error(f"Gemini API Error (Unknown): {str(e)}", exc_info=True)
            logger.debug(f"Exiting call_gemini_api (Unknown)")
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ™‚ç™¼ç”ŸæœªçŸ¥çš„Google APIéŒ¯èª¤ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except Exception as e:
            logger.exception("Unexpected error during Gemini API call:")
            error_message = str(e)
            if hasattr(e, 'message'): error_message = e.message
            elif hasattr(e, 'args') and e.args: error_message = str(e.args[0])
            logger.debug(f"Exiting call_gemini_api (Unexpected error: {error_message})")
            return f"å‘¼å« Gemini API æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {error_message}"

    # --- Sidebar UI ---
    logger.debug("Setting up sidebar UI.")
    st.sidebar.title("âš™ï¸ å…¨åŸŸè¨­å®šèˆ‡å·¥å…·")
    st.sidebar.header("ğŸ¨ å¤–è§€ä¸»é¡Œèˆ‡å­—é«”")
    active_theme = st.session_state.get("active_theme", "dark")
    current_theme_label = "æš—è‰²æ¨¡å¼ (Gemini)" if active_theme == "dark" else "äº®è‰²æ¨¡å¼ (é è¨­)"
    toggle_label = f"åˆ‡æ›åˆ° {'äº®è‰²æ¨¡å¼ (é è¨­)' if active_theme == 'dark' else 'æš—è‰²æ¨¡å¼ (Gemini)'}"

    original_theme = st.session_state.active_theme
    new_toggle_state_is_dark = st.sidebar.toggle(
        toggle_label, value=(active_theme == "dark"), key="theme_toggle_widget", help="é»æ“Šåˆ‡æ›äº®æš—ä¸»é¡Œ"
    )

    theme_changed = False
    if new_toggle_state_is_dark and original_theme == "light":
        st.session_state.active_theme = "dark"
        theme_changed = True
    elif not new_toggle_state_is_dark and original_theme == "dark":
        st.session_state.active_theme = "light"
        theme_changed = True

    if theme_changed:
        logger.debug(f"Theme toggled. Old theme: {original_theme}, New theme: {st.session_state.active_theme}")
        st.experimental_rerun()

    st.sidebar.caption(f"ç›®å‰ä¸»é¡Œ: {current_theme_label}")
    st.sidebar.markdown("##### é¸æ“‡å­—é«”å¤§å°:")
    font_cols = st.sidebar.columns(3)
    original_font_size = st.session_state.get("font_size_name", "ä¸­")
    font_changed = False
    if font_cols[0].button("A- (å°)", key="font_small_button", use_container_width=True):
        if original_font_size != "å°":
            st.session_state.font_size_name = "å°"; font_changed = True
    if font_cols[1].button("A (ä¸­)", key="font_medium_button", use_container_width=True):
        if original_font_size != "ä¸­":
            st.session_state.font_size_name = "ä¸­"; font_changed = True
    if font_cols[2].button("A+ (å¤§)", key="font_large_button", use_container_width=True):
        if original_font_size != "å¤§":
            st.session_state.font_size_name = "å¤§"; font_changed = True

    if font_changed:
        logger.debug(f"Font size changed from {original_font_size} to: {st.session_state.font_size_name}")
        st.experimental_rerun()

    st.sidebar.caption(f"ç›®å‰å­—é«”: {st.session_state.get('font_size_name', 'ä¸­')}")
    st.sidebar.markdown("---")

    st.sidebar.header("ğŸ”‘ API é‡‘é‘°ç®¡ç†")
    st.sidebar.caption("è«‹åœ¨æ­¤è™•ç®¡ç†æ‚¨çš„ API é‡‘é‘°ã€‚")
    # This specific check for sidebar might be redundant if the main page already shows a big warning,
    # but keeping it doesn't hurt and provides context within the sidebar itself.
    if not are_gemini_keys_valid(): # Using the helper function here as well
        st.sidebar.warning("è­¦å‘Šï¼šè‡³å°‘éœ€è¦ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°æ‰èƒ½ä½¿ç”¨ Gemini åˆ†æåŠŸèƒ½ã€‚")

    keys_updated_in_sidebar = False
    for key_name_snake_case, key_label in api_keys_info.items():
        old_value = st.session_state.get(key_name_snake_case, "")
        new_value = st.sidebar.text_input(
            key_label, type="password", value=old_value, key=f"{key_name_snake_case}_input"
        )
        if new_value != old_value:
            st.session_state[key_name_snake_case] = new_value
            logger.debug(f"API key {key_label} ({key_name_snake_case}) updated in session state. New length: {len(new_value)>0}")
            keys_updated_in_sidebar = True

    if keys_updated_in_sidebar:
        # This message might appear even if keys are not valid yet, but it confirms user action.
        st.sidebar.success("API é‡‘é‘°å·²æ›´æ–°ä¸¦å„²å­˜åœ¨æœƒè©±ä¸­ã€‚")
        # Optionally, re-validate Gemini keys silently or provide feedback
        # are_gemini_keys_valid() # Call to log if keys are now valid

    st.sidebar.header("ğŸ¤– Gemini æ¨¡å‹è¨­å®š")
    st.sidebar.caption("é¸æ“‡ä¸¦é…ç½®è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ã€‚")
    st.session_state.selected_model_name = st.sidebar.selectbox(
        "é¸æ“‡ Gemini æ¨¡å‹:", options=available_models, index=available_models.index(st.session_state.selected_model_name), key="selected_model_name_selector"
    )
    st.session_state.global_rpm_limit = st.sidebar.number_input(
        "å…¨åŸŸ RPM (æ¯åˆ†é˜è«‹æ±‚æ•¸):", min_value=1, value=st.session_state.global_rpm_limit, step=1, key="global_rpm_limit_input"
    )
    st.session_state.global_tpm_limit = st.sidebar.number_input(
        "å…¨åŸŸ TPM (æ¯åˆ†é˜è©å…ƒæ•¸):", min_value=1000, value=st.session_state.global_tpm_limit, step=10000, key="global_tpm_limit_input"
    )
    st.sidebar.caption("æ³¨æ„ï¼šè«‹åƒè€ƒ Gemini å®˜æ–¹æ–‡ä»¶äº†è§£ä¸åŒæ¨¡å‹çš„å…·é«” RPM/TPM é™åˆ¶ã€‚")
    st.sidebar.header("ğŸ“ ä¸»è¦æç¤ºè©")
    st.sidebar.caption("è¨­å®šç”¨æ–¼æŒ‡å° Gemini åˆ†æçš„ä¸»è¦æç¤ºè©ã€‚")

    old_prompt = st.session_state.main_gemini_prompt
    st.session_state.main_gemini_prompt = st.sidebar.text_area(
        "ä¸»è¦åˆ†ææç¤ºè© (System Prompt):", value=st.session_state.main_gemini_prompt, height=300, key="main_gemini_prompt_input"
    )
    if st.session_state.main_gemini_prompt != old_prompt:
        logger.debug(f"Main Gemini prompt updated via text area. New length: {len(st.session_state.main_gemini_prompt)}")

    uploaded_prompt_file = st.sidebar.file_uploader("æˆ–å¾ .txt æª”æ¡ˆè¼‰å…¥æç¤ºè©:", type=["txt"], key="prompt_file_uploader")
    if uploaded_prompt_file is not None:
        logger.debug(f"Prompt file uploaded: {uploaded_prompt_file.name}")
        prompt_content = uploaded_prompt_file.read().decode("utf-8")
        st.session_state.main_gemini_prompt = prompt_content
        logger.debug(f"Main Gemini prompt updated from file {uploaded_prompt_file.name}. New length: {len(prompt_content)}")
        # Clear the uploader after processing to allow re-upload of same file if needed
        # st.session_state.prompt_file_uploader = None # This might cause issues if not handled carefully with Streamlit's state

    st.sidebar.header("ğŸ§¹ å¿«å–ç®¡ç†")
    st.sidebar.caption("ç®¡ç†æ‡‰ç”¨ç¨‹å¼çš„æ•¸æ“šå¿«å–ã€‚")
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰æ•¸æ“šå¿«å–", key="clear_all_cache_button"):
        logger.debug("Clear all data cache button clicked.")
        st.cache_data.clear()
        logger.info("All data caches cleared.")
        st.sidebar.success("æ‰€æœ‰æ•¸æ“šå¿«å–å·²æˆåŠŸæ¸…é™¤ï¼ä¸‹æ¬¡ç²å–æ•¸æ“šæ™‚å°‡å¾æºé ­é‡æ–°è¼‰å…¥ã€‚")
    st.sidebar.caption("é»æ“Šæ­¤æŒ‰éˆ•å°‡æ¸…é™¤æ‰€æœ‰å·²å¿«å–çš„ yfinance, FRED åŠ NY Fed æ•¸æ“šã€‚")
    st.sidebar.header("ğŸ§  Gemini å…§å®¹å¿«å–")
    st.session_state.cache_display_name_input = st.sidebar.text_input(
        "è¦å¿«å–çš„å…§å®¹åç¨± (ä¾‹å¦‚ system_prompt_cache):", value=st.session_state.get("cache_display_name_input", "system_prompt_main"), key="cache_display_name_input_widget"
    )
    st.session_state.cache_content_input = st.sidebar.text_area(
        "è¦å¿«å–çš„å…§å®¹ (é€šå¸¸æ˜¯ System Prompt):", value=st.session_state.get("cache_content_input", st.session_state.get("main_gemini_prompt","")), height=150, key="cache_content_input_widget"
    )
    st.session_state.cache_ttl_seconds_input = st.sidebar.number_input(
        "å¿«å– TTL (ç§’, e.g., 3600 for 1 hour):", min_value=60, value=st.session_state.get("cache_ttl_seconds_input",3600), key="cache_ttl_input_widget"
    )

    if st.sidebar.button("å‰µå»º/æ›´æ–°å…§å®¹å¿«å–", key="create_cache_button"):
        cache_name = st.session_state.get("cache_display_name_input", "")
        cache_content_provided = bool(st.session_state.get("cache_content_input", ""))
        logger.debug(f"Cache action: Create/Update button clicked. Name: {cache_name}, Content provided: {cache_content_provided}, TTL: {st.session_state.get('cache_ttl_seconds_input')}")
        logger.info(f"Attempting to create/update cache: {st.session_state.cache_display_name_input}")
        gemini_keys_for_cache = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
        valid_gemini_key_for_cache = next((key for key in gemini_keys_for_cache if key), None)
        selected_model_for_cache = st.session_state.get("selected_model_name", "gemini-1.0-pro")

        if valid_gemini_key_for_cache and st.session_state.cache_display_name_input and st.session_state.cache_content_input:
            try:
                logger.debug(f"Configuring genai with API key for cache creation: {valid_gemini_key_for_cache[:10]}...")
                genai.configure(api_key=valid_gemini_key_for_cache)
                ttl_str = f"{st.session_state.cache_ttl_seconds_input}s"
                model_for_caching_api = f"models/{selected_model_for_cache}" if not selected_model_for_cache.startswith("models/") else selected_model_for_cache
                logger.debug(f"Calling genai.create_cached_content with model: {model_for_caching_api}, display_name: {st.session_state.cache_display_name_input}, ttl: {ttl_str}")
                cached_content = genai.create_cached_content(
                    model=model_for_caching_api, display_name=st.session_state.cache_display_name_input,
                    system_instruction=st.session_state.cache_content_input, ttl=ttl_str
                )
                st.sidebar.success(f"å¿«å– '{cached_content.display_name}' å·²å‰µå»º/æ›´æ–°ã€‚\nåç¨±: {cached_content.name}")
                logger.info(f"Cache '{cached_content.display_name}' created/updated successfully. Name: {cached_content.name}")
                st.session_state.gemini_caches_list = list(genai.list_cached_contents(api_key=valid_gemini_key_for_cache))
                logger.debug(f"Updated cache list, new count: {len(st.session_state.gemini_caches_list)}")
            except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.InvalidArgument,
                    google.api_core.exceptions.FailedPrecondition, google.api_core.exceptions.DeadlineExceeded,
                    google.api_core.exceptions.ServiceUnavailable, google.api_core.exceptions.InternalServerError,
                    google.api_core.exceptions.Unknown) as e:
                logger.error(f"Failed to create/update cache ({type(e).__name__}): {st.session_state.cache_display_name_input} - {str(e)}", exc_info=True)
                st.sidebar.error(f"å‰µå»ºå¿«å–å¤±æ•— ({type(e).__name__}): {str(e)}")
            except Exception as e:
                logger.error(f"Unexpected error creating/updating cache: {st.session_state.cache_display_name_input} - {str(e)}", exc_info=True)
                st.sidebar.error(f"å‰µå»ºå¿«å–æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
        else:
            logger.warning("Cannot create/update cache: Missing Gemini API key, cache name, or content.")
            st.sidebar.warning("è«‹æä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€å¿«å–åç¨±å’Œå¿«å–å…§å®¹ã€‚")

    if st.sidebar.button("åˆ—å‡ºå¯ç”¨å¿«å–", key="list_caches_button"):
        logger.debug("Cache action: List button clicked.")
        logger.info("Attempting to list caches.")
        gemini_keys_for_cache_list = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
        valid_gemini_key_for_cache_list = next((key for key in gemini_keys_for_cache_list if key), None)
        if valid_gemini_key_for_cache_list:
            try:
                logger.debug(f"Configuring genai with API key for listing caches: {valid_gemini_key_for_cache_list[:10]}...")
                genai.configure(api_key=valid_gemini_key_for_cache_list)
                st.session_state.gemini_caches_list = list(genai.list_cached_contents())
                if not st.session_state.gemini_caches_list:
                    st.sidebar.info("ç›®å‰æ²’æœ‰å¯ç”¨çš„å…§å®¹å¿«å–ã€‚")
                    logger.info("No caches found.")
                else:
                    logger.info(f"Found {len(st.session_state.gemini_caches_list)} caches.")
                    logger.debug(f"Caches listed: {[c.name for c in st.session_state.gemini_caches_list]}")
            except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.DeadlineExceeded,
                    google.api_core.exceptions.ServiceUnavailable, google.api_core.exceptions.InternalServerError,
                    google.api_core.exceptions.Unknown) as e:
                logger.error(f"Failed to list caches ({type(e).__name__}): {str(e)}", exc_info=True)
                st.sidebar.error(f"åˆ—å‡ºå¿«å–å¤±æ•— ({type(e).__name__}): {str(e)}")
                st.session_state.gemini_caches_list = []
            except Exception as e:
                logger.error(f"Unexpected error listing caches: {str(e)}", exc_info=True)
                st.sidebar.error(f"åˆ—å‡ºå¿«å–æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
                st.session_state.gemini_caches_list = []
        else:
            logger.warning("Cannot list caches: Missing Gemini API key.")
            st.sidebar.warning("è«‹å…ˆè¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆ—å‡ºå¿«å–ã€‚")

    if st.session_state.gemini_caches_list:
        cache_options = {"(ä¸ä½¿ç”¨å¿«å–)": None}
        cache_options.update({f"{c.display_name} ({c.name.split('/')[-1][:8]}...)": c.name for c in st.session_state.gemini_caches_list})
        current_selected_cache_name = st.session_state.get("selected_cache_for_generation", None)
        options_list = list(cache_options.values())
        current_index = options_list.index(current_selected_cache_name) if current_selected_cache_name in options_list else 0

        old_selected_cache = st.session_state.selected_cache_for_generation
        selected_display_key = st.sidebar.selectbox(
            "é¸æ“‡ä¸€å€‹å¿«å–ç”¨æ–¼ä¸‹æ¬¡ç”Ÿæˆ:", options=list(cache_options.keys()), index=current_index, key="select_cache_dropdown"
        )
        st.session_state.selected_cache_for_generation = cache_options.get(selected_display_key)
        if st.session_state.selected_cache_for_generation != old_selected_cache:
            logger.debug(f"Selected cache for generation changed from {old_selected_cache} to {st.session_state.selected_cache_for_generation}")

    st.session_state.cache_name_to_delete_input = st.sidebar.text_input(
        "è¦åˆªé™¤çš„å¿«å–åç¨± (projects/.../cachedContents/...):", value=st.session_state.get("cache_name_to_delete_input",""), key="cache_name_to_delete_input_widget"
    )
    if st.sidebar.button("åˆªé™¤æŒ‡å®šå¿«å–", key="delete_cache_button"):
        cache_to_delete = st.session_state.cache_name_to_delete_input
        logger.debug(f"Cache action: Delete button clicked. Name: {cache_to_delete}")
        logger.info(f"Attempting to delete cache: {cache_to_delete}")
        if cache_to_delete:
            gemini_keys_for_delete = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
            valid_gemini_key_for_delete = next((key for key in gemini_keys_for_delete if key), None)
            if valid_gemini_key_for_delete:
                try:
                    logger.debug(f"Configuring genai with API key for cache deletion: {valid_gemini_key_for_delete[:10]}...")
                    genai.configure(api_key=valid_gemini_key_for_delete)
                    logger.debug(f"Calling genai.delete_cached_content for: {cache_to_delete}")
                    genai.delete_cached_content(name=cache_to_delete)
                    st.sidebar.success(f"å¿«å– {cache_to_delete} å·²æˆåŠŸåˆªé™¤ã€‚")
                    logger.info(f"Cache {cache_to_delete} deleted successfully.")
                    st.session_state.gemini_caches_list = list(genai.list_cached_contents(api_key=valid_gemini_key_for_delete)) # Refresh list
                    logger.debug(f"Refreshed cache list after deletion. New count: {len(st.session_state.gemini_caches_list)}")
                    if st.session_state.selected_cache_for_generation == cache_to_delete:
                        st.session_state.selected_cache_for_generation = None
                        logger.debug(f"Deleted cache was the selected one. Resetting selected_cache_for_generation to None.")
                except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.NotFound,
                        google.api_core.exceptions.DeadlineExceeded, google.api_core.exceptions.ServiceUnavailable,
                        google.api_core.exceptions.InternalServerError, google.api_core.exceptions.Unknown) as e:
                    logger.error(f"Failed to delete cache {cache_to_delete} ({type(e).__name__}): {str(e)}", exc_info=True)
                    st.sidebar.error(f"åˆªé™¤å¿«å– {cache_to_delete} å¤±æ•— ({type(e).__name__}): {str(e)}")
                except Exception as e:
                    logger.error(f"Unexpected error deleting cache {cache_to_delete}: {str(e)}", exc_info=True)
                    st.sidebar.error(f"åˆªé™¤å¿«å– {cache_to_delete} æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
            else:
                logger.warning("Cannot delete cache: Missing Gemini API key.")
                st.sidebar.warning("è«‹è¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆªé™¤å¿«å–ã€‚")
        else:
            logger.warning("Cannot delete cache: Cache name not provided.")
            st.sidebar.warning("è«‹è¼¸å…¥è¦åˆªé™¤çš„å¿«å–åç¨±ã€‚")

    # --- Main Page UI ---
    logger.debug("Setting up main page UI.")
    st.title("é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç†")

    # API Key Check is done earlier, this section is for file uploads etc.
    st.header("ğŸ“„ æ­¥é©Ÿä¸€ï¼šä¸Šå‚³èˆ‡æª¢è¦–æ–‡ä»¶")
    st.caption("è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆã€‚")

    # Preserve previously uploaded files if the widget hasn't changed
    # This helps avoid re-processing if only other parts of the UI cause a rerun
    previous_uploaded_files_list = st.session_state.get("uploaded_files_list", [])
    uploaded_files_from_widget = st.file_uploader(
        "è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆ (å¯å¤šé¸ .txt):", type=["txt"], accept_multiple_files=True, key="file_uploader_widget"
    )
    logger.debug(f"File uploader widget returned {len(uploaded_files_from_widget) if uploaded_files_from_widget else 0} files.")

    # Check if the list of uploaded files has actually changed
    # This simple check might not be robust for all cases (e.g. same names, different content) but good for basic optimization
    if uploaded_files_from_widget and uploaded_files_from_widget != previous_uploaded_files_list:
        logger.debug("New files detected from uploader.")
        st.session_state.uploaded_files_list = uploaded_files_from_widget
        st.session_state.uploaded_file_contents = {} # Reset contents for new batch
        logger.debug(f"Processing {len(st.session_state.uploaded_files_list)} uploaded files.")
        for file_obj in st.session_state.uploaded_files_list:
            logger.debug(f"Attempting to read file: {file_obj.name}")
            try:
                content = file_obj.read().decode("utf-8")
                st.session_state.uploaded_file_contents[file_obj.name] = content
                logger.debug(f"Successfully read file: {file_obj.name}, content length: {len(content)}")
            except Exception as e:
                logger.error(f"è®€å–æª”æ¡ˆ {file_obj.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
                logger.debug(f"Error reading file {file_obj.name}: {e}", exc_info=True) # Also log as debug with exc_info
                st.error(f"è®€å–æª”æ¡ˆ {file_obj.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        if st.session_state.uploaded_file_contents:
            logger.info(f"Successfully uploaded and read {len(st.session_state.uploaded_file_contents)} files.")
            st.success(f"æˆåŠŸä¸Šå‚³ä¸¦è®€å– {len(st.session_state.uploaded_file_contents)} å€‹æª”æ¡ˆã€‚")
    elif not uploaded_files_from_widget and previous_uploaded_files_list:
        # Files were cleared from uploader
        logger.debug("File uploader is now empty, clearing stored files.")
        st.session_state.uploaded_files_list = []
        st.session_state.uploaded_file_contents = {}


    if st.session_state.get("uploaded_files_list"): # Check session state directly
        st.subheader("å·²ä¸Šå‚³æ–‡ä»¶é è¦½:")
        if not st.session_state.uploaded_file_contents and uploaded_files_from_widget:
            st.warning("æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆéƒ½ç„¡æ³•æˆåŠŸè®€å–å…§å®¹ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å…§å®¹ã€‚")
        elif not st.session_state.uploaded_file_contents and not uploaded_files_from_widget:
            st.info("ä¹‹å‰ä¸Šå‚³çš„æª”æ¡ˆå…§å®¹å·²æ¸…é™¤æˆ–ç›®å‰æ²’æœ‰é¸æ“‡æª”æ¡ˆã€‚è«‹é‡æ–°ä¸Šå‚³ã€‚")
        for file_name, content in st.session_state.uploaded_file_contents.items():
            with st.expander(f"æª”å: {file_name} (é»æ“Šå±•é–‹/æ”¶èµ·é è¦½)", expanded=False):
                st.text(content[:500] + "..." if len(content) > 500 else content)
    elif not uploaded_files_from_widget:
        st.info("è«‹ä¸Šå‚³æ–‡å­—æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")

    st.header("ğŸ“Š æ­¥é©ŸäºŒï¼šå¼•å…¥å¤–éƒ¨æ•¸æ“š (å¯é¸)")
    with st.expander("ğŸ“Š æ­¥é©ŸäºŒï¼šé¸æ“‡ä¸¦è¼‰å…¥å¤–éƒ¨æ•¸æ“š (é»æ“Šå±•é–‹/æ”¶èµ·)", expanded=False):
        st.caption("é¸æ“‡ yfinance, FRED, NY Fed ç­‰å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæºï¼Œè¨­å®šåƒæ•¸ä¸¦è¼‰å…¥æ•¸æ“šã€‚")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            select_all_sources_widget = st.checkbox("ğŸŒ å…¨é¸/å–æ¶ˆæ‰€æœ‰æ•¸æ“šæº", value=st.session_state.select_all_sources, key="select_all_sources_cb")
            if select_all_sources_widget != st.session_state.select_all_sources:
                st.session_state.select_all_sources = select_all_sources_widget
                st.session_state.select_yfinance = select_all_sources_widget
                st.session_state.select_fred = select_all_sources_widget
                st.session_state.select_ny_fed = select_all_sources_widget
                st.experimental_rerun()
        with col2: st.session_state.select_yfinance = st.checkbox("ğŸ“ˆ yfinance è‚¡å¸‚æ•¸æ“š", value=st.session_state.select_yfinance, key="select_yfinance_cb")
        with col3: st.session_state.select_fred = st.checkbox("ğŸ¦ FRED ç¸½ç¶“æ•¸æ“š", value=st.session_state.select_fred, key="select_fred_cb")
        with col4: st.session_state.select_ny_fed = st.checkbox("ğŸ‡ºğŸ‡¸ NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š", value=st.session_state.select_ny_fed, key="select_ny_fed_cb")
        date_col1, date_col2 = st.columns(2)
        with date_col1: st.session_state.data_start_date = st.text_input("è¼¸å…¥é–‹å§‹æ—¥æœŸ (YYYYMMDD):", value=st.session_state.data_start_date, key="data_start_date_input")
        with date_col2: st.session_state.data_end_date = st.text_input("è¼¸å…¥çµæŸæ—¥æœŸ (YYYYMMDD):", value=st.session_state.data_end_date, key="data_end_date_input")
        param_col1, param_col2 = st.columns(2)
        interval_options = {"æ¯æ—¥": "1d", "æ¯é€±": "1wk", "æ¯å°æ™‚": "1h", "æ¯5åˆ†é˜": "5m"}
        with param_col1:
            if st.session_state.select_yfinance:
                st.session_state.yfinance_tickers = st.text_input("yfinance è‚¡ç¥¨ä»£ç¢¼ (é€—è™Ÿåˆ†éš”):", value=st.session_state.yfinance_tickers, key="yfinance_tickers_input")
                current_interval_label = st.session_state.yfinance_interval_label
                if current_interval_label not in interval_options: current_interval_label = list(interval_options.keys())[0]; st.session_state.yfinance_interval_label = current_interval_label
                st.session_state.yfinance_interval_label = st.selectbox("yfinance æ•¸æ“šé€±æœŸ:", options=list(interval_options.keys()), index=list(interval_options.keys()).index(current_interval_label), key="yfinance_interval_label_select")
        with param_col2:
            if st.session_state.select_fred:
                st.session_state.fred_series_ids = st.text_input("FRED Series ID (é€—è™Ÿåˆ†éš”):", value=st.session_state.fred_series_ids, key="fred_series_ids_input")
        st.markdown("---")
        if st.button("ğŸ” ç²å–ä¸¦é è¦½é¸å®šæ•¸æ“š", key="fetch_data_button"):
            logger.debug("Fetch data button clicked.")
            st.session_state.fetch_data_button_clicked = True
            st.session_state.fetched_data_preview = {}
            st.session_state.fetch_errors = []
            logger.debug(f"Data sources selected - yfinance: {st.session_state.select_yfinance}, FRED: {st.session_state.select_fred}, NY Fed: {st.session_state.select_ny_fed}")

            something_selected = (st.session_state.select_yfinance or st.session_state.select_fred or st.session_state.select_ny_fed)
            if not something_selected:
                st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ•¸æ“šæºã€‚")
                st.session_state.fetch_data_button_clicked = False # Reset as no action taken
                logger.debug("No data source selected for fetching.")
            else:
                with st.spinner("æ­£åœ¨ç²å–æ•¸æ“šï¼Œè«‹ç¨å€™..."):
                    if st.session_state.select_yfinance:
                        logger.debug("Fetching yfinance data...")
                        actual_interval = interval_options[st.session_state.yfinance_interval_label]
                        yfinance_data, yfinance_errs = fetch_yfinance_data(st.session_state.yfinance_tickers, st.session_state.data_start_date, st.session_state.data_end_date, actual_interval)
                        if yfinance_data:
                            st.session_state.fetched_data_preview["yfinance"] = yfinance_data
                            logger.debug(f"yfinance data fetched. Keys: {list(yfinance_data.keys())}")
                        if yfinance_errs:
                            st.session_state.fetch_errors.extend([f"[yfinance] {e}" for e in yfinance_errs])
                            logger.debug(f"yfinance errors: {yfinance_errs}")
                    if st.session_state.select_fred:
                        logger.debug("Fetching FRED data...")
                        fred_api_key = st.session_state.get("fred_api_key", "")
                        if not fred_api_key:
                            msg = "[FRED] éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªåœ¨å´é‚Šæ¬„è¨­å®šã€‚è«‹å…ˆè¨­å®šã€‚"
                            st.session_state.fetch_errors.append(msg)
                            # logger.error(msg) # Already logged as error by fetch_fred_data if key is missing
                            logger.debug("FRED API key missing for data fetch.")
                        else:
                            fred_data, fred_errs = fetch_fred_data(st.session_state.fred_series_ids, st.session_state.data_start_date, st.session_state.data_end_date, fred_api_key)
                            if fred_data:
                                st.session_state.fetched_data_preview["fred"] = fred_data
                                logger.debug(f"FRED data fetched. Keys: {list(fred_data.keys())}")
                            if fred_errs:
                                st.session_state.fetch_errors.extend([f"[FRED] {e}" for e in fred_errs])
                                logger.debug(f"FRED errors: {fred_errs}")
                    if st.session_state.select_ny_fed:
                        logger.debug("Fetching NY Fed data...")
                        ny_fed_data, ny_fed_errs = fetch_ny_fed_data()
                        if ny_fed_data is not None:
                            st.session_state.fetched_data_preview["ny_fed"] = ny_fed_data
                            logger.debug(f"NY Fed data fetched. Shape: {ny_fed_data.shape if ny_fed_data is not None else 'None'}")
                        if ny_fed_errs:
                            st.session_state.fetch_errors.extend([f"[NY Fed] {e}" for e in ny_fed_errs])
                            logger.debug(f"NY Fed errors: {ny_fed_errs}")
        if st.session_state.fetch_errors:
            st.subheader("æ•¸æ“šç²å–éŒ¯èª¤ï¼š")
            for err_msg in st.session_state.fetch_errors:
                st.error(err_msg) # UI
                logger.warning(f"Data fetching error displayed to user: {err_msg}") # Log as warning as it's also a UI message
        if st.session_state.fetched_data_preview:
            st.subheader("å·²ç²å–æ•¸æ“šé è¦½:")
            if "yfinance" in st.session_state.fetched_data_preview:
                st.markdown("#### yfinance æ•¸æ“š:")
                for ticker, df_yf in st.session_state.fetched_data_preview["yfinance"].items():
                    with st.expander(f"Ticker: {ticker} (å…± {len(df_yf)} è¡Œ)", expanded=False): st.dataframe(df_yf.head())
            if "fred" in st.session_state.fetched_data_preview:
                st.markdown("#### FRED æ•¸æ“š:")
                for series_id, df_fred in st.session_state.fetched_data_preview["fred"].items():
                    with st.expander(f"Series ID: {series_id} (å…± {len(df_fred)} è¡Œ)", expanded=False): st.dataframe(df_fred.head())
            if "ny_fed" in st.session_state.fetched_data_preview and not st.session_state.fetched_data_preview["ny_fed"].empty:
                st.markdown("#### NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š:")
                with st.expander(f"NY Fed ç¸½æŒæœ‰é‡ (å…± {len(st.session_state.fetched_data_preview['ny_fed'])} è¡Œ)", expanded=False): st.dataframe(st.session_state.fetched_data_preview["ny_fed"].head())
            has_data = any((isinstance(ds, dict) and ds) or (isinstance(ds, pd.DataFrame) and not ds.empty) for ds in st.session_state.fetched_data_preview.values())
            if has_data and not st.session_state.fetch_errors: st.success("æ•¸æ“šå·²æˆåŠŸè¼‰å…¥ä¸¦æº–å‚™å¥½ç”¨æ–¼åˆ†æã€‚")
            elif not has_data and not st.session_state.fetch_errors and st.session_state.fetch_data_button_clicked: st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")
        elif st.session_state.fetch_data_button_clicked and not st.session_state.fetch_errors:
            st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")

    st.header("ğŸ’¬ æ­¥é©Ÿä¸‰ï¼šèˆ‡ Gemini é€²è¡Œåˆ†æèˆ‡è¨è«–")
    chat_container = st.container(height=400)
    with chat_container:
        for message in st.session_state.chat_history:
            avatar_icon = "ğŸ‘¤" if message["role"] == "user" else "âœ¨"
            with st.chat_message(message["role"], avatar=avatar_icon):
                if message["role"] == "model" and message.get("is_error", False): st.error(message["parts"][0])
                else: st.markdown(message["parts"][0])

    user_input = st.chat_input("å‘ Gemini æå•æˆ–çµ¦å‡ºæŒ‡ä»¤ï¼š", key="gemini_user_input")
    if user_input:
        logger.info(f"User input received: {user_input}") # Standard info log for user action
        logger.debug(f"User chat input: {user_input}")   # Debug log for the same
        st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
        with st.spinner("Gemini æ­£åœ¨æ€è€ƒä¸­ï¼Œè«‹ç¨å€™..."):
            model_response_text, is_error_response = "", False
            try:
                logger.info("Preparing data and prompt for Gemini.") # Existing info
                logger.debug("Start: Preparing data and prompt for Gemini call.") # New debug
                full_prompt_parts = []
                if st.session_state.get("main_gemini_prompt"):
                    full_prompt_parts.append(f"**ä¸»è¦æŒ‡ç¤º (System Prompt):**\n{st.session_state.main_gemini_prompt}\n\n---\n")
                    logger.debug("Added main_gemini_prompt to prompt_parts.")
                if st.session_state.get("uploaded_file_contents"):
                    uploaded_texts_str = "**å·²ä¸Šå‚³æ–‡ä»¶å…§å®¹æ‘˜è¦:**\n" + "".join([f"æª”å: {fn}\nå…§å®¹ç‰‡æ®µ:\n{ct[:1000]}...\n\n" for fn, ct in st.session_state.uploaded_file_contents.items()])
                    full_prompt_parts.append(uploaded_texts_str + "---\n")
                    logger.debug(f"Added {len(st.session_state.uploaded_file_contents)} uploaded file summaries to prompt_parts.")
                if st.session_state.get("fetched_data_preview"):
                    external_data_str = "**å·²å¼•å…¥çš„å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæ‘˜è¦:**\n"
                    for source, data_items in st.session_state.fetched_data_preview.items():
                        external_data_str += f"\nä¾†æº: {source.upper()}\n"
                        if source in ["yfinance", "fred"] and isinstance(data_items, dict):
                            for item_name, df_item in data_items.items():
                                if isinstance(df_item, pd.DataFrame): external_data_str += f"  {item_name} (æœ€è¿‘å¹¾ç­†):\n{df_item.tail(3).to_string()}\n"
                        elif source == "ny_fed" and isinstance(data_items, pd.DataFrame) and not data_items.empty:
                             external_data_str += f"  NY Fed ç¸½æŒæœ‰é‡ (æœ€è¿‘å¹¾ç­†):\n{data_items.tail(3).to_string()}\n"
                    full_prompt_parts.append(external_data_str + "---\n")
                    logger.debug(f"Added {len(st.session_state.fetched_data_preview)} fetched data summaries to prompt_parts.")
                full_prompt_parts.append(f"**ä½¿ç”¨è€…ç•¶å‰å•é¡Œ/æŒ‡ä»¤:**\n{user_input}")
                logger.debug("Added user input to prompt_parts.")

                valid_gemini_api_keys = [key for key in [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)] if key and key.strip()]
                selected_model_name = st.session_state.get("selected_model_name", "gemini-1.0-pro")
                generation_config = {"temperature": 0.7, "top_p": 1.0, "top_k": 32, "max_output_tokens": 8192}
                selected_cache_name_for_api = st.session_state.get("selected_cache_for_generation", None)
                logger.debug(f"Gemini call parameters: model={selected_model_name}, valid_keys_count={len(valid_gemini_api_keys)}, cache_name={selected_cache_name_for_api}, generation_config={generation_config}")

                if not valid_gemini_api_keys:
                    model_response_text, is_error_response = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„è¨­å®šè‡³å°‘ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚", True
                    logger.error("No valid Gemini API keys for call_gemini_api.")
                elif not selected_model_name:
                    model_response_text, is_error_response = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹ Gemini æ¨¡å‹ã€‚", True
                    logger.error("No Gemini model selected for call_gemini_api.")
                else:
                    model_response_text = call_gemini_api(
                        prompt_parts=full_prompt_parts, api_keys_list=valid_gemini_api_keys, selected_model=selected_model_name,
                        global_rpm=st.session_state.get("global_rpm_limit", 5), global_tpm=st.session_state.get("global_tpm_limit", 200000),
                        generation_config_dict=generation_config, cached_content_name=selected_cache_name_for_api
                    )
                    logger.debug(f"call_gemini_api returned. Response length: {len(model_response_text)}") # Log length of what was returned
                    if model_response_text.startswith("éŒ¯èª¤ï¼š"):
                        is_error_response = True
                        # Error already logged in call_gemini_api, no need to repeat logger.error here unless adding more context
                        logger.debug(f"Gemini call resulted in error message: {model_response_text}")
            except Exception as e:
                logger.exception("Unexpected error during Gemini interaction step:") # This will log the full exception
                model_response_text, is_error_response = f"è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š {str(e)}", True
                logger.debug(f"Gemini interaction step caught exception: {type(e).__name__} - {str(e)}")
            st.session_state.chat_history.append({"role": "model", "parts": [model_response_text], "is_error": is_error_response})
            logger.debug(f"Appended model response to chat history. is_error: {is_error_response}. Rerunning.")
            st.experimental_rerun()

    # --- Application Logs Viewer ---
    st.markdown("---") # Add a separator
    with st.expander("ğŸ“„ æ‡‰ç”¨ç¨‹å¼æ—¥èªŒ (Application Logs)", expanded=False):
        if 'log_handler' in st.session_state and hasattr(st.session_state.log_handler, 'get_logs'):
            log_records = st.session_state.log_handler.get_logs()
            # Display logs in reverse order (newest first) for better readability
            log_text = "\n".join(reversed(log_records))
            st.text_area("æ—¥èªŒå…§å®¹:", value=log_text, height=300, key="log_display_area", disabled=True)

            if st.button("æ¸…é™¤æ—¥èªŒç´€éŒ„", key="clear_logs_button"):
                if hasattr(st.session_state.log_handler, 'clear_logs'):
                    st.session_state.log_handler.clear_logs()
                    logging.debug("UI logs cleared by user.") # Log the action itself
                    st.experimental_rerun() # Rerun to refresh the log display
        else:
            st.warning("æ—¥èªŒè™•ç†ç¨‹å¼å°šæœªåˆå§‹åŒ–ã€‚")

    st.markdown("</div>", unsafe_allow_html=True)
    logger.debug("Exiting main_app_logic")

if __name__ == "__main__":
    # Get a logger instance for the main execution block
    # This is separate from the one inside main_app_logic to catch errors if main_app_logic itself fails to initialize its logger
    main_execution_logger = logging.getLogger("__main_execution__")
    main_execution_logger.debug("Application started. Entering __main__ block.")
    try:
        main_app_logic()
    except Exception as e:
        # Use the main_execution_logger here
        main_execution_logger.exception("An unhandled exception occurred in main_app_logic:") # Logs full trace

        # Fallback logging for UI if st.error is available
        try:
            st.error(f"""
            ğŸ˜ æ‡‰ç”¨ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤ ğŸ˜
            å¾ˆæŠ±æ­‰ï¼Œæ‡‰ç”¨ç¨‹å¼é‡åˆ°ä¸€å€‹æœªé æœŸçš„å•é¡Œï¼Œå¯èƒ½ç„¡æ³•æ­£å¸¸é‹ä½œã€‚
            è«‹å˜—è©¦é‡æ–°æ•´ç†é é¢ã€‚å¦‚æœå•é¡ŒæŒçºŒç™¼ç”Ÿï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚
            **éŒ¯èª¤è©³ç´°è³‡è¨Š:**
            é¡å‹: {type(e).__name__}
            è¨Šæ¯: {str(e)}
            """)
            main_execution_logger.debug("Displayed unhandled exception to Streamlit UI.")
        except Exception as st_e:
            # If Streamlit itself is failing, log that too
            main_execution_logger.error(f"Failed to display error in Streamlit UI: {st_e}", exc_info=True)
    main_execution_logger.debug("Application exiting __main__ block.")
        å¾ˆæŠ±æ­‰ï¼Œæ‡‰ç”¨ç¨‹å¼é‡åˆ°ä¸€å€‹æœªé æœŸçš„å•é¡Œï¼Œå¯èƒ½ç„¡æ³•æ­£å¸¸é‹ä½œã€‚
        è«‹å˜—è©¦é‡æ–°æ•´ç†é é¢ã€‚å¦‚æœå•é¡ŒæŒçºŒç™¼ç”Ÿï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚
        **éŒ¯èª¤è©³ç´°è³‡è¨Š:**
        é¡å‹: {type(e).__name__}
        è¨Šæ¯: {str(e)}
        """)
