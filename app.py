import streamlit as st
import pandas as pd
import os
import yfinance as yf
from datetime import datetime, timedelta
from fredapi import Fred
import requests
import io
import google.generativeai as genai
import google.api_core.exceptions
import time
import traceback
import logging
import sys

# --- Basic Logging Configuration ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(name)s:%(funcName)s:%(lineno)d] - %(message)s',
    stream=sys.stderr
)

# Set page config - MUST be the first Streamlit command
st.set_page_config(
    page_title="é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç† (ç”± Gemini é©…å‹•)",
    layout="wide"
)

def main_app_logic():
    logger = logging.getLogger(__name__)

    # API Key Definitions (needed for initialization and validation)
    api_keys_info = {
        "gemini_api_key_1": "Gemini API Key 1",
        "gemini_api_key_2": "Gemini API Key 2",
        "gemini_api_key_3": "Gemini API Key 3",
        "fred_api_key": "FRED API Key",
        "alpha_vantage_api_key": "Alpha Vantage API Key",
        "api_key_fmpnb": "Financial Modeling Prep API Key",
        "api_key_finnhub": "Finnhub API Key",
        "api_key_figi": "OpenFigi API Key",
        "api_key_iex": "IEX Cloud API Key",
        "api_key_polygon": "Polygon API Key",
        "deepseek_api_key": "DeepSeek API Key",
    }

    # Initialize session state for API keys if not already done
    if 'initialized_keys' not in st.session_state:
        logger.info("Initializing API keys in session state from secrets.")
        for key_name_snake_case in api_keys_info.keys():
            secret_key_name = key_name_snake_case.upper()
            st.session_state[key_name_snake_case] = st.secrets.get(secret_key_name, "")
        st.session_state.initialized_keys = True

    # --- Helper function to check for valid Gemini API keys ---
    def are_gemini_keys_valid():
        for i in range(1, 4):  # Check gemini_api_key_1, _2, _3
            key_value = st.session_state.get(f"gemini_api_key_{i}", "")
            if key_value and key_value.strip():
                logger.info(f"Found valid Gemini API key: gemini_api_key_{i}")
                return True
        logger.warning("No valid Gemini API keys found in session state.")
        return False

    # --- Perform API Key Check and Display Guidance ---
    if not are_gemini_keys_valid():
        # This message will appear on the main page if keys are missing
        st.warning(
            "âš ï¸ **æ ¸å¿ƒåŠŸèƒ½éœ€è¦ Gemini API é‡‘é‘°**\n\n"
            "æ­¤æ‡‰ç”¨ç¨‹å¼çš„æ ¸å¿ƒåˆ†æåŠŸèƒ½ç”± Google Gemini æä¾›æŠ€è¡“æ”¯æ´ã€‚è«‹åœ¨å·¦å´é‚Šæ¬„è¨­å®šæ‚¨çš„ Gemini API é‡‘é‘°ä»¥å•Ÿç”¨å®Œæ•´åŠŸèƒ½ã€‚\n\n"
            "å¦‚æœæ‚¨é‚„æ²’æœ‰é‡‘é‘°ï¼Œå¯ä»¥é»æ“Šä»¥ä¸‹é€£çµç²å–ï¼š "
            "[é»æ­¤ç²å– Gemini API é‡‘é‘°](https://aistudio.google.com/app/apikey)",
            icon="ğŸ”‘"
        )
        with st.expander("ğŸ”§ å¦‚ä½•è¨­å®š API é‡‘é‘°ï¼Ÿ(ä¸­æ–‡æ•™å­¸)", expanded=True):
            st.markdown("""
                ### å¦‚ä½•è¨­å®šåŠä½¿ç”¨ API é‡‘é‘°ï¼š

                1.  **ç²å–é‡‘é‘°**ï¼š
                    *   å‰å¾€ [Google AI Studio](https://aistudio.google.com/app/apikey) ç¶²ç«™ã€‚
                    *   ç™»å…¥æ‚¨çš„ Google å¸³æˆ¶ã€‚
                    *   é»æ“Š "Create API key in new project" æˆ–é¡ä¼¼æŒ‰éˆ•ä¾†å‰µå»ºä¸€å€‹æ–°çš„ API é‡‘é‘°ã€‚
                    *   è¤‡è£½æ‚¨ç²å¾—çš„ API é‡‘é‘°å­—ä¸²ã€‚

                2.  **åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­è¨­å®š**ï¼š
                    *   åœ¨æœ¬æ‡‰ç”¨ç¨‹å¼çš„å·¦å´é‚Šæ¬„æ‰¾åˆ°ã€ŒğŸ”‘ API é‡‘é‘°ç®¡ç†ã€éƒ¨åˆ†ã€‚
                    *   å°‡æ‚¨è¤‡è£½çš„ API é‡‘é‘°è²¼åˆ° "Gemini API Key 1", "Gemini API Key 2", æˆ– "Gemini API Key 3" ä»»ä¸€è¼¸å…¥æ¡†ä¸­ã€‚
                    *   è‡³å°‘éœ€è¦è¨­å®šä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚
                    *   ï¼ˆå¯é¸ï¼‰æ‚¨ä¹Ÿå¯ä»¥åœ¨æ­¤è™•è¨­å®š FRED API é‡‘é‘°ç­‰å…¶ä»–é‡‘é‘°ã€‚

                3.  **é–‹å§‹ä½¿ç”¨**ï¼š
                    *   é‡‘é‘°è¨­å®šå®Œæˆå¾Œï¼Œæ‡‰ç”¨ç¨‹å¼çš„ Gemini åˆ†æåŠŸèƒ½å³å¯ä½¿ç”¨ã€‚

                **é‡è¦æç¤º**ï¼šè«‹å¦¥å–„ä¿ç®¡æ‚¨çš„ API é‡‘é‘°ï¼Œä¸è¦åˆ†äº«çµ¦ä»–äººæˆ–åœ¨å…¬é–‹çš„ç¨‹å¼ç¢¼ä¸­æ´©æ¼ã€‚
            """)
        logger.info("API key guidance displayed on the main page.")

    # --- Function to load custom CSS ---
    def load_custom_css():
        try:
            with open("style.css", "r", encoding="utf-8") as f:
                css_content = f.read()
            st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
        except FileNotFoundError:
            logger.warning("style.css æª”æ¡ˆæœªæ‰¾åˆ°ã€‚å°‡ä½¿ç”¨é è¨­æ¨£å¼ã€‚")
            st.warning("è­¦å‘Šï¼šstyle.css æª”æ¡ˆæœªæ‰¾åˆ°ã€‚å°‡ä½¿ç”¨é è¨­æ¨£å¼ã€‚")
        except Exception as e:
            logger.error(f"è¼‰å…¥è‡ªè¨‚ CSS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            st.error(f"è¼‰å…¥è‡ªè¨‚ CSS æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # --- Load CSS and Apply Theme Wrapper ---
    load_custom_css()

    # Apply a global div with the theme class.
    # Ensure active_theme is initialized before this line if it's used.
    # It's initialized later, so using .get with a default is safe.
    st.markdown(f"<div class='theme-{st.session_state.get('active_theme', 'dark')}'>", unsafe_allow_html=True)

    # --- Inject Dynamic Font Size CSS ---
    font_size_css_map = {
        "å°": "0.875rem",
        "ä¸­": "1rem",
        "å¤§": "1.125rem"
    }
    selected_font_size_value = font_size_css_map.get(st.session_state.get("font_size_name", "ä¸­"), "1rem")
    font_override_style = f"""
<style>
html {{ font-size: {selected_font_size_value} !important; }}
</style>
"""
    st.markdown(font_override_style, unsafe_allow_html=True)

    # Gemini Model Definitions
    available_models = ["gemini-1.5-flash-latest", "gemini-1.5-pro-latest", "gemini-1.0-pro"]
    if 'initialized_model_settings' not in st.session_state:
        st.session_state.selected_model_name = available_models[0]
        st.session_state.global_rpm_limit = 5
        st.session_state.global_tpm_limit = 200000
        st.session_state.initialized_model_settings = True

    DEFAULT_MAIN_GEMINI_PROMPT = """è«‹ä½ åˆ†ææˆ‘æä¾›çš„æ‰€æœ‰æ–‡å­—æª”ã€‚
ä½ çš„ä»»å‹™æ˜¯æ•´ç†é€™äº›æª”æ¡ˆä¸­åŒ…å«çš„ç¤¾ç¾¤åª’é«”è²¼æ–‡ã€‚
è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹æŒ‡ç¤ºå‘ˆç¾çµæœï¼š
1.  **ä¾†æºè­˜åˆ¥**ï¼šç¢ºèªæ¯å€‹è²¼æ–‡çš„åŸå§‹æª”æ¡ˆåç¨±ã€‚
2.  **å…§å®¹æ‘˜è¦**ï¼šå°æ¯å€‹è²¼æ–‡é€²è¡Œç°¡æ½”æ‘˜è¦ã€‚
3.  **æƒ…ç·’åˆ†æ**ï¼šåˆ¤æ–·æ¯å€‹è²¼æ–‡è¡¨é”çš„æƒ…ç·’ï¼ˆä¾‹å¦‚ï¼Œæ­£é¢ã€è² é¢ã€ä¸­æ€§ï¼‰ã€‚
4.  **é—œéµä¸»é¡Œ**ï¼šæå–æ¯å€‹è²¼æ–‡è¨è«–çš„æ ¸å¿ƒä¸»é¡Œã€‚
5.  **å»ºè­°è¡Œå‹•**ï¼šå¦‚æœè²¼æ–‡æš—ç¤ºäº†æŸç¨®è¡Œå‹•æˆ–å»ºè­°ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºã€‚
è«‹ç¢ºä¿æœ€çµ‚è¼¸å‡ºçµæœåš´æ ¼éµå¾ªä¸Šè¿°æ‰€æœ‰æŒ‡ç¤ºã€‚"""
    if 'initialized_prompt_settings' not in st.session_state:
        st.session_state.main_gemini_prompt = DEFAULT_MAIN_GEMINI_PROMPT
        st.session_state.initialized_prompt_settings = True

    if 'initialized_file_upload_settings' not in st.session_state:
        st.session_state.uploaded_files_list = []
        st.session_state.uploaded_file_contents = {}
        st.session_state.initialized_file_upload_settings = True

    if 'initialized_data_source_settings' not in st.session_state:
        st.session_state.select_yfinance = False
        st.session_state.select_fred = False
        st.session_state.select_ny_fed = False
        st.session_state.select_all_sources = False
        st.session_state.data_start_date = "20230101"
        st.session_state.data_end_date = datetime.now().strftime("%Y%m%d")
        st.session_state.yfinance_tickers = "AAPL,^MOVE"
        st.session_state.yfinance_interval_label = "æ¯æ—¥"
        st.session_state.fred_series_ids = "DGS10,VIXCLS"
        st.session_state.fetched_data_preview = {}
        st.session_state.fetch_errors = []
        st.session_state.fetch_data_button_clicked = False
        st.session_state.initialized_data_source_settings = True

    if 'initialized_gemini_interaction_settings' not in st.session_state:
        st.session_state.chat_history = []
        st.session_state.active_gemini_key_index = 0
        st.session_state.gemini_api_key_usage = {}
        st.session_state.gemini_caches_list = []
        st.session_state.selected_cache_for_generation = None
        st.session_state.initialized_gemini_interaction_settings = True

    if 'initialized_theme_settings' not in st.session_state:
        st.session_state.active_theme = "dark"
        st.session_state.initialized_theme_settings = True

    if 'initialized_font_settings' not in st.session_state:
        st.session_state.font_size_name = "ä¸­"
        st.session_state.initialized_font_settings = True

    @st.cache_data(ttl=3600)
    def fetch_yfinance_data(tickers_str: str, start_date_str: str, end_date_str: str, interval: str):
        logger.info(f"Fetching yfinance data for tickers: {tickers_str}, interval: {interval}")
        data_frames = {}
        errors = []
        if not tickers_str.strip():
            msg = "Ticker å­—ä¸²ä¸å¯ç‚ºç©ºã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_frames, errors
        list_of_tickers = [ticker.strip().upper() for ticker in tickers_str.split(',') if ticker.strip()]
        if not list_of_tickers:
            msg = "æœªæä¾›æœ‰æ•ˆçš„ Tickerã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_frames, errors
        try:
            start_dt = datetime.strptime(start_date_str, "%Y%m%d")
        except ValueError:
            msg = f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_frames, errors
        try:
            end_dt = datetime.strptime(end_date_str, "%Y%m%d")
        except ValueError:
            msg = f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_frames, errors
        if start_dt > end_dt:
            msg = f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_frames, errors
        for ticker in list_of_tickers:
            try:
                logger.info(f"Downloading yfinance data for {ticker}")
                df = yf.download(ticker, start=start_dt, end=end_dt, interval=interval, progress=False)
                if df.empty:
                    msg = f"Ticker {ticker}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                else:
                    df.reset_index(inplace=True)
                    df.columns = df.columns.astype(str)
                    data_frames[ticker] = df
                    logger.info(f"Successfully downloaded yfinance data for {ticker}")
            except Exception as e:
                msg = f"ä¸‹è¼‰ Ticker {ticker} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
        return data_frames, errors

    @st.cache_data(ttl=86400)
    def fetch_fred_data(series_ids_str: str, start_date_str: str, end_date_str: str, api_key: str):
        logger.info(f"Fetching FRED data for series: {series_ids_str}")
        data_series_dict = {}
        errors = []
        if not api_key:
            msg = "éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªæä¾›ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        try:
            fred = Fred(api_key=api_key)
        except Exception as e:
            msg = f"FRED API é‡‘é‘°åˆå§‹åŒ–å¤±æ•—: {str(e)}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ API é‡‘é‘°ã€‚"
            errors.append(msg)
            logger.error(msg, exc_info=True)
            return data_series_dict, errors
        if not series_ids_str.strip():
            msg = "Series ID å­—ä¸²ä¸å¯ç‚ºç©ºã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        list_of_series_ids = [sid.strip().upper() for sid in series_ids_str.split(',') if sid.strip()]
        if not list_of_series_ids:
            msg = "æœªæä¾›æœ‰æ•ˆçš„ Series IDã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        try:
            start_dt = datetime.strptime(start_date_str, "%Y%m%d")
        except ValueError:
            msg = f"é–‹å§‹æ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {start_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        try:
            end_dt = datetime.strptime(end_date_str, "%Y%m%d")
        except ValueError:
            msg = f"çµæŸæ—¥æœŸæ ¼å¼ç„¡æ•ˆ: {end_date_str}ã€‚è«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        if start_dt > end_dt:
            msg = f"é–‹å§‹æ—¥æœŸ ({start_date_str}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_date_str})ã€‚"
            errors.append(msg)
            logger.error(msg)
            return data_series_dict, errors
        for series_id in list_of_series_ids:
            try:
                logger.info(f"Downloading FRED data for {series_id}")
                series_data = fred.get_series(series_id, observation_start=start_dt, observation_end=end_dt)
                if series_data.empty:
                    msg = f"Series ID {series_id}: åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                else:
                    df = series_data.to_frame(name=series_id)
                    df.reset_index(inplace=True)
                    df.rename(columns={'index': 'Date', series_id: 'Value'}, inplace=True)
                    df['Date'] = pd.to_datetime(df['Date'])
                    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
                    df.dropna(subset=['Value'], inplace=True)
                    data_series_dict[series_id] = df
                    logger.info(f"Successfully downloaded FRED data for {series_id}")
            except ValueError as ve:
                 msg = f"Series ID {series_id} ç„¡æ•ˆæˆ–æ‰¾ä¸åˆ°: {str(ve)}"
                 errors.append(msg)
                 logger.error(msg, exc_info=True)
            except Exception as e:
                msg = f"ä¸‹è¼‰ Series ID {series_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
        return data_series_dict, errors

    NY_FED_POSITIONS_URLS_CORRECTED = [
        "https://markets.newyorkfed.org/api/pd/get/SBN2024/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2022/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11L21_PDPOSGSC-G21.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2015/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBN2013/timeseries/PDPOSGSC-L2_PDPOSGSC-G2L3_PDPOSGSC-G3L6_PDPOSGSC-G6L7_PDPOSGSC-G7L11_PDPOSGSC-G11.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBP2013/timeseries/PDPUSGCS3LNOP_PDPUSGCS36NOP_PDPUSGCS611NOP_PDPUSGCSM11NOP.xlsx",
        "https://markets.newyorkfed.org/api/pd/get/SBP2001/timeseries/PDPUSGCS5LNOP_PDPUSGCS5MNOP.xlsx",
    ]
    SBP_COLS_TO_SUM = {
        "SBP2013": ["PDPUSGCS3LNOP", "PDPUSGCS36NOP", "PDPUSGCS611NOP", "PDPUSGCSM11NOP"],
        "SBP2001": ["PDPUSGCS5LNOP", "PDPUSGCS5MNOP"],
    }

    @st.cache_data(ttl=86400)
    def fetch_ny_fed_data():
        logger.info("Fetching NY Fed Primary Dealer Positions data.")
        all_positions_data = []
        errors = []
        HEADER_ROW_ASSUMPTION = 4
        DATE_COLUMN_INDEX_ASSUMPTION = 0
        for url in NY_FED_POSITIONS_URLS_CORRECTED:
            try:
                logger.info(f"Downloading NY Fed data from {url}")
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                excel_content = io.BytesIO(response.content)
                xls = pd.ExcelFile(excel_content)
                df = pd.read_excel(xls, sheet_name=0, header=HEADER_ROW_ASSUMPTION, index_col=DATE_COLUMN_INDEX_ASSUMPTION)
                df.index = pd.to_datetime(df.index, errors='coerce')
                df = df[df.index.notna()]
                if df.empty:
                    msg = f"æª”æ¡ˆ {url} åœ¨è½‰æ›æ—¥æœŸå¾Œæ²’æœ‰æœ‰æ•ˆæ•¸æ“šã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    continue
                source_type, target_cols = None, []
                if "SBN" in url:
                    source_type = "SBN"
                    target_cols = [col for col in df.columns if str(col).startswith("PDPOSGSC-")]
                elif "SBP2013" in url:
                    source_type = "SBP2013"
                    target_cols = [col for col in SBP_COLS_TO_SUM["SBP2013"] if col in df.columns]
                elif "SBP2001" in url:
                    source_type = "SBP2001"
                    target_cols = [col for col in SBP_COLS_TO_SUM["SBP2001"] if col in df.columns]
                if not target_cols:
                    msg = f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) ä¸­æœªæ‰¾åˆ°ç›®æ¨™æ¬„ä½æˆ–ç›®æ¨™æ¬„ä½åˆ—è¡¨ç‚ºç©ºã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    continue
                df_target = df[target_cols].apply(pd.to_numeric, errors='coerce')
                if df_target.isnull().all().all():
                    msg = f"æª”æ¡ˆ {url} (é¡å‹ {source_type}) çš„ç›®æ¨™æ¬„ä½ {target_cols} è½‰æ›ç‚ºæ•¸å­—å¾Œå‡ç‚ºç©ºå€¼ã€‚"
                    errors.append(msg)
                    logger.warning(msg)
                    continue
                daily_sum = df_target.sum(axis=1)
                all_positions_data.append(daily_sum)
                logger.info(f"Successfully processed NY Fed data from {url}")
            except requests.exceptions.HTTPError as http_err:
                msg = f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”Ÿ HTTP éŒ¯èª¤: {http_err}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
            except requests.exceptions.RequestException as req_err:
                msg = f"ä¸‹è¼‰æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {req_err}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
            except Exception as e:
                msg = f"è™•ç†æª”æ¡ˆ {url} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                errors.append(msg)
                logger.error(msg, exc_info=True)
        if not all_positions_data:
            logger.warning("No data collected from any NY Fed URL.")
            return None, errors
        try:
            final_series = pd.concat(all_positions_data)
            final_series = final_series.groupby(final_series.index).last()
            final_series = final_series.sort_index()
            final_series = final_series.ffill()
            result_df = final_series.to_frame(name="Total_Dealer_Positions")
            result_df.reset_index(inplace=True)
            result_df.rename(columns={'index': 'Date'}, inplace=True)
            logger.info("Successfully combined and processed all NY Fed data.")
        except Exception as e:
            msg = f"åˆä½µå’Œæœ€çµ‚è™•ç† NY Fed æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            errors.append(msg)
            logger.error(msg, exc_info=True)
            return None, errors
        return result_df, errors

    def call_gemini_api(prompt_parts: list, api_keys_list: list, selected_model: str,
                        global_rpm: int, global_tpm: int,
                        generation_config_dict: dict = None, cached_content_name: str = None):
        logger.info(f"Calling Gemini API with model: {selected_model}, cache: {cached_content_name}")
        if not api_keys_list:
            logger.error("Gemini API call failed: No valid API keys provided.")
            return "éŒ¯èª¤ï¼šæœªæä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚"
        active_key_index = st.session_state.get('active_gemini_key_index', 0)
        current_api_key = api_keys_list[active_key_index]
        now = time.time()
        if current_api_key not in st.session_state.gemini_api_key_usage:
            st.session_state.gemini_api_key_usage[current_api_key] = {'requests': [], 'tokens': []}
        st.session_state.gemini_api_key_usage[current_api_key]['requests'] = \
            [ts for ts in st.session_state.gemini_api_key_usage[current_api_key]['requests'] if now - ts < 60]
        if len(st.session_state.gemini_api_key_usage[current_api_key]['requests']) >= global_rpm:
            st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list)
            logger.warning(f"RPM limit reached for API key {current_api_key[:10]}...")
            return f"éŒ¯èª¤ï¼šAPI é‡‘é‘° {current_api_key[:10]}... RPM é”åˆ°ä¸Šé™ ({global_rpm})ã€‚è«‹ç¨å¾Œé‡è©¦æˆ–åˆ‡æ›é‡‘é‘°ã€‚"
        try:
            genai.configure(api_key=current_api_key)
            model = genai.GenerativeModel(model_name=selected_model)
            gen_config_obj = genai.types.GenerationConfig(**generation_config_dict) if generation_config_dict else None
            final_prompt_content = "\n".join(map(str, prompt_parts))
            response = model.generate_content(
                final_prompt_content, generation_config=gen_config_obj, safety_settings=None,
                tools=None, tool_config=None, cached_content=cached_content_name
            )
            st.session_state.gemini_api_key_usage[current_api_key]['requests'].append(now)
            if response.usage_metadata and response.usage_metadata.total_token_count:
                st.session_state.gemini_api_key_usage[current_api_key]['tokens'].append((now, response.usage_metadata.total_token_count))
            st.session_state.active_gemini_key_index = (active_key_index + 1) % len(api_keys_list)
            logger.info("Gemini API call successful.")
            if response.parts: return "".join(part.text for part in response.parts if hasattr(part, 'text'))
            if response.text: return response.text
            logger.warning("Gemini API response has no text/parts.")
            return "æ¨¡å‹æœªè¿”å›æ–‡å­—å…§å®¹ã€‚"
        except genai.types.BlockedPromptException as bpe:
            logger.error(f"Gemini API Error (BlockedPromptException): {bpe}", exc_info=True)
            return f"éŒ¯èª¤ï¼šæç¤ºè©è¢« Gemini API å°é–ã€‚åŸå› : {bpe}"
        except genai.types.generation_types.StopCandidateException as sce:
            logger.error(f"Gemini API Error (StopCandidateException): {sce}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå…§å®¹ç”Ÿæˆå› å®‰å…¨åŸå› æˆ–å…¶ä»–é™åˆ¶è€Œåœæ­¢ã€‚åŸå› : {sce}"
        except google.api_core.exceptions.PermissionDenied as e:
            logger.error(f"Gemini API Error (PermissionDenied): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ¬Šé™ä¸è¶³æˆ–APIé‡‘é‘°ç„¡æ•ˆã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.InvalidArgument as e:
            logger.error(f"Gemini API Error (InvalidArgument): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ™‚åƒæ•¸ç„¡æ•ˆ (ä¾‹å¦‚æ¨¡å‹åç¨±ä¸æ­£ç¢ºæˆ–å…§å®¹ä¸å½“)ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.FailedPrecondition as e:
            logger.error(f"Gemini API Error (FailedPrecondition): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API é è¨­æ¢ä»¶å¤±æ•— (ä¾‹å¦‚ï¼Œæ‰€é¸æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå¿«å–)ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.DeadlineExceeded as e:
            logger.error(f"Gemini API Error (DeadlineExceeded): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API è¶…æ™‚ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.ServiceUnavailable as e:
            logger.error(f"Gemini API Error (ServiceUnavailable): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šGeminiæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.InternalServerError as e:
            logger.error(f"Gemini API Error (InternalServerError): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šGeminiå…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except google.api_core.exceptions.Unknown as e:
            logger.error(f"Gemini API Error (Unknown): {str(e)}", exc_info=True)
            return f"éŒ¯èª¤ï¼šå‘¼å« Gemini API æ™‚ç™¼ç”ŸæœªçŸ¥çš„Google APIéŒ¯èª¤ã€‚è©³ç´°è³‡è¨Š: {str(e)}"
        except Exception as e:
            logger.exception("Unexpected error during Gemini API call:")
            error_message = str(e)
            if hasattr(e, 'message'): error_message = e.message
            elif hasattr(e, 'args') and e.args: error_message = str(e.args[0])
            return f"å‘¼å« Gemini API æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {error_message}"

    # --- Sidebar UI ---
    st.sidebar.title("âš™ï¸ å…¨åŸŸè¨­å®šèˆ‡å·¥å…·")
    st.sidebar.header("ğŸ¨ å¤–è§€ä¸»é¡Œèˆ‡å­—é«”")
    active_theme = st.session_state.get("active_theme", "dark")
    current_theme_label = "æš—è‰²æ¨¡å¼ (Gemini)" if active_theme == "dark" else "äº®è‰²æ¨¡å¼ (é è¨­)"
    toggle_label = f"åˆ‡æ›åˆ° {'äº®è‰²æ¨¡å¼ (é è¨­)' if active_theme == 'dark' else 'æš—è‰²æ¨¡å¼ (Gemini)'}"
    new_toggle_state_is_dark = st.sidebar.toggle(
        toggle_label, value=(active_theme == "dark"), key="theme_toggle_widget", help="é»æ“Šåˆ‡æ›äº®æš—ä¸»é¡Œ"
    )
    if new_toggle_state_is_dark and active_theme == "light":
        st.session_state.active_theme = "dark"; st.experimental_rerun()
    elif not new_toggle_state_is_dark and active_theme == "dark":
        st.session_state.active_theme = "light"; st.experimental_rerun()
    st.sidebar.caption(f"ç›®å‰ä¸»é¡Œ: {current_theme_label}")
    st.sidebar.markdown("##### é¸æ“‡å­—é«”å¤§å°:")
    font_cols = st.sidebar.columns(3)
    if font_cols[0].button("A- (å°)", key="font_small_button", use_container_width=True):
        st.session_state.font_size_name = "å°"; st.experimental_rerun()
    if font_cols[1].button("A (ä¸­)", key="font_medium_button", use_container_width=True):
        st.session_state.font_size_name = "ä¸­"; st.experimental_rerun()
    if font_cols[2].button("A+ (å¤§)", key="font_large_button", use_container_width=True):
        st.session_state.font_size_name = "å¤§"; st.experimental_rerun()
    st.sidebar.caption(f"ç›®å‰å­—é«”: {st.session_state.get('font_size_name', 'ä¸­')}")
    st.sidebar.markdown("---")

    st.sidebar.header("ğŸ”‘ API é‡‘é‘°ç®¡ç†")
    st.sidebar.caption("è«‹åœ¨æ­¤è™•ç®¡ç†æ‚¨çš„ API é‡‘é‘°ã€‚")
    # This specific check for sidebar might be redundant if the main page already shows a big warning,
    # but keeping it doesn't hurt and provides context within the sidebar itself.
    if not are_gemini_keys_valid(): # Using the helper function here as well
        st.sidebar.warning("è­¦å‘Šï¼šè‡³å°‘éœ€è¦ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°æ‰èƒ½ä½¿ç”¨ Gemini åˆ†æåŠŸèƒ½ã€‚")
    for key_name_snake_case, key_label in api_keys_info.items():
        st.session_state[key_name_snake_case] = st.sidebar.text_input(
            key_label, type="password", value=st.session_state[key_name_snake_case], key=f"{key_name_snake_case}_input"
        )
    st.sidebar.success("API é‡‘é‘°å·²æ›´æ–°ä¸¦å„²å­˜åœ¨æœƒè©±ä¸­ã€‚") # This message might appear even if keys are not valid yet.

    st.sidebar.header("ğŸ¤– Gemini æ¨¡å‹è¨­å®š")
    st.sidebar.caption("é¸æ“‡ä¸¦é…ç½®è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ã€‚")
    st.session_state.selected_model_name = st.sidebar.selectbox(
        "é¸æ“‡ Gemini æ¨¡å‹:", options=available_models, index=available_models.index(st.session_state.selected_model_name), key="selected_model_name_selector"
    )
    st.session_state.global_rpm_limit = st.sidebar.number_input(
        "å…¨åŸŸ RPM (æ¯åˆ†é˜è«‹æ±‚æ•¸):", min_value=1, value=st.session_state.global_rpm_limit, step=1, key="global_rpm_limit_input"
    )
    st.session_state.global_tpm_limit = st.sidebar.number_input(
        "å…¨åŸŸ TPM (æ¯åˆ†é˜è©å…ƒæ•¸):", min_value=1000, value=st.session_state.global_tpm_limit, step=10000, key="global_tpm_limit_input"
    )
    st.sidebar.caption("æ³¨æ„ï¼šè«‹åƒè€ƒ Gemini å®˜æ–¹æ–‡ä»¶äº†è§£ä¸åŒæ¨¡å‹çš„å…·é«” RPM/TPM é™åˆ¶ã€‚")
    st.sidebar.header("ğŸ“ ä¸»è¦æç¤ºè©")
    st.sidebar.caption("è¨­å®šç”¨æ–¼æŒ‡å° Gemini åˆ†æçš„ä¸»è¦æç¤ºè©ã€‚")
    st.session_state.main_gemini_prompt = st.sidebar.text_area(
        "ä¸»è¦åˆ†ææç¤ºè© (System Prompt):", value=st.session_state.main_gemini_prompt, height=300, key="main_gemini_prompt_input"
    )
    uploaded_prompt_file = st.sidebar.file_uploader("æˆ–å¾ .txt æª”æ¡ˆè¼‰å…¥æç¤ºè©:", type=["txt"], key="prompt_file_uploader")
    if uploaded_prompt_file is not None:
        prompt_content = uploaded_prompt_file.read().decode("utf-8")
        st.session_state.main_gemini_prompt = prompt_content
    st.sidebar.header("ğŸ§¹ å¿«å–ç®¡ç†")
    st.sidebar.caption("ç®¡ç†æ‡‰ç”¨ç¨‹å¼çš„æ•¸æ“šå¿«å–ã€‚")
    if st.sidebar.button("æ¸…é™¤æ‰€æœ‰æ•¸æ“šå¿«å–", key="clear_all_cache_button"):
        st.cache_data.clear(); logger.info("All data caches cleared.")
        st.sidebar.success("æ‰€æœ‰æ•¸æ“šå¿«å–å·²æˆåŠŸæ¸…é™¤ï¼ä¸‹æ¬¡ç²å–æ•¸æ“šæ™‚å°‡å¾æºé ­é‡æ–°è¼‰å…¥ã€‚")
    st.sidebar.caption("é»æ“Šæ­¤æŒ‰éˆ•å°‡æ¸…é™¤æ‰€æœ‰å·²å¿«å–çš„ yfinance, FRED åŠ NY Fed æ•¸æ“šã€‚")
    st.sidebar.header("ğŸ§  Gemini å…§å®¹å¿«å–")
    st.session_state.cache_display_name_input = st.sidebar.text_input(
        "è¦å¿«å–çš„å…§å®¹åç¨± (ä¾‹å¦‚ system_prompt_cache):", value=st.session_state.get("cache_display_name_input", "system_prompt_main"), key="cache_display_name_input_widget"
    )
    st.session_state.cache_content_input = st.sidebar.text_area(
        "è¦å¿«å–çš„å…§å®¹ (é€šå¸¸æ˜¯ System Prompt):", value=st.session_state.get("cache_content_input", st.session_state.get("main_gemini_prompt","")), height=150, key="cache_content_input_widget"
    )
    st.session_state.cache_ttl_seconds_input = st.sidebar.number_input(
        "å¿«å– TTL (ç§’, e.g., 3600 for 1 hour):", min_value=60, value=st.session_state.get("cache_ttl_seconds_input",3600), key="cache_ttl_input_widget"
    )

    if st.sidebar.button("å‰µå»º/æ›´æ–°å…§å®¹å¿«å–", key="create_cache_button"):
        logger.info(f"Attempting to create/update cache: {st.session_state.cache_display_name_input}")
        gemini_keys_for_cache = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
        valid_gemini_key_for_cache = next((key for key in gemini_keys_for_cache if key), None)
        selected_model_for_cache = st.session_state.get("selected_model_name", "gemini-1.0-pro")
        if valid_gemini_key_for_cache and st.session_state.cache_display_name_input and st.session_state.cache_content_input:
            try:
                genai.configure(api_key=valid_gemini_key_for_cache)
                ttl_str = f"{st.session_state.cache_ttl_seconds_input}s"
                model_for_caching_api = f"models/{selected_model_for_cache}" if not selected_model_for_cache.startswith("models/") else selected_model_for_cache
                cached_content = genai.create_cached_content(
                    model=model_for_caching_api, display_name=st.session_state.cache_display_name_input,
                    system_instruction=st.session_state.cache_content_input, ttl=ttl_str
                )
                st.sidebar.success(f"å¿«å– '{cached_content.display_name}' å·²å‰µå»º/æ›´æ–°ã€‚\nåç¨±: {cached_content.name}")
                logger.info(f"Cache '{cached_content.display_name}' created/updated successfully. Name: {cached_content.name}")
                st.session_state.gemini_caches_list = list(genai.list_cached_contents(api_key=valid_gemini_key_for_cache))
            except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.InvalidArgument,
                    google.api_core.exceptions.FailedPrecondition, google.api_core.exceptions.DeadlineExceeded,
                    google.api_core.exceptions.ServiceUnavailable, google.api_core.exceptions.InternalServerError,
                    google.api_core.exceptions.Unknown) as e:
                logger.error(f"Failed to create/update cache ({type(e).__name__}): {st.session_state.cache_display_name_input} - {str(e)}", exc_info=True)
                st.sidebar.error(f"å‰µå»ºå¿«å–å¤±æ•— ({type(e).__name__}): {str(e)}")
            except Exception as e:
                logger.error(f"Unexpected error creating/updating cache: {st.session_state.cache_display_name_input} - {str(e)}", exc_info=True)
                st.sidebar.error(f"å‰µå»ºå¿«å–æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
        else:
            logger.warning("Cannot create/update cache: Missing Gemini API key, cache name, or content.")
            st.sidebar.warning("è«‹æä¾›æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€å¿«å–åç¨±å’Œå¿«å–å…§å®¹ã€‚")

    if st.sidebar.button("åˆ—å‡ºå¯ç”¨å¿«å–", key="list_caches_button"):
        logger.info("Attempting to list caches.")
        gemini_keys_for_cache_list = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
        valid_gemini_key_for_cache_list = next((key for key in gemini_keys_for_cache_list if key), None)
        if valid_gemini_key_for_cache_list:
            try:
                genai.configure(api_key=valid_gemini_key_for_cache_list)
                st.session_state.gemini_caches_list = list(genai.list_cached_contents())
                if not st.session_state.gemini_caches_list:
                    st.sidebar.info("ç›®å‰æ²’æœ‰å¯ç”¨çš„å…§å®¹å¿«å–ã€‚")
                    logger.info("No caches found.")
                else:
                    logger.info(f"Found {len(st.session_state.gemini_caches_list)} caches.")
            except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.DeadlineExceeded,
                    google.api_core.exceptions.ServiceUnavailable, google.api_core.exceptions.InternalServerError,
                    google.api_core.exceptions.Unknown) as e:
                logger.error(f"Failed to list caches ({type(e).__name__}): {str(e)}", exc_info=True)
                st.sidebar.error(f"åˆ—å‡ºå¿«å–å¤±æ•— ({type(e).__name__}): {str(e)}")
                st.session_state.gemini_caches_list = []
            except Exception as e:
                logger.error(f"Unexpected error listing caches: {str(e)}", exc_info=True)
                st.sidebar.error(f"åˆ—å‡ºå¿«å–æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
                st.session_state.gemini_caches_list = []
        else:
            logger.warning("Cannot list caches: Missing Gemini API key.")
            st.sidebar.warning("è«‹å…ˆè¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆ—å‡ºå¿«å–ã€‚")

    if st.session_state.gemini_caches_list:
        cache_options = {"(ä¸ä½¿ç”¨å¿«å–)": None}
        cache_options.update({f"{c.display_name} ({c.name.split('/')[-1][:8]}...)": c.name for c in st.session_state.gemini_caches_list})
        current_selected_cache_name = st.session_state.get("selected_cache_for_generation", None)
        options_list = list(cache_options.values())
        current_index = options_list.index(current_selected_cache_name) if current_selected_cache_name in options_list else 0
        selected_display_key = st.sidebar.selectbox(
            "é¸æ“‡ä¸€å€‹å¿«å–ç”¨æ–¼ä¸‹æ¬¡ç”Ÿæˆ:", options=list(cache_options.keys()), index=current_index, key="select_cache_dropdown"
        )
        st.session_state.selected_cache_for_generation = cache_options.get(selected_display_key)

    st.session_state.cache_name_to_delete_input = st.sidebar.text_input(
        "è¦åˆªé™¤çš„å¿«å–åç¨± (projects/.../cachedContents/...):", value=st.session_state.get("cache_name_to_delete_input",""), key="cache_name_to_delete_input_widget"
    )
    if st.sidebar.button("åˆªé™¤æŒ‡å®šå¿«å–", key="delete_cache_button"):
        cache_to_delete = st.session_state.cache_name_to_delete_input
        logger.info(f"Attempting to delete cache: {cache_to_delete}")
        if cache_to_delete:
            gemini_keys_for_delete = [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)]
            valid_gemini_key_for_delete = next((key for key in gemini_keys_for_delete if key), None)
            if valid_gemini_key_for_delete:
                try:
                    genai.configure(api_key=valid_gemini_key_for_delete)
                    genai.delete_cached_content(name=cache_to_delete)
                    st.sidebar.success(f"å¿«å– {cache_to_delete} å·²æˆåŠŸåˆªé™¤ã€‚")
                    logger.info(f"Cache {cache_to_delete} deleted successfully.")
                    st.session_state.gemini_caches_list = list(genai.list_cached_contents())
                    if st.session_state.selected_cache_for_generation == cache_to_delete:
                        st.session_state.selected_cache_for_generation = None
                except (google.api_core.exceptions.PermissionDenied, google.api_core.exceptions.NotFound,
                        google.api_core.exceptions.DeadlineExceeded, google.api_core.exceptions.ServiceUnavailable,
                        google.api_core.exceptions.InternalServerError, google.api_core.exceptions.Unknown) as e:
                    logger.error(f"Failed to delete cache {cache_to_delete} ({type(e).__name__}): {str(e)}", exc_info=True)
                    st.sidebar.error(f"åˆªé™¤å¿«å– {cache_to_delete} å¤±æ•— ({type(e).__name__}): {str(e)}")
                except Exception as e:
                    logger.error(f"Unexpected error deleting cache {cache_to_delete}: {str(e)}", exc_info=True)
                    st.sidebar.error(f"åˆªé™¤å¿«å– {cache_to_delete} æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {str(e)}")
            else:
                logger.warning("Cannot delete cache: Missing Gemini API key.")
                st.sidebar.warning("è«‹è¨­å®šæœ‰æ•ˆçš„ Gemini API é‡‘é‘°ä»¥åˆªé™¤å¿«å–ã€‚")
        else:
            logger.warning("Cannot delete cache: Cache name not provided.")
            st.sidebar.warning("è«‹è¼¸å…¥è¦åˆªé™¤çš„å¿«å–åç¨±ã€‚")

    # --- Main Page UI ---
    st.title("é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç†")

    # API Key Check is done earlier, this section is for file uploads etc.
    st.header("ğŸ“„ æ­¥é©Ÿä¸€ï¼šä¸Šå‚³èˆ‡æª¢è¦–æ–‡ä»¶")
    st.caption("è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆã€‚")
    uploaded_files_from_widget = st.file_uploader(
        "è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆ (å¯å¤šé¸ .txt):", type=["txt"], accept_multiple_files=True, key="file_uploader_widget"
    )
    if uploaded_files_from_widget:
        st.session_state.uploaded_files_list = uploaded_files_from_widget
        st.session_state.uploaded_file_contents = {}
        for file_obj in st.session_state.uploaded_files_list:
            try:
                content = file_obj.read().decode("utf-8")
                st.session_state.uploaded_file_contents[file_obj.name] = content
            except Exception as e:
                logger.error(f"è®€å–æª”æ¡ˆ {file_obj.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
                st.error(f"è®€å–æª”æ¡ˆ {file_obj.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        if st.session_state.uploaded_file_contents:
            logger.info(f"Successfully uploaded and read {len(st.session_state.uploaded_file_contents)} files.")
            st.success(f"æˆåŠŸä¸Šå‚³ä¸¦è®€å– {len(st.session_state.uploaded_file_contents)} å€‹æª”æ¡ˆã€‚")

    if st.session_state.uploaded_files_list:
        st.subheader("å·²ä¸Šå‚³æ–‡ä»¶é è¦½:")
        if not st.session_state.uploaded_file_contents and uploaded_files_from_widget:
            st.warning("æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆéƒ½ç„¡æ³•æˆåŠŸè®€å–å…§å®¹ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å…§å®¹ã€‚")
        elif not st.session_state.uploaded_file_contents and not uploaded_files_from_widget:
            st.info("ä¹‹å‰ä¸Šå‚³çš„æª”æ¡ˆå…§å®¹å·²æ¸…é™¤æˆ–ç›®å‰æ²’æœ‰é¸æ“‡æª”æ¡ˆã€‚è«‹é‡æ–°ä¸Šå‚³ã€‚")
        for file_name, content in st.session_state.uploaded_file_contents.items():
            with st.expander(f"æª”å: {file_name} (é»æ“Šå±•é–‹/æ”¶èµ·é è¦½)", expanded=False):
                st.text(content[:500] + "..." if len(content) > 500 else content)
    elif not uploaded_files_from_widget:
        st.info("è«‹ä¸Šå‚³æ–‡å­—æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")

    st.header("ğŸ“Š æ­¥é©ŸäºŒï¼šå¼•å…¥å¤–éƒ¨æ•¸æ“š (å¯é¸)")
    with st.expander("ğŸ“Š æ­¥é©ŸäºŒï¼šé¸æ“‡ä¸¦è¼‰å…¥å¤–éƒ¨æ•¸æ“š (é»æ“Šå±•é–‹/æ”¶èµ·)", expanded=False):
        st.caption("é¸æ“‡ yfinance, FRED, NY Fed ç­‰å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæºï¼Œè¨­å®šåƒæ•¸ä¸¦è¼‰å…¥æ•¸æ“šã€‚")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            select_all_sources_widget = st.checkbox("ğŸŒ å…¨é¸/å–æ¶ˆæ‰€æœ‰æ•¸æ“šæº", value=st.session_state.select_all_sources, key="select_all_sources_cb")
            if select_all_sources_widget != st.session_state.select_all_sources:
                st.session_state.select_all_sources = select_all_sources_widget
                st.session_state.select_yfinance = select_all_sources_widget
                st.session_state.select_fred = select_all_sources_widget
                st.session_state.select_ny_fed = select_all_sources_widget
                st.experimental_rerun()
        with col2: st.session_state.select_yfinance = st.checkbox("ğŸ“ˆ yfinance è‚¡å¸‚æ•¸æ“š", value=st.session_state.select_yfinance, key="select_yfinance_cb")
        with col3: st.session_state.select_fred = st.checkbox("ğŸ¦ FRED ç¸½ç¶“æ•¸æ“š", value=st.session_state.select_fred, key="select_fred_cb")
        with col4: st.session_state.select_ny_fed = st.checkbox("ğŸ‡ºğŸ‡¸ NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š", value=st.session_state.select_ny_fed, key="select_ny_fed_cb")
        date_col1, date_col2 = st.columns(2)
        with date_col1: st.session_state.data_start_date = st.text_input("è¼¸å…¥é–‹å§‹æ—¥æœŸ (YYYYMMDD):", value=st.session_state.data_start_date, key="data_start_date_input")
        with date_col2: st.session_state.data_end_date = st.text_input("è¼¸å…¥çµæŸæ—¥æœŸ (YYYYMMDD):", value=st.session_state.data_end_date, key="data_end_date_input")
        param_col1, param_col2 = st.columns(2)
        interval_options = {"æ¯æ—¥": "1d", "æ¯é€±": "1wk", "æ¯å°æ™‚": "1h", "æ¯5åˆ†é˜": "5m"}
        with param_col1:
            if st.session_state.select_yfinance:
                st.session_state.yfinance_tickers = st.text_input("yfinance è‚¡ç¥¨ä»£ç¢¼ (é€—è™Ÿåˆ†éš”):", value=st.session_state.yfinance_tickers, key="yfinance_tickers_input")
                current_interval_label = st.session_state.yfinance_interval_label
                if current_interval_label not in interval_options: current_interval_label = list(interval_options.keys())[0]; st.session_state.yfinance_interval_label = current_interval_label
                st.session_state.yfinance_interval_label = st.selectbox("yfinance æ•¸æ“šé€±æœŸ:", options=list(interval_options.keys()), index=list(interval_options.keys()).index(current_interval_label), key="yfinance_interval_label_select")
        with param_col2:
            if st.session_state.select_fred:
                st.session_state.fred_series_ids = st.text_input("FRED Series ID (é€—è™Ÿåˆ†éš”):", value=st.session_state.fred_series_ids, key="fred_series_ids_input")
        st.markdown("---")
        if st.button("ğŸ” ç²å–ä¸¦é è¦½é¸å®šæ•¸æ“š", key="fetch_data_button"):
            st.session_state.fetch_data_button_clicked = True; st.session_state.fetched_data_preview = {}; st.session_state.fetch_errors = []
            something_selected = (st.session_state.select_yfinance or st.session_state.select_fred or st.session_state.select_ny_fed)
            if not something_selected: st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ•¸æ“šæºã€‚"); st.session_state.fetch_data_button_clicked = False
            else:
                with st.spinner("æ­£åœ¨ç²å–æ•¸æ“šï¼Œè«‹ç¨å€™..."):
                    if st.session_state.select_yfinance:
                        actual_interval = interval_options[st.session_state.yfinance_interval_label]
                        yfinance_data, yfinance_errs = fetch_yfinance_data(st.session_state.yfinance_tickers, st.session_state.data_start_date, st.session_state.data_end_date, actual_interval)
                        if yfinance_data: st.session_state.fetched_data_preview["yfinance"] = yfinance_data
                        if yfinance_errs: st.session_state.fetch_errors.extend([f"[yfinance] {e}" for e in yfinance_errs])
                    if st.session_state.select_fred:
                        fred_api_key = st.session_state.get("fred_api_key", "")
                        if not fred_api_key: msg = "[FRED] éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªåœ¨å´é‚Šæ¬„è¨­å®šã€‚è«‹å…ˆè¨­å®šã€‚"; st.session_state.fetch_errors.append(msg); logger.error(msg)
                        else:
                            fred_data, fred_errs = fetch_fred_data(st.session_state.fred_series_ids, st.session_state.data_start_date, st.session_state.data_end_date, fred_api_key)
                            if fred_data: st.session_state.fetched_data_preview["fred"] = fred_data
                            if fred_errs: st.session_state.fetch_errors.extend([f"[FRED] {e}" for e in fred_errs])
                    if st.session_state.select_ny_fed:
                        ny_fed_data, ny_fed_errs = fetch_ny_fed_data()
                        if ny_fed_data is not None: st.session_state.fetched_data_preview["ny_fed"] = ny_fed_data
                        if ny_fed_errs: st.session_state.fetch_errors.extend([f"[NY Fed] {e}" for e in ny_fed_errs])
        if st.session_state.fetch_errors:
            st.subheader("æ•¸æ“šç²å–éŒ¯èª¤ï¼š"); [st.error(err_msg) for err_msg in st.session_state.fetch_errors]
        if st.session_state.fetched_data_preview:
            st.subheader("å·²ç²å–æ•¸æ“šé è¦½:")
            if "yfinance" in st.session_state.fetched_data_preview:
                st.markdown("#### yfinance æ•¸æ“š:")
                for ticker, df_yf in st.session_state.fetched_data_preview["yfinance"].items():
                    with st.expander(f"Ticker: {ticker} (å…± {len(df_yf)} è¡Œ)", expanded=False): st.dataframe(df_yf.head())
            if "fred" in st.session_state.fetched_data_preview:
                st.markdown("#### FRED æ•¸æ“š:")
                for series_id, df_fred in st.session_state.fetched_data_preview["fred"].items():
                    with st.expander(f"Series ID: {series_id} (å…± {len(df_fred)} è¡Œ)", expanded=False): st.dataframe(df_fred.head())
            if "ny_fed" in st.session_state.fetched_data_preview and not st.session_state.fetched_data_preview["ny_fed"].empty:
                st.markdown("#### NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š:")
                with st.expander(f"NY Fed ç¸½æŒæœ‰é‡ (å…± {len(st.session_state.fetched_data_preview['ny_fed'])} è¡Œ)", expanded=False): st.dataframe(st.session_state.fetched_data_preview["ny_fed"].head())
            has_data = any((isinstance(ds, dict) and ds) or (isinstance(ds, pd.DataFrame) and not ds.empty) for ds in st.session_state.fetched_data_preview.values())
            if has_data and not st.session_state.fetch_errors: st.success("æ•¸æ“šå·²æˆåŠŸè¼‰å…¥ä¸¦æº–å‚™å¥½ç”¨æ–¼åˆ†æã€‚")
            elif not has_data and not st.session_state.fetch_errors and st.session_state.fetch_data_button_clicked: st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")
        elif st.session_state.fetch_data_button_clicked and not st.session_state.fetch_errors:
            st.info("æœªç²å–åˆ°ä»»ä½•æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„é¸æ“‡å’Œè¼¸å…¥ï¼Œæˆ–ç¢ºèªæ•¸æ“šæºåœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")

    st.header("ğŸ’¬ æ­¥é©Ÿä¸‰ï¼šèˆ‡ Gemini é€²è¡Œåˆ†æèˆ‡è¨è«–")
    chat_container = st.container(height=400)
    with chat_container:
        for message in st.session_state.chat_history:
            avatar_icon = "ğŸ‘¤" if message["role"] == "user" else "âœ¨"
            with st.chat_message(message["role"], avatar=avatar_icon):
                if message["role"] == "model" and message.get("is_error", False): st.error(message["parts"][0])
                else: st.markdown(message["parts"][0])

    user_input = st.chat_input("å‘ Gemini æå•æˆ–çµ¦å‡ºæŒ‡ä»¤ï¼š", key="gemini_user_input")
    if user_input:
        logger.info(f"User input: {user_input}")
        st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
        with st.spinner("Gemini æ­£åœ¨æ€è€ƒä¸­ï¼Œè«‹ç¨å€™..."):
            model_response_text, is_error_response = "", False
            try:
                logger.info("Preparing data and prompt for Gemini.")
                full_prompt_parts = []
                if st.session_state.get("main_gemini_prompt"): full_prompt_parts.append(f"**ä¸»è¦æŒ‡ç¤º (System Prompt):**\n{st.session_state.main_gemini_prompt}\n\n---\n")
                if st.session_state.get("uploaded_file_contents"):
                    uploaded_texts_str = "**å·²ä¸Šå‚³æ–‡ä»¶å…§å®¹æ‘˜è¦:**\n" + "".join([f"æª”å: {fn}\nå…§å®¹ç‰‡æ®µ:\n{ct[:1000]}...\n\n" for fn, ct in st.session_state.uploaded_file_contents.items()])
                    full_prompt_parts.append(uploaded_texts_str + "---\n")
                if st.session_state.get("fetched_data_preview"):
                    external_data_str = "**å·²å¼•å…¥çš„å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæ‘˜è¦:**\n"
                    for source, data_items in st.session_state.fetched_data_preview.items():
                        external_data_str += f"\nä¾†æº: {source.upper()}\n"
                        if source in ["yfinance", "fred"] and isinstance(data_items, dict):
                            for item_name, df_item in data_items.items():
                                if isinstance(df_item, pd.DataFrame): external_data_str += f"  {item_name} (æœ€è¿‘å¹¾ç­†):\n{df_item.tail(3).to_string()}\n"
                        elif source == "ny_fed" and isinstance(data_items, pd.DataFrame) and not data_items.empty:
                             external_data_str += f"  NY Fed ç¸½æŒæœ‰é‡ (æœ€è¿‘å¹¾ç­†):\n{data_items.tail(3).to_string()}\n"
                    full_prompt_parts.append(external_data_str + "---\n")
                full_prompt_parts.append(f"**ä½¿ç”¨è€…ç•¶å‰å•é¡Œ/æŒ‡ä»¤:**\n{user_input}")

                valid_gemini_api_keys = [key for key in [st.session_state.get(f"gemini_api_key_{i+1}","") for i in range(3)] if key and key.strip()]
                selected_model_name = st.session_state.get("selected_model_name", "gemini-1.0-pro")
                generation_config = {"temperature": 0.7, "top_p": 1.0, "top_k": 32, "max_output_tokens": 8192}
                selected_cache_name_for_api = st.session_state.get("selected_cache_for_generation", None)

                if not valid_gemini_api_keys: model_response_text, is_error_response = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„è¨­å®šè‡³å°‘ä¸€å€‹æœ‰æ•ˆçš„ Gemini API é‡‘é‘°ã€‚", True
                elif not selected_model_name: model_response_text, is_error_response = "éŒ¯èª¤ï¼šè«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹ Gemini æ¨¡å‹ã€‚", True
                else:
                    model_response_text = call_gemini_api(
                        prompt_parts=full_prompt_parts, api_keys_list=valid_gemini_api_keys, selected_model=selected_model_name,
                        global_rpm=st.session_state.get("global_rpm_limit", 5), global_tpm=st.session_state.get("global_tpm_limit", 200000),
                        generation_config_dict=generation_config, cached_content_name=selected_cache_name_for_api
                    )
                    if model_response_text.startswith("éŒ¯èª¤ï¼š"):
                        is_error_response = True
                        logger.error(f"Gemini call failed. Response: {model_response_text}")
            except Exception as e:
                logger.exception("Unexpected error during Gemini interaction step:")
                model_response_text, is_error_response = f"è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š {str(e)}", True
            st.session_state.chat_history.append({"role": "model", "parts": [model_response_text], "is_error": is_error_response})
            st.experimental_rerun()

    st.markdown("</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    try:
        main_app_logic()
    except Exception as e:
        fallback_logger = logging.getLogger(__name__)
        fallback_logger.exception("An unhandled exception occurred in main_app_logic:")

        st.error(f"""
        ğŸ˜ æ‡‰ç”¨ç¨‹å¼åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤ ğŸ˜
        å¾ˆæŠ±æ­‰ï¼Œæ‡‰ç”¨ç¨‹å¼é‡åˆ°ä¸€å€‹æœªé æœŸçš„å•é¡Œï¼Œå¯èƒ½ç„¡æ³•æ­£å¸¸é‹ä½œã€‚
        è«‹å˜—è©¦é‡æ–°æ•´ç†é é¢ã€‚å¦‚æœå•é¡ŒæŒçºŒç™¼ç”Ÿï¼Œè«‹è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚
        **éŒ¯èª¤è©³ç´°è³‡è¨Š:**
        é¡å‹: {type(e).__name__}
        è¨Šæ¯: {str(e)}
        """)
