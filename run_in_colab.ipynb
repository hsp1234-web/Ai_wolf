```python
#@title ğŸš€ğŸº Ai_wolf å¤šæ¨¡å¼å•Ÿå‹•å™¨ (Wolf_V5 / Wolf_V6)
#@markdown ### Ai_wolf Multi-Modal Launcher (Wolf_V5 / Wolf_V6)
#@markdown ---
#@markdown **é‡è¦æç¤ºï¼š**
#@markdown 1.  **é¦–æ¬¡åŸ·è¡Œæˆ–åˆ‡æ›æ¨¡å¼å¾Œï¼Œè«‹å‹™å¿…é»æ“Šå·¦ä¸Šè§’çš„ã€ŒåŸ·è¡Œéšæ®µã€->ã€Œé‡æ–°å•Ÿå‹•å·¥ä½œéšæ®µéšæ®µã€**ï¼Œç„¶å¾Œé‡æ–°åŸ·è¡Œæ­¤å„²å­˜æ ¼ï¼Œä»¥ç¢ºä¿ç’°å¢ƒè®Šæ•¸å’Œè·¯å¾‘æ­£ç¢ºæ‡‰ç”¨ã€‚
#@markdown 2.  API é‡‘é‘° (å¦‚ `GEMINI_API_KEY`) æ‡‰å„²å­˜åœ¨ Colab çš„ã€Œå¯†é‘°ã€(Secrets) ä¸­ã€‚æ­¤è…³æœ¬æœƒå˜—è©¦è®€å–å®ƒå€‘ã€‚
#@markdown 3.  **åµéŒ¯æ¨¡å¼ (DEBUG_MODE)** æä¾›é¡å¤–çš„ç³»çµ±å¥åº·æª¢æŸ¥å’Œæ—¥èªŒè¼¸å‡ºï¼Œæœ‰åŠ©æ–¼é–‹ç™¼å’Œå•é¡Œæ’æŸ¥ã€‚
#@markdown ---
#@markdown **é¸æ“‡å•Ÿå‹•æ¨¡å¼ (Mode Selection):**
MODE = "Wolf_V5 (Backend + Frontend)" #@param ["Wolf_V5 (Backend + Frontend)", "Wolf_V6 (Backend Only)", "Wolf_V6 (Frontend Only)"]
#@markdown ---
#@markdown **å°ˆæ¡ˆç›¸é—œè¨­å®š (Project Settings):**
PROJECT_GIT_URL = "https://github.com/hsp1234-web/Ai_wolf.git" #@param {type:"string"}
#@markdown > Google Drive ä¸­çš„å°ˆæ¡ˆæ ¹ç›®éŒ„ (Project root in Google Drive)
GDRIVE_PROJECT_ROOT = "wolfAI" #@param {type:"string"}
#@markdown > Colab æœ¬åœ°å›é€€å°ˆæ¡ˆæ ¹ç›®éŒ„ (Local Colab fallback project root)
LOCAL_PROJECT_ROOT = "wolfAI_local" #@param {type:"string"}
#@markdown > æ‡‰ç”¨ç¨‹å¼ä¸»è¦è³‡æ–™å¤¾ (é€šå¸¸åœ¨ Google Driveï¼Œç”¨æ–¼å­˜æ”¾æ—¥èªŒã€è³‡æ–™åº«ã€å‚™ä»½ç­‰)
APP_DATA_FOLDER_GDRIVE = "Wolf_Data" #@param {type:"string"}
#@markdown ---
#@markdown **åµéŒ¯èˆ‡æ—¥èªŒè¨­å®š (Debug & Logging Settings):**
IS_DEBUG_MODE = True #@param {type:"boolean"}
#@markdown > åµéŒ¯æ¨¡å¼ä¸‹çš„å¾Œç«¯ API æ¸¬è©¦åŸ è™Ÿ (Backend API test port in DEBUG_MODE)
DEBUG_BACKEND_PORT = 8080 #@param {type:"integer"}
#@markdown > Streamlit å‰ç«¯æ‡‰ç”¨ç¨‹å¼åŸ è™Ÿ (Streamlit frontend application port)
STREAMLIT_PORT = 8501 #@param {type:"integer"}
#@markdown ---

import os
import sys
import subprocess
import time
import threading
import shutil
import json # æ–°å¢å°å…¥
from IPython.display import display, HTML, clear_output

# --- ç’°å¢ƒåµæ¸¬èˆ‡å¸¸æ•¸å®šç¾© ---
IN_COLAB = 'google.colab' in sys.modules
GDRIVE_BASE_PATH = "/content/drive/MyDrive"
PROJECT_DIR_GDRIVE = os.path.join(GDRIVE_BASE_PATH, GDRIVE_PROJECT_ROOT)
PROJECT_DIR_LOCAL = f"/content/{LOCAL_PROJECT_ROOT}"
APP_DATA_DIR_GDRIVE = os.path.join(GDRIVE_BASE_PATH, APP_DATA_FOLDER_GDRIVE)
APP_DATA_DIR_LOCAL = f"/content/{APP_DATA_FOLDER_GDRIVE}" # æœ¬åœ°æ¨¡æ“¬çš„è³‡æ–™ç›®éŒ„

# æ ¹æ“šæ¨¡å¼æ±ºå®šå¾Œç«¯å’Œå‰ç«¯çš„åŸ·è¡Œè·¯å¾‘
PROJECT_DIR_TO_USE = None # å°‡åœ¨æ›è¼‰ Drive å¾Œæ±ºå®š
APP_DATA_DIR_TO_USE = None  # å°‡åœ¨æ›è¼‰ Drive å¾Œæ±ºå®š

# å¾Œç«¯ API ç«¯é» (ç”¨æ–¼åµéŒ¯æ¨¡å¼ä¸‹çš„å¥åº·æª¢æŸ¥)
# æ³¨æ„: åŸ è™Ÿå°‡æ ¹æ“š IS_DEBUG_MODE å’Œ MODE å‹•æ…‹èª¿æ•´ (å¾Œç«¯æœå‹™å¯¦éš›ç¶å®šçš„åŸ è™Ÿ)
# ä»¥ä¸‹ URL ä¸­çš„åŸ è™Ÿæ˜¯ç¤ºæ„æ€§çš„ï¼Œå¯¦éš›æ¸¬è©¦æ™‚æœƒä½¿ç”¨ DEBUG_BACKEND_PORT
BACKEND_BASE_URL_DEBUG = f"http://127.0.0.1:{DEBUG_BACKEND_PORT}"
BACKEND_HEALTH_CHECK_URL = f"{BACKEND_BASE_URL_DEBUG}/api/health"
# CORE_API_ENDPOINT ä½¿ç”¨è€…æä¾›çš„æ˜¯ /api/generate
CORE_API_ENDPOINT = f"{BACKEND_BASE_URL_DEBUG}/api/generate"
DATA_FETCH_API_ENDPOINT = f"{BACKEND_BASE_URL_DEBUG}/api/data/fetch"
# AUTH_LOGIN_API_ENDPOINT = f"{BACKEND_BASE_URL_DEBUG}/api/auth/login" # å‡è¨­ç™»å…¥ç«¯é»
# å…¶ä»–ç«¯é» (å¦‚æœè¦åœ¨åµéŒ¯æ¨¡å¼ä¸­æ¸¬è©¦)
# DB_BACKUP_API_ENDPOINT = f"{BACKEND_BASE_URL_DEBUG}/api/db/backup"
# FILE_UPLOAD_API_ENDPOINT = f"{BACKEND_BASE_URL_DEBUG}/api/files/upload"


# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---
def mount_google_drive():
    global PROJECT_DIR_TO_USE, APP_DATA_DIR_TO_USE
    if IN_COLAB:
        from google.colab import drive
        print("æ­£åœ¨å˜—è©¦æ›è¼‰ Google Drive...")
        try:
            drive.mount('/content/drive', force_remount=True)
            print("âœ… Google Drive æ›è¼‰æˆåŠŸï¼")
            PROJECT_DIR_TO_USE = PROJECT_DIR_GDRIVE
            APP_DATA_DIR_TO_USE = APP_DATA_DIR_GDRIVE
            # å‰µå»ºæ‡‰ç”¨ç¨‹å¼è³‡æ–™ç›®éŒ„ (å¦‚æœä¸å­˜åœ¨)
            if not os.path.exists(APP_DATA_DIR_TO_USE):
                os.makedirs(APP_DATA_DIR_TO_USE, exist_ok=True)
                print(f"å·²å‰µå»ºæ‡‰ç”¨ç¨‹å¼è³‡æ–™ç›®éŒ„: {APP_DATA_DIR_TO_USE}")

            # ç‚º Wolf_Data å‰µå»ºå¿…è¦çš„å­ç›®éŒ„çµæ§‹
            sub_dirs_to_create = ["source_documents/masters", "source_documents/shan_jia_lang", "weekly_reports", "logs", "db_backups", "uploaded_files", "AI_data"]
            for sub_dir in sub_dirs_to_create:
                full_sub_dir_path = os.path.join(APP_DATA_DIR_TO_USE, sub_dir)
                if not os.path.exists(full_sub_dir_path):
                    os.makedirs(full_sub_dir_path, exist_ok=True)
                    print(f"    âœ… å­ç›®éŒ„ '{full_sub_dir_path}' å·²å‰µå»ºã€‚")

            return True
        except Exception as e:
            print(f"âš ï¸ Google Drive æ›è¼‰å¤±æ•—: {e}")
            print("   å°‡ä½¿ç”¨ Colab æœ¬åœ°å„²å­˜ç©ºé–“ä½œç‚ºå‚™æ´ã€‚")
            PROJECT_DIR_TO_USE = PROJECT_DIR_LOCAL
            APP_DATA_DIR_TO_USE = APP_DATA_DIR_LOCAL
            # å‰µå»ºæœ¬åœ°è³‡æ–™ç›®éŒ„ (å¦‚æœä¸å­˜åœ¨)
            if not os.path.exists(APP_DATA_DIR_TO_USE):
                os.makedirs(APP_DATA_DIR_TO_USE, exist_ok=True)
                print(f"å·²å‰µå»ºæœ¬åœ°æ‡‰ç”¨ç¨‹å¼è³‡æ–™ç›®éŒ„: {APP_DATA_DIR_TO_USE}")
            return False
    else:
        print("é Colab ç’°å¢ƒï¼Œè·³é Google Drive æ›è¼‰ã€‚")
        PROJECT_DIR_TO_USE = PROJECT_DIR_LOCAL # æˆ–å…¶ä»–æœ¬åœ°è·¯å¾‘
        APP_DATA_DIR_TO_USE = APP_DATA_DIR_LOCAL
        if not os.path.exists(APP_DATA_DIR_TO_USE):
            os.makedirs(APP_DATA_DIR_TO_USE, exist_ok=True)
        return False

def git_clone_or_pull_project():
    print(f"\nè¨­å®šå°ˆæ¡ˆå°‡éƒ¨ç½²æ–¼: {PROJECT_DIR_TO_USE}")
    if os.path.exists(os.path.join(PROJECT_DIR_TO_USE, ".git")):
        print("åµæ¸¬åˆ°å·²å­˜åœ¨çš„å°ˆæ¡ˆï¼Œå˜—è©¦æ›´æ–° (git pull)...")
        try:
            # cwd åƒæ•¸ç¢ºä¿å‘½ä»¤åœ¨æ­£ç¢ºçš„ç›®éŒ„ä¸‹åŸ·è¡Œ
            subprocess.run(["git", "pull"], cwd=PROJECT_DIR_TO_USE, check=True, capture_output=True, text=True)
            print("âœ… å°ˆæ¡ˆæ›´æ–°å®Œæˆï¼")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Git pull å¤±æ•—: {e.stderr}")
            print("   å¯èƒ½åŸå› ï¼šæœ¬åœ°ä¿®æ”¹è¡çªã€‚å¦‚æœå•é¡ŒæŒçºŒï¼Œè«‹è€ƒæ…®æ‰‹å‹•åˆªé™¤ Drive ä¸­çš„å°ˆæ¡ˆç›®éŒ„å¾Œé‡è©¦ã€‚")
            # ä¸çµ‚æ­¢åŸ·è¡Œï¼Œå…è¨±ä½¿ç”¨è€…ç¹¼çºŒå˜—è©¦å•Ÿå‹•
    else:
        print(f"æœªåµæ¸¬åˆ°ç¾æœ‰å°ˆæ¡ˆæ–¼ '{PROJECT_DIR_TO_USE}'ï¼ŒåŸ·è¡Œå…¨æ–°å…‹éš†...")
        if os.path.exists(PROJECT_DIR_TO_USE):
             print(f"   è­¦å‘Šï¼šç›®éŒ„ '{PROJECT_DIR_TO_USE}' å·²å­˜åœ¨ä½†é Git å€‰åº«ã€‚å°‡å˜—è©¦åœ¨æ­¤ç›®éŒ„ä¸­å…‹éš†ã€‚")
        else:
             os.makedirs(PROJECT_DIR_TO_USE, exist_ok=True)

        try:
            subprocess.run(["git", "clone", "--depth", "1", PROJECT_GIT_URL, PROJECT_DIR_TO_USE], check=True, capture_output=True, text=True)
            print("âœ… å°ˆæ¡ˆå…‹éš†å®Œæˆï¼")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Git clone å¤±æ•—: {e.stderr}")
            # å¦‚æœå…‹éš†å¤±æ•—ï¼ŒAPP_DATA_DIR_TO_USE çš„è¨­å®šä¹Ÿå¯èƒ½éœ€è¦èª¿æ•´å›æœ¬åœ°
            raise SystemExit("Git clone å¤±æ•—ï¼Œçµ‚æ­¢åŸ·è¡Œã€‚")

def install_dependencies():
    requirements_path = os.path.join(PROJECT_DIR_TO_USE, "requirements.txt")
    if os.path.exists(requirements_path):
        print("\næ­£åœ¨å®‰è£ä¾è³´å¥—ä»¶ (from requirements.txt)...")
        try:
            subprocess.run([sys.executable, "-m", "pip", "install", "-q", "-r", requirements_path], check=True)
            print("âœ… ä¾è³´å¥—ä»¶å®‰è£å®Œæˆï¼")
        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¾è³´å®‰è£å¤±æ•—: {e}")
            # è€ƒæ…®æ˜¯å¦è¦çµ‚æ­¢åŸ·è¡Œ
    else:
        print("âš ï¸ æœªæ‰¾åˆ° requirements.txtï¼Œè·³éä¾è³´å®‰è£ã€‚")

def set_environment_variables():
    print("\næ­£åœ¨è¨­å®šç’°å¢ƒè®Šæ•¸...")
    os.environ['PROJECT_ROOT_DIR'] = PROJECT_DIR_TO_USE
    os.environ['APP_DATA_DIR'] = APP_DATA_DIR_TO_USE
    # å…¶ä»–å¯èƒ½éœ€è¦çš„ç’°å¢ƒè®Šæ•¸
    # os.environ['PYTHONUNBUFFERED'] = "1" # Streamlit/FastAPI æ—¥èªŒé€šå¸¸éœ€è¦
    print(f"âœ… ç’°å¢ƒè®Šæ•¸ PROJECT_ROOT_DIR å·²è¨­å®šç‚º: {PROJECT_DIR_TO_USE}")
    print(f"âœ… ç’°å¢ƒè®Šæ•¸ APP_DATA_DIR å·²è¨­å®šç‚º: {APP_DATA_DIR_TO_USE}")

def start_backend_service(port):
    print(f"\nå•Ÿå‹•å¾Œç«¯ FastAPI æœå‹™ (åŸ è™Ÿ: {port})...")
    backend_main_path = os.path.join(PROJECT_DIR_TO_USE, "backend", "main.py")
    if not os.path.exists(backend_main_path):
        print(f"âŒ éŒ¯èª¤: å¾Œç«¯ä¸»ç¨‹å¼ backend/main.py æœªæ‰¾åˆ°æ–¼ {PROJECT_DIR_TO_USE}ã€‚")
        return None

    # ä½¿ç”¨ PROJECT_DIR_TO_USE ä½œç‚º app-dirï¼Œç¢ºä¿å¾Œç«¯èƒ½æ­£ç¢ºè§£æå…¶å…§éƒ¨æ¨¡å¡Šè·¯å¾‘
    # æ—¥èªŒæª”æ¡ˆè·¯å¾‘ä¹Ÿæ‡‰è©²æ˜¯åŸºæ–¼ APP_DATA_DIR_TO_USE
    log_file = os.path.join(APP_DATA_DIR_TO_USE, "logs", f"fastapi_backend_{port}.log")
    os.makedirs(os.path.dirname(log_file), exist_ok=True)

    cmd = [
        sys.executable, "-m", "uvicorn",
        "backend.main:app",
        "--host", "0.0.0.0",
        "--port", str(port),
        "--app-dir", PROJECT_DIR_TO_USE, # ç¢ºä¿å¾Œç«¯ FastAPI èƒ½æ‰¾åˆ°å…¶æ¨¡å¡Š
        "--reload" # é–‹ç™¼æ™‚å»ºè­°ä½¿ç”¨ï¼Œç”Ÿç”¢ç’°å¢ƒç§»é™¤
    ]
    print(f"   åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
    print(f"   å¾Œç«¯æ—¥èªŒå°‡è¼¸å‡ºåˆ°: {log_file}")

    with open(log_file, 'wb') as out: # äºŒé€²ä½æ¨¡å¼é–‹å•Ÿï¼Œé¿å…ç·¨ç¢¼å•é¡Œ
        process = subprocess.Popen(cmd, stdout=out, stderr=out, cwd=PROJECT_DIR_TO_USE)

    print(f"   å¾Œç«¯æœå‹™ PID: {process.pid}. ç­‰å¾…ç´„ 10-15 ç§’è®“æœå‹™å®Œæˆåˆå§‹åŒ–...")
    time.sleep(15) # çµ¦äºˆè¶³å¤ æ™‚é–“å•Ÿå‹•

    # æª¢æŸ¥æœå‹™æ˜¯å¦æˆåŠŸå•Ÿå‹• (é€šéæ—¥èªŒæˆ– API health check)
    # æ­¤è™•ç°¡åŒ–ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰æœ‰æ›´ç©©å¥çš„æª¢æŸ¥
    if process.poll() is None:
        print(f"âœ… å¾Œç«¯æœå‹™æ‡‰å·²åœ¨èƒŒæ™¯å•Ÿå‹•ã€‚è«‹æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ {log_file} ç¢ºèªã€‚")
        return process
    else:
        print(f"âŒ å¾Œç«¯æœå‹™å•Ÿå‹•å¤±æ•—æˆ–æ„å¤–çµ‚æ­¢ã€‚è«‹æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ {log_file}ã€‚")
        return None

def start_frontend_service(port):
    print(f"\nå•Ÿå‹•å‰ç«¯ Streamlit æ‡‰ç”¨ç¨‹å¼ (åŸ è™Ÿ: {port})...")
    frontend_app_path = os.path.join(PROJECT_DIR_TO_USE, "app.py")
    if not os.path.exists(frontend_app_path):
        print(f"âŒ éŒ¯èª¤: å‰ç«¯ä¸»ç¨‹å¼ app.py æœªæ‰¾åˆ°æ–¼ {PROJECT_DIR_TO_USE}ã€‚")
        return None, None

    log_file = os.path.join(APP_DATA_DIR_TO_USE, "logs", f"streamlit_frontend_{port}.log")
    os.makedirs(os.path.dirname(log_file), exist_ok=True)

    cmd = [
        sys.executable, "-m", "streamlit", "run", frontend_app_path,
        "--server.port", str(port),
        "--server.headless", "true", # Colab ä¸­å¿…é ˆ
        "--server.enableCORS", "false",
        "--server.enableXsrfProtection", "false"
    ]
    print(f"   åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
    print(f"   å‰ç«¯æ—¥èªŒå°‡è¼¸å‡ºåˆ°: {log_file}")

    streamlit_process = None
    tunnel_url = None

    try:
        with open(log_file, 'wb') as out:
             streamlit_process = subprocess.Popen(cmd, stdout=out, stderr=out, text=False, cwd=PROJECT_DIR_TO_USE) # text=False for binary stream

        print(f"   å‰ç«¯æœå‹™ PID: {streamlit_process.pid if streamlit_process else 'N/A'}. ç­‰å¾…ç´„ 15-30 ç§’è®“æœå‹™å®Œæˆåˆå§‹åŒ–...")
        time.sleep(20) # Streamlit å¯èƒ½éœ€è¦æ›´é•·æ™‚é–“

        if streamlit_process and streamlit_process.poll() is None:
            print("   âœ… å‰ç«¯æœå‹™æ‡‰å·²åœ¨èƒŒæ™¯å•Ÿå‹•ã€‚")
            if IN_COLAB:
                from google.colab.output import eval_js
                print("   å˜—è©¦ç²å– Colab ä»£ç† URL...")
                MAX_RETRIES = 3
                for attempt in range(MAX_RETRIES):
                    try:
                        tunnel_url = eval_js(f'google.colab.kernel.proxyPort({port})', timeout_sec=10)
                        if tunnel_url:
                            print(f"   ğŸ‰ æˆåŠŸç²å– Colab ä»£ç† URL: {tunnel_url}")
                            break
                    except Exception as e:
                        print(f"      ç²å– URL ç¬¬ {attempt+1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                    if attempt < MAX_RETRIES - 1:
                         time.sleep(5)
                if not tunnel_url:
                    print("      âŒ æœªèƒ½ç²å– Colab ä»£ç† URLã€‚")
            else: # æœ¬åœ°ç’°å¢ƒ
                tunnel_url = f"http://localhost:{port}"
                print(f"   æœ¬åœ°ç’°å¢ƒï¼Œè«‹æ‰‹å‹•è¨ªå•: {tunnel_url}")

        else:
            print(f"   âŒ å‰ç«¯æœå‹™å•Ÿå‹•å¤±æ•—æˆ–æ„å¤–çµ‚æ­¢ã€‚è«‹æª¢æŸ¥æ—¥èªŒæª”æ¡ˆ {log_file}ã€‚")
            return None, None

    except Exception as e:
        print(f"âŒ å•Ÿå‹•å‰ç«¯æœå‹™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        if streamlit_process and streamlit_process.poll() is None:
            streamlit_process.terminate()
        return None, None

    return streamlit_process, tunnel_url


# --- æ­¥é©Ÿ 5ï¼šåŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥ (åƒ…é™é™¤éŒ¯æ¨¡å¼) ---
# æ­¤éƒ¨åˆ†åŸºæ–¼ health_check_script_final.py çš„æ ¸å¿ƒé‚è¼¯ï¼Œä¸¦æ•´åˆåˆ°æ­¤ Notebook ä¸­
# æ¸¬è©¦çµæœå°‡ç›´æ¥æ‰“å°åˆ°æ­¤å„²å­˜æ ¼çš„è¼¸å‡º

def run_debug_mode_health_checks():
    print("\n--- æ­¥é©Ÿ 5ï¼šåŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥ (åµéŒ¯æ¨¡å¼) ---")
    all_tests_passed = True
    test_results_summary = []

    # å…¨åŸŸè®Šæ•¸å­˜å„² token (å¦‚æœéœ€è¦)
    # global test_api_auth_token
    # test_api_auth_token = None

    def run_test(test_name, test_function):
        nonlocal all_tests_passed # å…è¨±ä¿®æ”¹å¤–éƒ¨ä½œç”¨åŸŸçš„ all_tests_passed
        print(f"\n[åµéŒ¯] é–‹å§‹æ¸¬è©¦: {test_name}")
        try:
            start_test_time = time.time()
            test_function() # ç›´æ¥èª¿ç”¨ï¼Œä¸å†éœ€è¦å‚³å…¥ result_list
            duration_test = time.time() - start_test_time
            print(f"[åµéŒ¯] âœ… {test_name} æ¸¬è©¦é€šéã€‚è€—æ™‚: {duration_test:.2f} ç§’")
            test_results_summary.append({"name": test_name, "status": "PASS", "duration": f"{duration_test:.2f}s"})
        except AssertionError as e:
            all_tests_passed = False
            duration_test = time.time() - start_test_time
            print(f"[åµéŒ¯] âŒ {test_name} æ¸¬è©¦å¤±æ•—: {e}ã€‚è€—æ™‚: {duration_test:.2f} ç§’")
            test_results_summary.append({"name": test_name, "status": "FAIL", "details": str(e), "duration": f"{duration_test:.2f}s"})
        except Exception as e_general:
            all_tests_passed = False
            duration_test = time.time() - start_test_time
            print(f"[åµéŒ¯] âŒ {test_name} åŸ·è¡Œæ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e_general}ã€‚è€—æ™‚: {duration_test:.2f} ç§’")
            import traceback
            tb_str = traceback.format_exc()
            print(tb_str)
            test_results_summary.append({"name": test_name, "status": "ERROR", "details": str(e_general), "traceback": tb_str, "duration": f"{duration_test:.2f}s"})


    # --- å¥åº·æª¢æŸ¥æ¸¬è©¦å‡½æ•¸å®šç¾© ---
    def test_backend_health():
        print(f"   æ­£åœ¨æª¢æŸ¥å¾Œç«¯å¥åº·ç‹€æ³ ({BACKEND_HEALTH_CHECK_URL})...")
        start_time = time.time()
        response = requests.get(BACKEND_HEALTH_CHECK_URL, timeout=10)
        duration = time.time() - start_time
        print(f"   è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        assert response.status_code == 200, f"é æœŸç‹€æ…‹ç¢¼ 200ï¼Œä½†æ”¶åˆ° {response.status_code}"
        assert response.json()["status"] == "OK", "å¾Œç«¯ API å¥åº·æª¢æŸ¥æœªè¿”å› 'OK'"
        print(f"   å¾Œç«¯ API å¥åº·æª¢æŸ¥æˆåŠŸå›æ‡‰: {response.json()}")

    def test_frontend_access():
        # é€™å€‹æ¸¬è©¦æ¯”è¼ƒåŸºç¤ï¼Œåªç¢ºèª Streamlit URL æ˜¯å¦å­˜åœ¨
        # å¯¦éš›çš„å‰ç«¯æ¸¬è©¦éœ€è¦æ›´è¤‡é›œçš„å·¥å…· (å¦‚ Selenium)
        print(f"   æ­£åœ¨æª¢æŸ¥å‰ç«¯å¯è¨ªå•æ€§ (åŸºæ–¼å…ˆå‰ç²å–çš„ URL)...")
        start_time = time.time()
        # tunnel_url æ˜¯åœ¨å•Ÿå‹•å‰ç«¯æœå‹™æ™‚ç²å–çš„å…¨åŸŸè®Šæ•¸
        assert 'tunnel_url' in globals() and tunnel_url is not None, "å‰ç«¯ tunnel_url æœªè¨­å®šæˆ–ç‚ºç©º"
        print(f"   å‰ç«¯ URL: {tunnel_url}")
        # é€™è£¡ä¸å¯¦éš›è«‹æ±‚ URLï¼Œå› ç‚ºå®ƒå¯èƒ½éœ€è¦ JS æ¸²æŸ“ï¼Œä¸”ä¾è³´ Colab ç’°å¢ƒ
        # åƒ…ç¢ºèª URL å·²ç²å–å³å¯è¦–ç‚ºåˆæ­¥é€šé
        duration = time.time() - start_time
        print(f"   å‰ç«¯ URL ç²å–æª¢æŸ¥è€—æ™‚: {duration:.2f}s")
        print(f"   å‰ç«¯åˆæ­¥æª¢æŸ¥é€šé (URL å·²ç²å–)ã€‚")

    def test_core_api(): # å‡è¨­é€™æ˜¯ /api/generate
        # headers = {'Content-Type': 'application/json'}
        # if test_api_auth_token:
        #     headers["Authorization"] = f"Bearer {test_api_auth_token}"
        headers = {'Content-Type': 'application/json'} # æ ¹æ“šä½¿ç”¨è€…æä¾›çš„ CORE_API_ENDPOINT

        print(f"   æ­£åœ¨æ¸¬è©¦æ ¸å¿ƒ AI API ({CORE_API_ENDPOINT}) ä¸€èˆ¬è«‹æ±‚...")
        # ä½¿ç”¨è€…æä¾›çš„ CORE_API_TEST_PAYLOAD
        CORE_API_TEST_PAYLOAD = {
            "user_message": "ä½ å¥½ï¼ŒAIï¼è«‹å¯«ä¸€å€‹é—œæ–¼å¸‚å ´è¶¨å‹¢çš„ç°¡çŸ­æ‘˜è¦ã€‚",
            "context": {
                "trigger_action": "chat", # æˆ–è€… "general_chat"
                "file_content": None,
                "date_range_for_analysis": None,
                "external_data": None,
                "chat_history": [],
                "selected_modules": ["åˆ€ç–¤è€äºŒ"]
            }
        }
        start_time = time.time()
        response = requests.post(CORE_API_ENDPOINT, headers=headers, json=CORE_API_TEST_PAYLOAD, timeout=45)
        duration = time.time() - start_time
        print(f"   è«‹æ±‚è€—æ™‚: {duration:.2f}s")

        assert response.status_code == 200, f"æ ¸å¿ƒ API é æœŸç‹€æ…‹ç¢¼ 200ï¼Œä½†æ”¶åˆ° {response.status_code}"
        response_json = response.json()
        assert "result" in response_json, "æ ¸å¿ƒ API å›æ‡‰ä¸­ç¼ºå°‘ 'result' æ¬„ä½"
        print(f"   æ ¸å¿ƒ AI API æˆåŠŸå›æ‡‰ï¼Œå…§å®¹ (å‰100å­—ç¬¦): {str(response_json.get('result'))[:100]}...")

    def test_data_fetch_yfinance():
        print("   åŸ·è¡Œ yfinance API æ•¸æ“šç²å–æ¸¬è©¦ (é€šé /api/data/fetch)...")
        base_start_time = time.time()
        headers = {} # å‡è¨­ data_fetch ä¸éœ€è¦ token

        # 1. æœ‰æ•ˆ yfinance Ticker (AAPL)
        yf_payload_valid = {"source": "yfinance", "parameters": {"symbol": "AAPL", "period": "1d"}}
        print(f"     æ­£åœ¨æ¸¬è©¦æœ‰æ•ˆ yfinance Ticker (AAPL) from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        r_yf_valid = requests.post(DATA_FETCH_API_ENDPOINT, json=yf_payload_valid, headers=headers, timeout=15)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        assert r_yf_valid.status_code == 200, f"æœ‰æ•ˆ yfinance Ticker è«‹æ±‚å¤±æ•—, ç‹€æ…‹ç¢¼: {r_yf_valid.status_code}"
        json_yf_valid = r_yf_valid.json()
        assert json_yf_valid.get("success"), f"æœ‰æ•ˆ yfinance Ticker API å›æ‡‰ success: false. Details: {json_yf_valid.get('details', '')}"
        assert not json_yf_valid.get("is_cached"), "æœ‰æ•ˆ yfinance Ticker é¦–æ¬¡è«‹æ±‚ä¸æ‡‰è¢«å¿«å–"
        print(f"     âœ… æœ‰æ•ˆ yfinance Ticker (AAPL) æ¸¬è©¦é€šéã€‚è³‡æ–™ç‰‡æ®µ: {str(json_yf_valid.get('data'))[:70]}...")

        # 2. yfinance Cache Check (AAPL)
        print(f"     æ­£åœ¨æ¸¬è©¦ yfinance Ticker (AAPL) å¿«å– from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        r_yf_cache = requests.post(DATA_FETCH_API_ENDPOINT, json=yf_payload_valid, headers=headers, timeout=15)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        assert r_yf_cache.status_code == 200, f"yfinance Ticker å¿«å–è«‹æ±‚å¤±æ•—, ç‹€æ…‹ç¢¼: {r_yf_cache.status_code}"
        json_yf_cache = r_yf_cache.json()
        assert json_yf_cache.get("success"), f"yfinance Ticker å¿«å– API å›æ‡‰ success: false. Details: {json_yf_cache.get('details', '')}"
        assert json_yf_cache.get("is_cached"), "yfinance Ticker å¿«å–æ¸¬è©¦æœªè¿”å› is_cached: true"
        print("     âœ… yfinance Ticker (AAPL) å¿«å–æ¸¬è©¦é€šéã€‚")

        # 3. ç„¡æ•ˆ yfinance Ticker
        yf_payload_invalid = {"source": "yfinance", "parameters": {"symbol": "INVALIDTICKERXYZ", "period": "1d"}}
        print(f"     æ­£åœ¨æ¸¬è©¦ç„¡æ•ˆ yfinance Ticker from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        r_yf_invalid = requests.post(DATA_FETCH_API_ENDPOINT, json=yf_payload_invalid, headers=headers, timeout=15)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        if r_yf_invalid.status_code == 200:
            assert not r_yf_invalid.json().get("success"), "ç„¡æ•ˆ yfinance Ticker é æœŸ success: falseï¼Œä½† API è¿”å› success: true"
            print("     âœ… ç„¡æ•ˆ yfinance Ticker æ¸¬è©¦é€šé (API è¿”å› success: false)ã€‚")
        elif r_yf_invalid.status_code >= 400:
            print(f"     âœ… ç„¡æ•ˆ yfinance Ticker æ¸¬è©¦é€šé (API è¿”å›éŒ¯èª¤ç‹€æ…‹ç¢¼: {r_yf_invalid.status_code})ã€‚")
        else:
            assert False, f"ç„¡æ•ˆ yfinance Ticker æ¸¬è©¦è¿”å›éé æœŸç‹€æ…‹ç¢¼: {r_yf_invalid.status_code}, content: {r_yf_invalid.text[:100]}"
        print(f"   yfinance API æ•¸æ“šç²å–ç¸½æ¸¬è©¦è€—æ™‚: {time.time() - base_start_time:.2f} ç§’")

    def test_data_fetch_fred():
        print("   åŸ·è¡Œ FRED API æ•¸æ“šç²å–æ¸¬è©¦ (é€šé /api/data/fetch)...")
        base_start_time = time.time()
        headers = {} # å‡è¨­ data_fetch ä¸éœ€è¦ token

        # 1. æœ‰æ•ˆ FRED Series (GNPCA)
        payload_valid = {"source": "fred", "parameters": {"series_id": "GNPCA", "limit": 5}}
        print(f"     æ­£åœ¨æ¸¬è©¦æœ‰æ•ˆ FRED Series (GNPCA) from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        response_valid = requests.post(DATA_FETCH_API_ENDPOINT, json=payload_valid, headers=headers, timeout=20)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        assert response_valid.status_code == 200, f"æœ‰æ•ˆ FRED Series è«‹æ±‚å¤±æ•—, ç‹€æ…‹ç¢¼: {response_valid.status_code}"
        json_valid = response_valid.json()
        assert json_valid.get("success"), f"æœ‰æ•ˆ FRED Series API å›æ‡‰ success: false. Details: {json_valid.get('details', '')}"
        assert json_valid.get("data") and isinstance(json_valid.get("data"), list) and len(json_valid.get("data")) > 0, "æœ‰æ•ˆ FRED Series æœªè¿”å›é æœŸæ•¸æ“šæ ¼å¼"
        assert not json_valid.get("is_cached"), "æœ‰æ•ˆ FRED Series é¦–æ¬¡è«‹æ±‚ä¸æ‡‰è¢«å¿«å–"
        print(f"     âœ… æœ‰æ•ˆ FRED Series (GNPCA) æ¸¬è©¦é€šéã€‚è³‡æ–™ç‰‡æ®µ: {str(json_valid.get('data')[:1])[:70]}...")

        # 2. FRED Cache Check (GNPCA)
        print(f"     æ­£åœ¨æ¸¬è©¦ FRED Series (GNPCA) å¿«å– from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        response_cache = requests.post(DATA_FETCH_API_ENDPOINT, json=payload_valid, headers=headers, timeout=20)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        assert response_cache.status_code == 200, f"FRED Series å¿«å–è«‹æ±‚å¤±æ•—, ç‹€æ…‹ç¢¼: {response_cache.status_code}"
        json_cache = response_cache.json()
        assert json_cache.get("success"), f"FRED Series å¿«å– API å›æ‡‰ success: false. Details: {json_cache.get('details', '')}"
        assert json_cache.get("is_cached"), "FRED Series å¿«å–æ¸¬è©¦æœªè¿”å› is_cached: true"
        print("     âœ… FRED Series (GNPCA) å¿«å–æ¸¬è©¦é€šéã€‚")

        # 3. ç„¡æ•ˆ FRED Series
        payload_invalid = {"source": "fred", "parameters": {"series_id": "INVALIDFREDIDXYZ"}}
        print(f"     æ­£åœ¨æ¸¬è©¦ç„¡æ•ˆ FRED Series from {DATA_FETCH_API_ENDPOINT}...")
        start_time = time.time()
        response_invalid = requests.post(DATA_FETCH_API_ENDPOINT, json=payload_invalid, headers=headers, timeout=20)
        duration = time.time() - start_time
        print(f"     è«‹æ±‚è€—æ™‚: {duration:.2f}s")
        if response_invalid.status_code == 200:
            assert not response_invalid.json().get("success"), "ç„¡æ•ˆ FRED Series é æœŸ success: falseï¼Œä½† API è¿”å› success: true"
            print("     âœ… ç„¡æ•ˆ FRED Series æ¸¬è©¦é€šé (API è¿”å› success: false)ã€‚")
        elif response_invalid.status_code >= 400:
            print(f"     âœ… ç„¡æ•ˆ FRED Series æ¸¬è©¦é€šé (API è¿”å›éŒ¯èª¤ç‹€æ…‹ç¢¼: {response_invalid.status_code})ã€‚")
        else:
            assert False, f"ç„¡æ•ˆ FRED Series æ¸¬è©¦è¿”å›éé æœŸç‹€æ…‹ç¢¼: {response_invalid.status_code}, content: {response_invalid.text[:100]}"
        print(f"   FRED API æ•¸æ“šç²å–ç¸½æ¸¬è©¦è€—æ™‚: {time.time() - base_start_time:.2f} ç§’")

    def test_initial_analysis_with_specific_date():
        print("   åŸ·è¡Œç‰¹å®šæ—¥æœŸ AI å¸‚å ´å›é¡§æ¸¬è©¦...")
        test_start_time = time.time() # Overall test timer

        temp_doc_content = "é€™æ˜¯ä¸€ç¯‡é—œæ–¼å¸‚å ´åˆ†æçš„æ–‡ç« ã€‚\næ—¥æœŸï¼š2023-10-26\næˆ‘å€‘èªç‚ºå¸‚å ´å°‡æœƒä¸Šæ¼²ã€‚"
        aapl_market_data = None # Initialize

        # é ç²å–å¸‚å ´æ•¸æ“š
        external_data_payload = {"source": "yfinance", "parameters": {"symbol": "AAPL", "period": "7d", "end_date": "2023-10-26"}}
        print(f"     æ­£åœ¨å¾ {DATA_FETCH_API_ENDPOINT} é ç²å– AAPL å¸‚å ´æ•¸æ“š...")
        fetch_start_time = time.time()
        # headers_fetch = {"Authorization": f"Bearer {test_api_auth_token}"} if test_api_auth_token else {}
        headers_fetch = {} # Assuming no token for data_fetch
        try:
            response_fetch = requests.post(DATA_FETCH_API_ENDPOINT, json=external_data_payload, headers=headers_fetch, timeout=20)
            fetch_duration = time.time() - fetch_start_time
            print(f"     å¸‚å ´æ•¸æ“šé ç²å–è«‹æ±‚è€—æ™‚: {fetch_duration:.2f}s")
            assert response_fetch.status_code == 200, f"é ç²å–å¸‚å ´æ•¸æ“šå¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response_fetch.status_code}"
            response_fetch_json = response_fetch.json()
            assert response_fetch_json.get("success"), f"é ç²å–å¸‚å ´æ•¸æ“š API å›æ‡‰ success: false. Details: {response_fetch_json.get('details')}"
            aapl_market_data = response_fetch_json.get("data")
            assert aapl_market_data, "é ç²å–çš„å¸‚å ´æ•¸æ“šç‚ºç©º"
            print(f"     æˆåŠŸé ç²å–åˆ° AAPL å¸‚å ´æ•¸æ“šã€‚")
        except Exception as e_fetch:
            fetch_duration = time.time() - fetch_start_time
            print(f"     âŒ é ç²å– AAPL å¸‚å ´æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e_fetch}ã€‚è€—æ™‚: {fetch_duration:.2f}s")
            assert False, f"é ç²å–å¸‚å ´æ•¸æ“šå¤±æ•—: {e_fetch}"

        # æ§‹é€  initial_analysis è«‹æ±‚
        payload = {
            "user_message": "",
            "context": {
                "trigger_action": "initial_analysis",
                "file_content": temp_doc_content,
                "date_range_for_analysis": "2023-10-26",
                "external_data": {"aapl_data": aapl_market_data},
                "chat_history": [],
                "selected_modules": ["åˆ€ç–¤è€äºŒ", "Vincentä½™é„­æ–‡"]
            }
        }
        print(f"     æ­£åœ¨èª¿ç”¨æ ¸å¿ƒ AI ç«¯é» ({CORE_API_ENDPOINT}) é€²è¡Œ initial_analysis...")
        # headers_ai = {"Authorization": f"Bearer {test_api_auth_token}"} if test_api_auth_token else {}
        headers_ai = {'Content-Type': 'application/json'}

        ai_call_start_time = time.time()
        response_ai = requests.post(CORE_API_ENDPOINT, headers=headers_ai, json=payload, timeout=60)
        ai_call_duration = time.time() - ai_call_start_time
        print(f"     æ ¸å¿ƒ AI ç«¯é»èª¿ç”¨è€—æ™‚: {ai_call_duration:.2f}s")

        assert response_ai.status_code == 200, f"AI åˆ†æ API ç‹€æ…‹ç¢¼éŒ¯èª¤: {response_ai.status_code}"
        response_json = response_ai.json()
        assert "result" in response_json, "AI åˆ†æ API å›æ‡‰ä¸­ç¼ºå°‘ 'result' æ¬„ä½"
        ai_reply_markdown = response_json["result"]
        print(f"     AI å›æ‡‰ (å‰100å­—ç¬¦): {ai_reply_markdown[:100]}...")

        assert "A. é€±æ¬¡èˆ‡æ—¥æœŸç¯„åœ:" in ai_reply_markdown, "å ±å‘Šä¸­æœªæ‰¾åˆ° 'A. é€±æ¬¡èˆ‡æ—¥æœŸç¯„åœ:'"
        assert "2023-10-26" in ai_reply_markdown or "2023å¹´10æœˆ26æ—¥" in ai_reply_markdown, "å ±å‘Š A ç« ç¯€æœªæ­£ç¢ºåæ˜ æŒ‡å®šæ—¥æœŸ '2023-10-26'"
        print("     âœ… å ±å‘Š A ç« ç¯€æ—¥æœŸé©—è­‰é€šéã€‚")

        assert "C. ç•¶é€±å¸‚å ´é‡é»å›é¡§:" in ai_reply_markdown, "å ±å‘Šä¸­æœªæ‰¾åˆ° 'C. ç•¶é€±å¸‚å ´é‡é»å›é¡§:'"
        assert "AAPL" in ai_reply_markdown.upper() or "è˜‹æœ" in ai_reply_markdown, "å ±å‘Š C ç« ç¯€å¯èƒ½æœªæåŠ AAPL æˆ–è˜‹æœç›¸é—œå…§å®¹"
        print("     âœ… å ±å‘Š C ç« ç¯€ AAPL æåŠé©—è­‰é€šé (å¯¬é¬†æª¢æŸ¥)ã€‚")

        overall_duration = time.time() - test_start_time
        print(f"   ç‰¹å®šæ—¥æœŸ AI å¸‚å ´å›é¡§æ¸¬è©¦ç¸½è€—æ™‚: {overall_duration:.2f} ç§’")

    # --- åŸ·è¡Œæ¸¬è©¦ ---
    if IS_DEBUG_MODE:
        # run_test("API èªè­‰ç™»å…¥", test_auth_login) # æš«æ™‚ä¸åŸ·è¡Œï¼Œå› å…¶ç‚ºæ¨¡æ“¬
        run_test("å¾Œç«¯ API å¥åº·æª¢æŸ¥", test_backend_health)
        if 'streamlit_process' in globals() and streamlit_process is not None and streamlit_process.poll() is None : # åƒ…åœ¨ V5 æˆ– V6 å‰ç«¯æ¨¡å¼ä¸‹æ¸¬è©¦
             if MODE != "Wolf_V6 (Backend Only)":
                run_test("å‰ç«¯éœæ…‹æª”æ¡ˆå¯è¨ªå•æ€§", test_frontend_access)
        else: # å¦‚æœå‰ç«¯æœªå•Ÿå‹• (ä¾‹å¦‚å¾Œç«¯onlyæ¨¡å¼)ï¼Œå‰‡è·³éæ­¤æ¸¬è©¦
             print("\n[åµéŒ¯] è·³éæ¸¬è©¦: å‰ç«¯éœæ…‹æª”æ¡ˆå¯è¨ªå•æ€§ (å‰ç«¯æœå‹™æœªåœ¨æ­¤æ¨¡å¼ä¸‹å•Ÿå‹•)")
             test_results_summary.append({"name": "å‰ç«¯éœæ…‹æª”æ¡ˆå¯è¨ªå•æ€§", "status": "SKIPPED", "details": "Frontend service not started in this mode."})

        # æ–°å¢çš„æ•´åˆæ¸¬è©¦ (åƒ…åœ¨å¾Œç«¯æœå‹™å•Ÿå‹•å¾ŒåŸ·è¡Œ)
        if backend_process and backend_process.poll() is None:
            run_test("yfinance API æ•¸æ“šç²å–æ•´åˆæ¸¬è©¦", test_data_fetch_yfinance)
            run_test("FRED API æ•¸æ“šç²å–æ•´åˆæ¸¬è©¦", test_data_fetch_fred)
            run_test("æ ¸å¿ƒåŠŸèƒ½ API ç«¯é»ä¸€èˆ¬æ¸¬è©¦", test_core_api) # ç§»åˆ°æ•¸æ“šç²å–ä¹‹å¾Œï¼ŒAIåˆ†æä¹‹å‰
            run_test("ç‰¹å®šæ—¥æœŸ AI å¸‚å ´å›é¡§æ•´åˆæ¸¬è©¦", test_initial_analysis_with_specific_date)
        else:
            print("\n[åµéŒ¯] è·³é API æ•´åˆæ¸¬è©¦ (å¾Œç«¯æœå‹™æœªæˆåŠŸå•Ÿå‹•)")
            for test_name_skip in [
                "yfinance API æ•¸æ“šç²å–æ•´åˆæ¸¬è©¦",
                "FRED API æ•¸æ“šç²å–æ•´åˆæ¸¬è©¦",
                "æ ¸å¿ƒåŠŸèƒ½ API ç«¯é»ä¸€èˆ¬æ¸¬è©¦",
                "ç‰¹å®šæ—¥æœŸ AI å¸‚å ´å›é¡§æ•´åˆæ¸¬è©¦"
            ]:
                test_results_summary.append({"name": test_name_skip, "status": "SKIPPED", "details": "Backend service not started."})

        # --- æ¸¬è©¦çµæœç¸½çµ ---
        print("\n\n--- å¥åº·æª¢æŸ¥çµæœç¸½çµ ---")
        for result in test_results_summary:
            if result['status'] == "PASS":
                print(f"âœ… {result['name']}: PASS (è€—æ™‚: {result.get('duration', 'N/A')})")
            elif result['status'] == "SKIPPED":
                print(f"ğŸŸ¡ {result['name']}: SKIPPED - {result.get('details', '')}")
            else: # FAIL or ERROR
                print(f"âŒ {result['name']}: {result['status']} - {result.get('details', '')} (è€—æ™‚: {result.get('duration', 'N/A')})")
                if result.get('traceback'):
                    print(f"   Traceback:\n{result['traceback']}")

        if all_tests_passed:
            print("\nğŸ‰ æ‰€æœ‰å¥åº·æª¢æŸ¥é€šéï¼")
        else:
            print("\nğŸ’” éƒ¨åˆ†å¥åº·æª¢æŸ¥å¤±æ•—æˆ–å‡ºéŒ¯ï¼Œè«‹æŸ¥çœ‹ä¸Šæ–¹æ—¥èªŒã€‚")
    else:
        print("\n--- åµéŒ¯æ¨¡å¼æœªå•Ÿç”¨ï¼Œè·³éå¥åº·æª¢æŸ¥ ---")
    print("-" * 70 + "\n")


# --- ä¸»åŸ·è¡Œæµç¨‹ ---
def main():
    global backend_process, frontend_process, tunnel_url # å…è¨±ä¿®æ”¹å…¨åŸŸè®Šæ•¸
    backend_process = None
    frontend_process = None
    tunnel_url = None

    clear_output(wait=True)
    print(f"ğŸš€ é¸æ“‡æ¨¡å¼: {MODE}")
    print(f"â³ Colab ç’°å¢ƒ: {IN_COLAB}")
    print(f"   åµéŒ¯æ¨¡å¼: {'å•Ÿç”¨' if IS_DEBUG_MODE else 'é—œé–‰'}")
    print("-" * 70)

    # æ­¥é©Ÿ 1: æ›è¼‰ Google Drive ä¸¦è¨­å®šè·¯å¾‘
    print("\n--- æ­¥é©Ÿ 1: è¨­å®šç’°å¢ƒèˆ‡ç›®éŒ„ ---")
    mount_google_drive()
    print(f"   å°ˆæ¡ˆå°‡ä½¿ç”¨è·¯å¾‘: {PROJECT_DIR_TO_USE}")
    print(f"   æ‡‰ç”¨ç¨‹å¼è³‡æ–™å°‡ä½¿ç”¨è·¯å¾‘: {APP_DATA_DIR_TO_USE}")

    # æ­¥é©Ÿ 2: å…‹éš†æˆ–æ›´æ–°å°ˆæ¡ˆç¨‹å¼ç¢¼
    print("\n--- æ­¥é©Ÿ 2: ç²å–å°ˆæ¡ˆç¨‹å¼ç¢¼ ---")
    git_clone_or_pull_project()

    # æ­¥é©Ÿ 3: å®‰è£ä¾è³´
    print("\n--- æ­¥é©Ÿ 3: å®‰è£ä¾è³´å¥—ä»¶ ---")
    install_dependencies()

    # æ­¥é©Ÿ 4: è¨­å®šç’°å¢ƒè®Šæ•¸
    print("\n--- æ­¥é©Ÿ 4: è¨­å®šç’°å¢ƒè®Šæ•¸ ---")
    set_environment_variables() # ç¢ºä¿ APP_DATA_DIR ç­‰è¢«è¨­å®š

    # æ ¹æ“šæ¨¡å¼å•Ÿå‹•æœå‹™
    backend_port_to_use = DEBUG_BACKEND_PORT if IS_DEBUG_MODE else 8000 # V5/V6 å¾Œç«¯é è¨­ 8000

    if MODE == "Wolf_V5 (Backend + Frontend)":
        backend_process = start_backend_service(backend_port_to_use)
        if backend_process and backend_process.poll() is None:
            frontend_process, tunnel_url = start_frontend_service(STREAMLIT_PORT)
        else:
            print("âŒ å¾Œç«¯æœå‹™å•Ÿå‹•å¤±æ•—ï¼Œç„¡æ³•å•Ÿå‹•å‰ç«¯ã€‚")
    elif MODE == "Wolf_V6 (Backend Only)":
        backend_process = start_backend_service(backend_port_to_use)
    elif MODE == "Wolf_V6 (Frontend Only)":
        # V6 å‰ç«¯å¯èƒ½ä¾è³´ä¸€å€‹å·²åœ¨å…¶ä»–åœ°æ–¹é‹è¡Œçš„å¾Œç«¯ï¼Œæˆ–è€…æœ‰ä¸åŒçš„å•Ÿå‹•é…ç½®
        # æ­¤è™•å‡è¨­å®ƒä»ç„¶éœ€è¦ PROJECT_DIR_TO_USE ä¸­çš„ app.py
        # å¦‚æœ V6 å‰ç«¯æœ‰è‡ªå·±çš„ main.pyï¼Œå‰‡éœ€ä¿®æ”¹ frontend_app_path
        frontend_process, tunnel_url = start_frontend_service(STREAMLIT_PORT)

    # æ­¥é©Ÿ 5: åŸ·è¡Œå¥åº·æª¢æŸ¥ (åƒ…é™åµéŒ¯æ¨¡å¼)
    if IS_DEBUG_MODE:
        # å¥åº·æª¢æŸ¥æ‡‰åœ¨ç›¸é—œæœå‹™å•Ÿå‹•å¾ŒåŸ·è¡Œ
        if MODE == "Wolf_V5 (Backend + Frontend)" and backend_process and backend_process.poll() is None:
            run_debug_mode_health_checks()
        elif MODE == "Wolf_V6 (Backend Only)" and backend_process and backend_process.poll() is None:
            run_debug_mode_health_checks() # å¯ä»¥åªæ¸¬å¾Œç«¯éƒ¨åˆ†
        elif MODE == "Wolf_V6 (Frontend Only)" and frontend_process and frontend_process.poll() is None:
            # å‰ç«¯ only æ¨¡å¼ä¸‹çš„å¥åº·æª¢æŸ¥å¯èƒ½æœ‰é™ï¼Œæˆ–éœ€è¦ç‰¹å®šé…ç½®
            print("\n[åµéŒ¯] å‰ç«¯ Only æ¨¡å¼ï¼ŒåŸ·è¡Œæœ‰é™çš„å¥åº·æª¢æŸ¥ (ä¾‹å¦‚å‰ç«¯è¨ªå•æ€§)ã€‚")
            run_debug_mode_health_checks()
        elif not IS_DEBUG_MODE:
             pass # éåµéŒ¯æ¨¡å¼ä¸åŸ·è¡Œ
        else:
            print("\n[åµéŒ¯] å› æœå‹™å•Ÿå‹•å•é¡Œï¼Œè·³ééƒ¨åˆ†æˆ–å…¨éƒ¨å¥åº·æª¢æŸ¥ã€‚")

    # --- é¡¯ç¤ºæœ€çµ‚è³‡è¨Šèˆ‡ä¿æŒé‹è¡Œ ---
    print("\n\n--- æœå‹™å•Ÿå‹•æ‘˜è¦ ---")
    if MODE == "Wolf_V5 (Backend + Frontend)":
        if backend_process and backend_process.poll() is None:
            print(f"âœ… å¾Œç«¯æœå‹™ (PID: {backend_process.pid}) æ‡‰åœ¨èƒŒæ™¯é‹è¡Œ (åŸ è™Ÿ: {backend_port_to_use})ã€‚")
        else:
            print(f"âŒ å¾Œç«¯æœå‹™æœªèƒ½æˆåŠŸå•Ÿå‹•ã€‚")
        if frontend_process and frontend_process.poll() is None and tunnel_url:
            display(HTML(f"<div style='border:2px solid blue;padding:15px;margin:10px;'>ğŸ‰ å‰ç«¯æ‡‰ç”¨ç¨‹å¼å·²å•Ÿå‹•ï¼é»æ“Šè¨ªå•: <a href='{tunnel_url}' target='_blank'>{tunnel_url}</a></div>"))
            print(f"âœ… å‰ç«¯æœå‹™ (PID: {frontend_process.pid}) æ‡‰åœ¨èƒŒæ™¯é‹è¡Œ (åŸ è™Ÿ: {STREAMLIT_PORT})ã€‚")
        else:
            print(f"âŒ å‰ç«¯æœå‹™æœªèƒ½æˆåŠŸå•Ÿå‹•æˆ–ç²å– URLã€‚")
    elif MODE == "Wolf_V6 (Backend Only)":
        if backend_process and backend_process.poll() is None:
            print(f"âœ… å¾Œç«¯æœå‹™ (PID: {backend_process.pid}) æ‡‰åœ¨èƒŒæ™¯é‹è¡Œ (åŸ è™Ÿ: {backend_port_to_use})ã€‚")
            print(f"   API ç«¯é»æ‡‰åœ¨ http://127.0.0.1:{backend_port_to_use} å¯ç”¨ã€‚")
        else:
            print(f"âŒ å¾Œç«¯æœå‹™æœªèƒ½æˆåŠŸå•Ÿå‹•ã€‚")
    elif MODE == "Wolf_V6 (Frontend Only)":
        if frontend_process and frontend_process.poll() is None and tunnel_url:
            display(HTML(f"<div style='border:2px solid blue;padding:15px;margin:10px;'>ğŸ‰ å‰ç«¯æ‡‰ç”¨ç¨‹å¼å·²å•Ÿå‹•ï¼é»æ“Šè¨ªå•: <a href='{tunnel_url}' target='_blank'>{tunnel_url}</a></div>"))
            print(f"âœ… å‰ç«¯æœå‹™ (PID: {frontend_process.pid}) æ‡‰åœ¨èƒŒæ™¯é‹è¡Œ (åŸ è™Ÿ: {STREAMLIT_PORT})ã€‚")
        else:
            print(f"âŒ å‰ç«¯æœå‹™æœªèƒ½æˆåŠŸå•Ÿå‹•æˆ–ç²å– URLã€‚")

    if (MODE == "Wolf_V5 (Backend + Frontend)" and frontend_process and frontend_process.poll() is None) or \
       (MODE == "Wolf_V6 (Frontend Only)" and frontend_process and frontend_process.poll() is None) or \
       (MODE == "Wolf_V6 (Backend Only)" and backend_process and backend_process.poll() is None) :
        print("\nâ³ æœå‹™æ­£åœ¨é‹è¡Œä¸­ã€‚é—œé–‰æ­¤ç€è¦½å™¨åˆ†é æˆ–ä¸­æ–·æ­¤ Colab Cell çš„åŸ·è¡Œå°‡çµ‚æ­¢æœå‹™ã€‚")
        print("   å¦‚æœéœ€è¦ï¼Œè«‹æª¢æŸ¥å°æ‡‰çš„æ—¥èªŒæª”æ¡ˆä»¥ç²å–è©³ç´°è¼¸å‡ºã€‚")
        try:
            while True:
                time.sleep(60) # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡æœå‹™ç‹€æ…‹
                if backend_process and backend_process.poll() is not None:
                    print(f"\nâš ï¸ å¾Œç«¯æœå‹™ (PID: {backend_process.pid}) å·²æ„å¤–çµ‚æ­¢ã€‚")
                    break
                if frontend_process and frontend_process.poll() is not None:
                    print(f"\nâš ï¸ å‰ç«¯æœå‹™ (PID: {frontend_process.pid}) å·²æ„å¤–çµ‚æ­¢ã€‚")
                    break
                if not backend_process and not frontend_process: # éƒ½æ²’å•Ÿå‹•
                    break
        except KeyboardInterrupt:
            print("\nâŒ¨ï¸ åµæ¸¬åˆ°æ‰‹å‹•ä¸­æ–·ã€‚")
    else:
        print("\nâŒ æœªèƒ½æˆåŠŸå•Ÿå‹•ä»»ä½•æœå‹™æˆ–æ‰€æœ‰æœå‹™å·²çµ‚æ­¢ã€‚")

    # --- æ¸…ç†å·¥ä½œ ---
    print("\n--- åŸ·è¡ŒçµæŸï¼Œé–‹å§‹æ¸…ç† ---")
    if backend_process and backend_process.poll() is None:
        print(f"   æ­£åœ¨çµ‚æ­¢å¾Œç«¯æœå‹™ (PID: {backend_process.pid})...")
        backend_process.terminate()
        backend_process.wait(timeout=10)
    if frontend_process and frontend_process.poll() is None:
        print(f"   æ­£åœ¨çµ‚æ­¢å‰ç«¯æœå‹™ (PID: {frontend_process.pid})...")
        frontend_process.terminate()
        frontend_process.wait(timeout=10)
    print("âœ… æ¸…ç†å®Œæˆã€‚")

# --- åŸ·è¡Œä¸»å‡½æ•¸ ---
if __name__ == '__main__':
    main()

```
