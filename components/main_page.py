# components/main_page.py
import streamlit as st
import logging
import pandas as pd # For displaying DataFrame previews
import os # Ensure os is imported for path operations
# Import the new helper function
from components.chat_interface import add_message_and_process
# Import for Colab Drive path checking
from services.file_processors import handle_file_uploads, ensure_colab_drive_mount_if_needed
import os
import sys
from services.data_fetchers import (
    fetch_yfinance_data,
    fetch_fred_data,
    fetch_ny_fed_data
)
from config.api_keys_config import api_keys_info # For checking Gemini keys
from config import app_settings # Import the whole module for constants

logger = logging.getLogger(__name__)

def _are_gemini_keys_set() -> bool:
    """æª¢æŸ¥ session_state ä¸­æ˜¯å¦è¨­ç½®äº†ä»»ä½• Gemini API é‡‘é‘°ã€‚"""
    for key_label, key_name in api_keys_info.items():
        if "gemini" in key_label.lower() and st.session_state.get(key_name):
            return True
    return False

def render_main_page_content():
    """
    æ¸²æŸ“ä¸»é é¢çš„UIå…§å®¹ã€‚
    åŒ…æ‹¬æ¨™é¡Œã€æ–‡ä»¶ä¸Šå‚³ã€å¤–éƒ¨æ•¸æ“šæºé¸æ“‡å’Œç²å–ã€æ•¸æ“šé è¦½å’ŒéŒ¯èª¤é¡¯ç¤ºç­‰ã€‚
    """
    logger.info("ä¸»é é¢ï¼šé–‹å§‹æ¸²æŸ“ä¸»è¦å…§å®¹ (render_main_page_content)ã€‚")

    # --- Handle Colab Drive Mount Prompt ---
    # This should be near the top to potentially block other rendering or inform user early.
    if st.session_state.get("show_drive_mount_prompt", False):
        path_requested = st.session_state.get("drive_path_requested", "æŒ‡å®šçš„è·¯å¾‘")
        st.warning(
            f"âš ï¸ **Google Drive è·¯å¾‘æœªæ›è¼‰æˆ–ä¸å¯ç”¨**\n\n"
            f"æ‡‰ç”¨ç¨‹å¼éœ€è¦å­˜å– Google Drive ä¸Šçš„è·¯å¾‘ '{path_requested}'ï¼Œä½†è©²è·¯å¾‘ç›®å‰ç„¡æ³•è¨ªå•ã€‚\n\n"
            "å¦‚æœæ‚¨æ­£åœ¨ Colab ç’°å¢ƒä¸­é‹è¡Œæ­¤æ‡‰ç”¨ç¨‹å¼ï¼Œè«‹åŸ·è¡Œç­†è¨˜æœ¬ä¸­çš„ Google Drive æ›è¼‰å„²å­˜æ ¼ï¼Œç„¶å¾Œé»æ“Šä¸‹æ–¹çš„ã€Œé‡è©¦æª”æ¡ˆå­˜å–ã€æŒ‰éˆ•ã€‚",
            icon="ğŸ“"
        )
        if st.button("ğŸ”„ é‡è©¦æª”æ¡ˆå­˜å–", key="drive_retry_button"):
            st.session_state.show_drive_mount_prompt = False # Clear the flag
            # We don't need to set drive_path_requested to "" here,
            # ensure_colab_drive_mount_if_needed will re-check and re-set if still not mounted.
            logger.info("ç”¨æˆ¶é»æ“Š 'é‡è©¦æª”æ¡ˆå­˜å–' æŒ‰éˆ•ã€‚é‡æ–°é‹è¡Œé é¢ã€‚")
            st.rerun()
        # Optionally, you might want to stop further rendering of components that depend on this path
        # For now, the check before os.walk will handle not trying to access it.

    # --- Initialize session state for this page if not already done ---
    if "selected_core_documents" not in st.session_state:
        st.session_state.selected_core_documents = []
        logger.debug("ä¸»é é¢ï¼š'selected_core_documents' åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨ã€‚")
    if "wolf_data_file_map" not in st.session_state: # For storing relative_path -> full_path
        st.session_state.wolf_data_file_map = {}
        logger.debug("ä¸»é é¢ï¼š'wolf_data_file_map' åˆå§‹åŒ–ç‚ºç©ºå­—å…¸ã€‚")

    st.title("é‡‘èåˆ†æèˆ‡æ´å¯ŸåŠ©ç† (ç”± Gemini é©…å‹•)")

    # --- Agent å¿«æ·ä»»å‹™ ---
    st.subheader("ğŸ¤– Agent å¿«æ·ä»»å‹™")
    # prompts_dir = "prompts" # Replaced by app_settings.PROMPTS_DIR
    agent_prompt_files = []
    if os.path.exists(app_settings.PROMPTS_DIR) and os.path.isdir(app_settings.PROMPTS_DIR):
        try:
            agent_prompt_files = sorted([
                f for f in os.listdir(app_settings.PROMPTS_DIR)
                if f.startswith("agent_") and f.endswith(".txt")
            ]) # Sort for consistent order
        except Exception as e:
            logger.error(f"ä¸»é é¢ï¼šè®€å– prompts ç›®éŒ„ '{app_settings.PROMPTS_DIR}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.error(f"ç„¡æ³•è®€å– Agent ä»»å‹™åˆ—è¡¨: {e}")

    if not agent_prompt_files:
        st.info(f"ç›®å‰æ²’æœ‰å¯ç”¨çš„ Agent å¿«æ·ä»»å‹™ã€‚è«‹åœ¨ '{app_settings.PROMPTS_DIR}' æ–‡ä»¶å¤¾ä¸‹æ·»åŠ  'agent_*.txt' æ–‡ä»¶ã€‚")
    else:
        # Determine number of columns, e.g., 3 or 4 per row
        num_cols = min(len(agent_prompt_files), 3) # Max 3 buttons per row, or fewer if less files
        cols = st.columns(num_cols)
        for i, prompt_file in enumerate(agent_prompt_files):
            button_label = prompt_file.replace("agent_", "").replace(".txt", "").replace("_", " ").title()
            # Use session state to manage button clicks to avoid issues with st.rerun if called from elsewhere
            button_key = f"agent_button_{prompt_file}"

            if cols[i % num_cols].button(button_label, key=button_key):
                logger.info(f"ä¸»é é¢ï¼šAgent æŒ‰éˆ• '{button_label}' è¢«é»æ“Šã€‚")
                try:
                    with open(os.path.join(app_settings.PROMPTS_DIR, prompt_file), "r", encoding="utf-8") as f:
                        prompt_content = f.read()

                    # Store the raw prompt. It will be cleared by add_message_and_process if from_agent is True.
                    st.session_state.current_agent_prompt = prompt_content

                    logger.info(f"Agent ä»»å‹™ '{button_label}' çš„æç¤ºè©å·²è¼‰å…¥ã€‚èª¿ç”¨ add_message_and_processã€‚")

                    # Call the helper function from chat_interface.py
                    add_message_and_process(prompt_content, from_agent=True)

                    # Toast is good, st.rerun() is handled by add_message_and_process
                    st.toast(f"Agent ä»»å‹™ '{button_label}' å·²è§¸ç™¼ã€‚", icon="ğŸ¤–")

                except Exception as e:
                    st.error(f"è¼‰å…¥ Agent æç¤ºè© '{prompt_file}' å¤±æ•—: {e}")
                    logger.error(f"è¼‰å…¥ Agent æç¤ºè© '{prompt_file}' å¤±æ•—: {e}")
    st.markdown("---") # åˆ†éš”ç·š

    # --- API é‡‘é‘°ç¼ºå¤±è­¦å‘Š ---
    if not _are_gemini_keys_set():
        st.warning(
            "âš ï¸ **æ ¸å¿ƒåŠŸèƒ½éœ€è¦ Gemini API é‡‘é‘°**\n\n"
            "æ­¤æ‡‰ç”¨ç¨‹å¼çš„æ ¸å¿ƒåˆ†æåŠŸèƒ½ç”± Google Gemini æä¾›æŠ€è¡“æ”¯æ´ã€‚è«‹åœ¨å·¦å´é‚Šæ¬„ã€ŒğŸ”‘ API é‡‘é‘°ç®¡ç†ã€éƒ¨åˆ†è¨­å®šæ‚¨çš„ Gemini API é‡‘é‘°ä»¥å•Ÿç”¨å®Œæ•´åŠŸèƒ½ã€‚\n\n"
            "å¦‚æœæ‚¨é‚„æ²’æœ‰é‡‘é‘°ï¼Œå¯ä»¥é»æ“Šä»¥ä¸‹é€£çµç²å–ï¼š "
            "[é»æ­¤ç²å– Gemini API é‡‘é‘°](https://aistudio.google.com/app/apikey)",
            icon="ğŸ”‘"
        )
        with st.expander("ğŸ”§ å¦‚ä½•è¨­å®š API é‡‘é‘°ï¼Ÿ(ä¸­æ–‡æ•™å­¸)", expanded=False): # é»˜èªä¸å±•é–‹
            st.markdown("""
                ### å¦‚ä½•è¨­å®šåŠä½¿ç”¨ API é‡‘é‘°ï¼š
                1.  **ç²å–é‡‘é‘°**ï¼šå‰å¾€ [Google AI Studio](https://aistudio.google.com/app/apikey) ç¶²ç«™ï¼Œå‰µå»ºä¸¦è¤‡è£½APIé‡‘é‘°ã€‚
                2.  **åœ¨æ‡‰ç”¨ç¨‹å¼ä¸­è¨­å®š**ï¼šåœ¨æœ¬æ‡‰ç”¨ç¨‹å¼çš„å·¦å´é‚Šæ¬„ã€ŒğŸ”‘ API é‡‘é‘°ç®¡ç†ã€éƒ¨åˆ†ï¼Œå°‡é‡‘é‘°è²¼å…¥ä»»ä¸€ Gemini API Key è¼¸å…¥æ¡†ä¸­ã€‚
                3.  **é–‹å§‹ä½¿ç”¨**ï¼šé‡‘é‘°è¨­å®šå®Œæˆå¾Œï¼Œæ‡‰ç”¨ç¨‹å¼çš„ Gemini åˆ†æåŠŸèƒ½å³å¯ä½¿ç”¨ã€‚
                **é‡è¦æç¤º**ï¼šè«‹å¦¥å–„ä¿ç®¡æ‚¨çš„ API é‡‘é‘°ã€‚
            """)
        logger.info("å› ç¼ºå°‘ Gemini API é‡‘é‘°ï¼Œå·²åœ¨ä¸»é é¡¯ç¤ºè­¦å‘Šå’Œè¨­å®šæŒ‡å—ã€‚")

    # --- æ­¥é©Ÿä¸€ï¼šä¸Šå‚³æ–‡ä»¶ ---
    st.header("ğŸ“„ æ­¥é©Ÿä¸€ï¼šä¸Šå‚³èˆ‡æª¢è¦–æ–‡ä»¶")
    st.caption("è«‹ä¸Šå‚³æ‚¨éœ€è¦åˆ†æçš„æ–‡å­—æª”æ¡ˆã€CSV æˆ– Excel æª”æ¡ˆåˆ°ç•¶å‰æœƒè©±ã€‚")
    logger.debug("ä¸»é é¢ï¼šæ¸²æŸ“æ–‡ä»¶ä¸Šå‚³å€åŸŸã€‚")

    uploaded_files_from_widget = st.file_uploader(
        "ä¸Šå‚³æ–°æ–‡ä»¶åˆ°ç•¶å‰æœƒè©± (å¯å¤šé¸):",
        type=["txt", "csv", "xls", "xlsx", "md", "py", "json", "xml", "html", "css", "js"],
        accept_multiple_files=True,
        key="main_file_uploader_widget",
        help="æ­¤è™•ä¸Šå‚³çš„æ–‡ä»¶å°‡å¯ç”¨æ–¼ä¸‹æ–¹é¸æ“‡é€²è¡Œ All-in-One åˆ†æï¼Œæˆ–ç”¨æ–¼å…¶ä»–ç¨ç«‹åˆ†æåŠŸèƒ½ã€‚"
    )

    if uploaded_files_from_widget: # Check if list is not empty
        logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶ä¸Šå‚³äº† {len(uploaded_files_from_widget)} å€‹æª”æ¡ˆã€‚èª¿ç”¨ handle_file_uploads è™•ç†ã€‚")
        handle_file_uploads(uploaded_files_from_widget)
        # handle_file_uploads å…§éƒ¨æœ‰è©³ç´°æ—¥èªŒï¼Œæ­¤è™•åƒ…è¨˜éŒ„ç”¨æˆ¶æ“ä½œå’Œèª¿ç”¨ã€‚

    if st.session_state.get("uploaded_files_list"):
        logger.debug(f"ä¸»é é¢ï¼šé¡¯ç¤ºå·²ä¸Šå‚³æ–‡ä»¶é è¦½ã€‚å…± {len(st.session_state.uploaded_files_list)} å€‹æ–‡ä»¶ã€‚")
        st.subheader("å·²ä¸Šå‚³æ–‡ä»¶é è¦½:")
        if not st.session_state.get("uploaded_file_contents"):
            logger.warning("ä¸»é é¢ï¼šå·²ä¸Šå‚³æ–‡ä»¶åˆ—è¡¨ä¸ç‚ºç©ºï¼Œä½†æ–‡ä»¶å…§å®¹ç‚ºç©ºã€‚")
            st.warning("æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆéƒ½ç„¡æ³•æˆåŠŸè®€å–å…§å®¹ï¼Œæˆ–å°šæœªè™•ç†ã€‚è«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼æˆ–å…§å®¹ã€‚")

        for file_name in st.session_state.uploaded_files_list:
            content_or_df = st.session_state.uploaded_file_contents.get(file_name)
            with st.expander(f"æª”å: {file_name} (é»æ“Šå±•é–‹/æ”¶èµ·é è¦½)", expanded=False):
                if isinstance(content_or_df, str):
                    st.text(content_or_df[:500] + "..." if len(content_or_df) > 500 else content_or_df)
                elif isinstance(content_or_df, pd.DataFrame):
                    st.dataframe(content_or_df.head())
                elif content_or_df is None and file_name in st.session_state.uploaded_files_list: # æ–‡ä»¶ååœ¨åˆ—è¡¨ä¸­ä½†å…§å®¹ç‚ºç©º
                    logger.warning(f"ä¸»é é¢ï¼šé è¦½æ–‡ä»¶ '{file_name}' æ™‚ç™¼ç¾å…¶å…§å®¹ç‚ºç©ºæˆ–è™•ç†å¤±æ•—ã€‚")
                    st.warning(f"æª”æ¡ˆ '{file_name}' çš„å…§å®¹å°šæœªè™•ç†æˆ–è™•ç†å¤±æ•—ã€‚")
                elif content_or_df is not None:
                    logger.debug(f"ä¸»é é¢ï¼šæ–‡ä»¶ '{file_name}' ç‚ºç„¡æ³•ç›´æ¥é è¦½çš„é¡å‹ (ä¾‹å¦‚å­—ç¯€)ã€‚å¤§å°: {len(content_or_df)} å­—ç¯€ã€‚")
                    st.text(f"ç„¡æ³•ç›´æ¥é è¦½æ­¤æª”æ¡ˆé¡å‹ (å¤§å°: {len(content_or_df)} å­—ç¯€)ã€‚")
    else:
        logger.debug("ä¸»é é¢ï¼šç•¶å‰æ²’æœ‰å·²ä¸Šå‚³çš„æª”æ¡ˆã€‚é¡¯ç¤ºæç¤ºä¿¡æ¯ã€‚")
        st.info("è«‹é€šéä¸Šæ–¹çš„ã€Œä¸Šå‚³æ–°æ–‡ä»¶åˆ°ç•¶å‰æœƒè©±ã€æŒ‰éˆ•ä¸Šå‚³æ–‡ä»¶ã€‚")
    st.markdown("---")

    # --- æ­¥é©ŸäºŒï¼šé¸æ“‡æ ¸å¿ƒåˆ†ææ–‡ä»¶ (ç”¨æ–¼ All-in-One å ±å‘Š) ---
    st.header("ğŸ¯ æ­¥é©ŸäºŒï¼šé¸æ“‡æ ¸å¿ƒåˆ†ææ–‡ä»¶ (ç”¨æ–¼ All-in-One å ±å‘Š)")
    st.caption("å¾ `Wolf_Data/source_documents/` æˆ–å·²ä¸Šå‚³çš„æ–‡ä»¶ä¸­é¸æ“‡æ ¸å¿ƒæ–‡æª”ã€‚")
    logger.debug("ä¸»é é¢ï¼šæ¸²æŸ“æ ¸å¿ƒåˆ†ææ–‡ä»¶é¸æ“‡å€åŸŸã€‚")

    # --- Wolf_Data/source_documents/ æ–‡ä»¶æƒæé‚è¼¯ ---
    IN_COLAB_MAIN_PAGE = 'google.colab' in sys.modules # Local check for Colab

    # Construct paths using constants from app_settings
    if IN_COLAB_MAIN_PAGE:
        wolf_data_source_path_to_scan = os.path.join(
            app_settings.COLAB_DRIVE_BASE_PATH,
            app_settings.BASE_DATA_DIR_NAME,
            app_settings.SOURCE_DOCUMENTS_DIR_NAME
        )
    else:
        wolf_data_source_path_to_scan = os.path.join(
            os.path.expanduser(app_settings.USER_HOME_DIR),
            app_settings.BASE_DATA_DIR_NAME,
            app_settings.SOURCE_DOCUMENTS_DIR_NAME
        )

    can_scan_wolf_data = True
    if IN_COLAB_MAIN_PAGE: # Only call ensure_colab_drive_mount_if_needed if in Colab and path is for Colab
        # ensure_colab_drive_mount_if_needed expects the specific path to check,
        # which is wolf_data_source_path_to_scan when in Colab.
        if not ensure_colab_drive_mount_if_needed(wolf_data_source_path_to_scan):
            can_scan_wolf_data = False
            logger.info(f"ä¸»é é¢ï¼šensure_colab_drive_mount_if_needed è¿”å› False for '{wolf_data_source_path_to_scan}'. è·³éæƒæã€‚")
            # The prompt will be shown at the top of the page.
            # We should ensure wolf_data_file_map is empty if we can't scan.
            st.session_state.wolf_data_file_map = {}


    display_name_to_path = {}
    # Only proceed with scanning if the path is considered valid (or not a Colab path needing mount)
    if can_scan_wolf_data and os.path.exists(wolf_data_source_path_to_scan):
        logger.info(f"ä¸»é é¢ï¼šé–‹å§‹æƒæ Wolf_Data ç›®éŒ„: {wolf_data_source_path_to_scan}")
        for root, _, files in os.walk(wolf_data_source_path_to_scan):
            for file in files:
                if file.endswith((".txt", ".md")):
                    full_path = os.path.join(root, file)
                    relative_path = os.path.relpath(full_path, wolf_data_source_path_to_scan)
                    display_name_to_path[relative_path] = full_path
        st.session_state.wolf_data_file_map = display_name_to_path
        logger.info(f"ä¸»é é¢ï¼šæƒæåˆ° {len(display_name_to_path)} å€‹æ–‡ä»¶å¾ Wolf_Dataã€‚")
    elif can_scan_wolf_data and not os.path.exists(wolf_data_source_path_to_scan):
        # This case handles if not IN_COLAB_MAIN_PAGE and local path doesn't exist,
        # or if ensure_colab_drive_mount_if_needed passed but path still somehow not found (less likely for Colab)
        logger.warning(f"ä¸»é é¢ï¼šWolf_Data ç›®éŒ„ '{wolf_data_source_path_to_scan}' ä¸å­˜åœ¨ (can_scan_wolf_data was True)ã€‚")
        st.session_state.wolf_data_file_map = {}
    # If can_scan_wolf_data is False, wolf_data_file_map is already set to {} above.

    multiselect_options_wolf = list(st.session_state.get("wolf_data_file_map", {}).keys())

    # --- å·²ä¸Šå‚³æ–‡ä»¶åˆ—è¡¨ (ä½œç‚ºå‚™é¸æˆ–è£œå……) ---
    # ä¿æŒ uploaded_files_list çš„å¯ç”¨æ€§ï¼Œä½†å„ªå…ˆé¡¯ç¤º Wolf_Data çš„æ–‡ä»¶
    # å¦‚æœ Wolf_Data ç‚ºç©ºï¼Œå¯ä»¥è€ƒæ…®ä½¿ç”¨ uploaded_files_list ä½œç‚ºå‚™é¸

    final_multiselect_options = multiselect_options_wolf
    info_message = ""

    if not final_multiselect_options:
        info_message = f"æç¤ºï¼šåœ¨ '{wolf_data_source_path_to_scan}' ä¸­æœªæ‰¾åˆ° .txt æˆ– .md æ–‡ä»¶ã€‚æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸Šæ–¹ã€Œæ­¥é©Ÿä¸€ã€ä¸Šå‚³è‡¨æ™‚æ–‡ä»¶ã€‚"
        # Fallback to uploaded files if Wolf_Data is empty and uploaded_files_list is not
        # For now, let's keep it simple and prioritize Wolf_Data. If Wolf_Data is empty, user sees that.
        # Fallback can be added later if needed.
        # options_for_multiselect = st.session_state.get("uploaded_files_list", [])
        # if options_for_multiselect:
        #     info_message += " æ‚¨å¯ä»¥å¾å·²ä¸Šå‚³çš„æ–‡ä»¶ä¸­é¸æ“‡ï¼š"
        # else:
        #     options_for_multiselect = ["ç¤ºä¾‹-ç„¡å¯ç”¨æ–‡ä»¶.txt"] # Placeholder if everything is empty
        #     info_message += " ä¹Ÿæ²’æœ‰å·²ä¸Šå‚³çš„æ–‡ä»¶ã€‚"
        st.info(info_message)
        # If final_multiselect_options is empty, ensure multiselect doesn't break
        if not final_multiselect_options: final_multiselect_options = ["ç›®å‰ç„¡å¯é¸æ–‡ä»¶"]


    else:
        st.info(f"è«‹å¾ '{os.path.basename(wolf_data_source_path_to_scan.rstrip(os.sep))}' ç›®éŒ„ (æˆ–å…¶å­ç›®éŒ„) ä¸­é¸æ“‡æ–‡ä»¶ã€‚")

    # ä½¿ç”¨ relative paths (keys of wolf_data_file_map) for selection
    # st.session_state.selected_core_documents should store these relative paths
    selected_relative_paths = st.multiselect(
        "é¸æ“‡è¦é€²è¡Œ All-in-One ç¶œåˆåˆ†æçš„æ–‡ä»¶ (å¯è¤‡é¸):",
        options=sorted(final_multiselect_options), # Sort for better UX
        default=st.session_state.selected_core_documents,
        key="main_selected_core_documents_multiselect"
    )

    if selected_relative_paths != st.session_state.selected_core_documents:
        st.session_state.selected_core_documents = selected_relative_paths
        logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶é¸æ“‡çš„æ ¸å¿ƒåˆ†ææ–‡ä»¶ (ç›¸å°è·¯å¾‘) å·²æ›´æ–°: {selected_relative_paths}")

    if st.session_state.selected_core_documents:
        st.markdown("##### å·²é¸å®šæ ¸å¿ƒæ–‡ä»¶ (ç›¸å°è·¯å¾‘):")
        for rel_path_doc_name in st.session_state.selected_core_documents:
            st.markdown(f"- {rel_path_doc_name}")
    else:
        st.caption("å°šæœªé¸å®šä»»ä½•æ ¸å¿ƒæ–‡ä»¶ã€‚")

    st.markdown("---")


    # --- æ­¥é©Ÿä¸‰ï¼šå¼•å…¥å¤–éƒ¨æ•¸æ“š ---
    st.header("ğŸ“Š æ­¥é©Ÿä¸‰ï¼šå¼•å…¥å¤–éƒ¨æ•¸æ“š (å¯é¸)")
    logger.debug("ä¸»é é¢ï¼šæ¸²æŸ“å¤–éƒ¨æ•¸æ“šæºé¸æ“‡å€åŸŸã€‚")
    with st.expander("ğŸ“Š è¨­å®šä¸¦è¼‰å…¥å¤–éƒ¨æ•¸æ“š (é»æ“Šå±•é–‹/æ”¶èµ·)", expanded=False):
        st.caption("é¸æ“‡ yfinance, FRED, NY Fed ç­‰å¤–éƒ¨å¸‚å ´èˆ‡ç¸½ç¶“æ•¸æ“šæºï¼Œè¨­å®šåƒæ•¸ä¸¦è¼‰å…¥æ•¸æ“šã€‚")

        # ç¢ºä¿ç›¸é—œ session_state éµå·²ç”± session_state_manager åˆå§‹åŒ–
        # æ­¤è™•ä¸å†é‡è¤‡åˆå§‹åŒ–ï¼Œä»¥ä¾è³´ manager çš„çµ±ä¸€ç®¡ç†

        col_sel1, col_sel2, col_sel3, col_sel4 = st.columns(4)
        with col_sel1:
            old_select_all = st.session_state.get("select_all_sources", False)
            new_select_all = st.checkbox("ğŸŒ å…¨é¸æ•¸æ“šæº", value=old_select_all, key="main_select_all_cb")
            if new_select_all != old_select_all:
                st.session_state.select_all_sources = new_select_all
                st.session_state.select_yfinance = new_select_all
                st.session_state.select_fred = new_select_all
                st.session_state.select_ny_fed = new_select_all
                logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶æ›´æ”¹'å…¨é¸æ•¸æ“šæº'ç‚º {new_select_all}ã€‚")
                st.rerun()
        with col_sel2:
            old_yf = st.session_state.get("select_yfinance", False)
            new_yf = st.checkbox("ğŸ“ˆ yfinance", value=old_yf, key="main_select_yfinance_cb")
            if new_yf != old_yf:
                st.session_state.select_yfinance = new_yf
                logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶æ›´æ”¹'yfinance'é¸æ“‡ç‚º {new_yf}ã€‚")
        with col_sel3:
            old_fred = st.session_state.get("select_fred", False)
            new_fred = st.checkbox("ğŸ¦ FRED", value=old_fred, key="main_select_fred_cb")
            if new_fred != old_fred:
                st.session_state.select_fred = new_fred
                logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶æ›´æ”¹'FRED'é¸æ“‡ç‚º {new_fred}ã€‚")
        with col_sel4:
            old_nyf = st.session_state.get("select_ny_fed", False)
            new_nyf = st.checkbox("ğŸ‡ºğŸ‡¸ NY Fed", value=old_nyf, key="main_select_nyfed_cb")
            if new_nyf != old_nyf:
                st.session_state.select_ny_fed = new_nyf
                logger.info(f"ä¸»é é¢ï¼šç”¨æˆ¶æ›´æ”¹'NY Fed'é¸æ“‡ç‚º {new_nyf}ã€‚")


        date_col1, date_col2 = st.columns(2)
        with date_col1:
            old_start_date = st.session_state.get("data_start_date", "")
            new_start_date = st.text_input("é–‹å§‹æ—¥æœŸ (YYYYMMDD):", value=old_start_date, key="main_data_start_date")
            if new_start_date != old_start_date:
                st.session_state.data_start_date = new_start_date
                logger.debug(f"ä¸»é é¢ï¼šæ•¸æ“šé–‹å§‹æ—¥æœŸæ›´æ”¹ç‚º {new_start_date}")
        with date_col2:
            old_end_date = st.session_state.get("data_end_date", "")
            new_end_date = st.text_input("çµæŸæ—¥æœŸ (YYYYMMDD):", value=old_end_date, key="main_data_end_date")
            if new_end_date != old_end_date:
                st.session_state.data_end_date = new_end_date
                logger.debug(f"ä¸»é é¢ï¼šæ•¸æ“šçµæŸæ—¥æœŸæ›´æ”¹ç‚º {new_end_date}")

        param_col1, param_col2 = st.columns(2)
        with param_col1:
            if st.session_state.get("select_yfinance"):
                old_yf_tickers = st.session_state.get("yfinance_tickers", "")
                new_yf_tickers = st.text_input("yfinance Tickers (é€—è™Ÿåˆ†éš”):", value=old_yf_tickers, key="main_yfinance_tickers")
                if new_yf_tickers != old_yf_tickers:
                    st.session_state.yfinance_tickers = new_yf_tickers
                    logger.debug(f"ä¸»é é¢ï¼šyfinance tickers æ›´æ”¹ç‚º '{new_yf_tickers}'")

                old_yf_interval = st.session_state.get("yfinance_interval_label", "1 Day")
                new_yf_interval = st.selectbox(
                    "yfinance æ•¸æ“šé€±æœŸ:",
                    options=list(app_settings.YFINANCE_INTERVAL_OPTIONS.keys()),
                    index=list(app_settings.YFINANCE_INTERVAL_OPTIONS.keys()).index(old_yf_interval) if old_yf_interval in app_settings.YFINANCE_INTERVAL_OPTIONS else 0,
                    key="main_yfinance_interval"
                )
                if new_yf_interval != old_yf_interval:
                    st.session_state.yfinance_interval_label = new_yf_interval
                    logger.debug(f"ä¸»é é¢ï¼šyfinance interval æ›´æ”¹ç‚º '{new_yf_interval}'")
        with param_col2:
            if st.session_state.get("select_fred"):
                old_fred_ids = st.session_state.get("fred_series_ids", app_settings.DEFAULT_FRED_SERIES_IDS) # Use default from settings
                new_fred_ids = st.text_input("FRED Series IDs (é€—è™Ÿåˆ†éš”):", value=old_fred_ids, key="main_fred_ids")
                if new_fred_ids != old_fred_ids:
                    st.session_state.fred_series_ids = new_fred_ids
                    logger.debug(f"ä¸»é é¢ï¼šFRED Series IDs æ›´æ”¹ç‚º '{new_fred_ids}'")

        if st.button("ğŸ” ç²å–ä¸¦é è¦½é¸å®šæ•¸æ“š", key="main_fetch_data_button"):
            logger.info("ä¸»é é¢ï¼šç”¨æˆ¶é»æ“Š 'ç²å–ä¸¦é è¦½é¸å®šæ•¸æ“š' æŒ‰éˆ•ã€‚")
            st.session_state.fetch_data_button_clicked = True
            st.session_state.fetched_data_preview = {}
            st.session_state.fetch_errors = {}

            if not (st.session_state.get("select_yfinance") or st.session_state.get("select_fred") or st.session_state.get("select_ny_fed")):
                logger.warning("ä¸»é é¢ï¼šç”¨æˆ¶é»æ“Šç²å–æ•¸æ“šä½†æœªé¸æ“‡ä»»ä½•æ•¸æ“šæºã€‚")
                st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ•¸æ“šæºã€‚")
                st.session_state.fetch_data_button_clicked = False
            else:
                with st.spinner("æ­£åœ¨ç²å–å¤–éƒ¨æ•¸æ“š...è«‹ç¨å€™..."):
                    st.toast("â³ æ­£åœ¨å¾å¤–éƒ¨æºç²å–æ•¸æ“šï¼Œè«‹è€å¿ƒç­‰å€™...", icon="â³")
                    logger.debug("ä¸»é é¢ï¼šé–‹å§‹ç²å–æ‰€é¸å¤–éƒ¨æ•¸æ“šã€‚")
                    if st.session_state.get("select_yfinance"):
                        actual_yf_interval = app_settings.YFINANCE_INTERVAL_OPTIONS[st.session_state.yfinance_interval_label]
                        current_yf_tickers = st.session_state.get("yfinance_tickers", app_settings.DEFAULT_YFINANCE_TICKERS) # Use default
                        logger.info(f"ä¸»é é¢ï¼šæº–å‚™èª¿ç”¨ fetch_yfinance_dataã€‚Tickers: {current_yf_tickers}, Start: {st.session_state.data_start_date}, End: {st.session_state.data_end_date}, Interval: {actual_yf_interval}")
                        yf_data, yf_errs = fetch_yfinance_data(
                            current_yf_tickers, st.session_state.data_start_date,
                            st.session_state.data_end_date, actual_yf_interval
                        )
                        if yf_data: st.session_state.fetched_data_preview["yfinance"] = yf_data
                        if yf_errs: st.session_state.fetch_errors["yfinance"] = yf_errs
                        logger.info(f"ä¸»é é¢ï¼šfetch_yfinance_data èª¿ç”¨å®Œç•¢ã€‚ç²å– {len(yf_data)} çµ„æ•¸æ“šï¼Œ{len(yf_errs)} å€‹éŒ¯èª¤ã€‚")

                    if st.session_state.get("select_fred"):
                        fred_api_key_val = ""
                        fred_key_name_in_session = next((k_name for k_label, k_name in api_keys_info.items() if "fred" in k_label.lower()), None)
                        if fred_key_name_in_session:
                            fred_api_key_val = st.session_state.get(fred_key_name_in_session, "")

                        if not fred_api_key_val:
                            logger.error("ä¸»é é¢ï¼šFRED API é‡‘é‘°æœªè¨­å®šï¼Œç„¡æ³•ç²å– FRED æ•¸æ“šã€‚")
                            st.session_state.fetch_errors["fred"] = ["éŒ¯èª¤ï¼šFRED API é‡‘é‘°æœªåœ¨å´é‚Šæ¬„çš„ API é‡‘é‘°ç®¡ç†ä¸­è¨­å®šã€‚"]
                        else:
                            logger.info(f"ä¸»é é¢ï¼šæº–å‚™èª¿ç”¨ fetch_fred_dataã€‚Series IDs: {st.session_state.fred_series_ids}, Start: {st.session_state.data_start_date}, End: {st.session_state.data_end_date}, Key_Present: {bool(fred_api_key_val)}")
                            fred_data, fred_errs = fetch_fred_data(
                                st.session_state.fred_series_ids, st.session_state.data_start_date,
                                st.session_state.data_end_date, fred_api_key_val
                            )
                            if fred_data: st.session_state.fetched_data_preview["fred"] = fred_data
                            if fred_errs: st.session_state.fetch_errors["fred"] = fred_errs
                            logger.info(f"ä¸»é é¢ï¼šfetch_fred_data èª¿ç”¨å®Œç•¢ã€‚ç²å– {len(fred_data)} çµ„æ•¸æ“šï¼Œ{len(fred_errs)} å€‹éŒ¯èª¤ã€‚")

                    if st.session_state.get("select_ny_fed"):
                        logger.info("ä¸»é é¢ï¼šæº–å‚™èª¿ç”¨ fetch_ny_fed_dataã€‚")
                        nyfed_df, nyfed_errs = fetch_ny_fed_data()
                        if nyfed_df is not None: st.session_state.fetched_data_preview["ny_fed"] = nyfed_df
                        if nyfed_errs: st.session_state.fetch_errors["ny_fed"] = nyfed_errs
                        logger.info(f"ä¸»é é¢ï¼šfetch_ny_fed_data èª¿ç”¨å®Œç•¢ã€‚ç²å–æ•¸æ“š: {'æ˜¯' if nyfed_df is not None else 'å¦'}ï¼Œ{len(nyfed_errs)} å€‹éŒ¯èª¤ã€‚")

                if not st.session_state.get("fetch_errors") and st.session_state.get("fetched_data_preview"):
                    logger.info("ä¸»é é¢ï¼šå¤–éƒ¨æ•¸æ“šå·²æˆåŠŸç²å–ä¸”ç„¡éŒ¯èª¤å ±å‘Šã€‚")
                    st.success("å¤–éƒ¨æ•¸æ“šå·²æˆåŠŸç²å–ã€‚")
                elif not st.session_state.get("fetched_data_preview") and not st.session_state.get("fetch_errors"):
                     logger.info("ä¸»é é¢ï¼šæœªç²å–åˆ°ä»»ä½•å¤–éƒ¨æ•¸æ“šï¼Œä¸”ç„¡éŒ¯èª¤å ±å‘Šã€‚")
                     st.info("æœªç²å–åˆ°ä»»ä½•å¤–éƒ¨æ•¸æ“šã€‚è«‹æª¢æŸ¥æ‚¨çš„è¼¸å…¥æˆ–æ•¸æ“šæºæ˜¯å¦åœ¨è©²æ™‚æ®µæœ‰æ•¸æ“šã€‚")
                # å¦‚æœæœ‰éŒ¯èª¤ï¼Œæœƒåœ¨ä¸‹é¢é¡¯ç¤º

        if st.session_state.get("fetch_errors"):
            logger.warning(f"ä¸»é é¢ï¼šæ•¸æ“šç²å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {st.session_state.fetch_errors}")
            st.subheader("æ•¸æ“šç²å–éŒ¯èª¤:")
            for source, errors_list in st.session_state.fetch_errors.items():
                st.error(f"ä¾†æº {source.upper()}:")
                for err_msg in errors_list:
                    st.markdown(f"- {err_msg}")

        if st.session_state.get("fetched_data_preview"):
            logger.debug("ä¸»é é¢ï¼šé–‹å§‹æ¸²æŸ“å·²ç²å–æ•¸æ“šçš„é è¦½ã€‚")
            st.subheader("å·²ç²å–æ•¸æ“šé è¦½:")
            if "yfinance" in st.session_state.fetched_data_preview:
                st.markdown("#### yfinance æ•¸æ“š:")
                for ticker, df_yf in st.session_state.fetched_data_preview["yfinance"].items():
                    with st.expander(f"Ticker: {ticker} (å…± {len(df_yf)} è¡Œ)", expanded=False): st.dataframe(df_yf.head())

            if "fred" in st.session_state.fetched_data_preview:
                st.markdown("#### FRED æ•¸æ“š:")
                for series_id, df_fred in st.session_state.fetched_data_preview["fred"].items():
                    with st.expander(f"Series ID: {series_id} (å…± {len(df_fred)} è¡Œ)", expanded=False): st.dataframe(df_fred.head())

            if "ny_fed" in st.session_state.fetched_data_preview and st.session_state.fetched_data_preview["ny_fed"] is not None and not st.session_state.fetched_data_preview["ny_fed"].empty:
                st.markdown("#### NY Fed ä¸€ç´šäº¤æ˜“å•†æ•¸æ“š:")
                df_nyfed = st.session_state.fetched_data_preview["ny_fed"]
                with st.expander(f"NY Fed ç¸½æŒæœ‰é‡ (å…± {len(df_nyfed)} è¡Œ)", expanded=False): st.dataframe(df_nyfed.head())
            logger.debug("ä¸»é é¢ï¼šå·²ç²å–æ•¸æ“šé è¦½æ¸²æŸ“å®Œç•¢ã€‚")

    st.markdown("---")
    logger.info("ä¸»é é¢ï¼šä¸»è¦å…§å®¹æ¸²æŸ“çµæŸ (render_main_page_content)ã€‚")

if __name__ == "__main__":
    # æ¨¡æ“¬æ¸¬è©¦ (éœ€è¦ Streamlit ç’°å¢ƒå’Œ session_state)
    # st.session_state.update({ ... åˆå§‹åŒ– main_page éœ€è¦çš„éµ ...})
    # render_main_page_content()
    pass
